
Python requests.get() Examples

def resolve_reference_http(cls, design_uri):
        """Retrieve design documents from http/https endpoints.

        Return a byte array of the response content. Support unsecured or
        basic auth

        :param design_uri: Tuple as returned by urllib.parse for the design reference
        """
        if design_uri.username is not None and design_uri.password is not None:
            response = requests.get(
                design_uri.geturl(),
                auth=(design_uri.username, design_uri.password),
                timeout=get_client_timeouts())
        else:
            response = requests.get(
                design_uri.geturl(), timeout=get_client_timeouts())

        return response.content 
def getTicket():
    # put the ip address or dns of your apic-em controller in this url
    url = "https://" + controller + "/api/v1/ticket"

    #the username and password to access the APIC-EM Controller
    payload = {"username":"usernae","password":"password"}

    #Content type must be included in the header
    header = {"content-type": "application/json"}

    #Performs a POST on the specified url to get the service ticket
    response= requests.post(url,data=json.dumps(payload), headers=header, verify=False)

    #convert response to json format
    r_json=response.json()

    #parse the json to get the service ticket
    ticket = r_json["response"]["serviceTicket"]

    return ticket 
def open_url(url: str) -> Iterator[BytesIO]:
    parsed_url = requests.utils.urlparse(url)
    if parsed_url.scheme == 'file':
        assert parsed_url.netloc == '', f'Bad file URL: {url}'
        with open(requests.utils.unquote(parsed_url.path), 'rb') as infile:
            yield infile
    elif parsed_url.scheme in ['http', 'https']:
        # verify=True is the default, but I want to be explicit about HTTPS,
        # since this function receives GPG key material.
        with requests.get(url, stream=True, verify=True) as r:
            r.raise_for_status()
            yield r.raw  # A file-like `io`-style object for the HTTP stream
            if r.raw.isclosed():   # Proxy for "all data was consumed"
                # Sadly, requests 2.x does not verify content-length :/
                # We could check r.raw.length_remaining, likely equivalent.
                actual_size = r.raw.tell()
                header_size = int(r.headers['content-length'])
                assert actual_size == header_size, (actual_size, header_size)
    else:  # pragma: no cover
        raise RuntimeError(f'Unknown URL scheme in {url}') 
def __init__(self, url, method='get', data=None, params=None,
                 headers=None, content_type='application/json', **kwargs):
        self.url = url
        self.method = method
        self.params = params or {}
        self.kwargs = kwargs

        if not isinstance(headers, dict):
            headers = {}
        self.headers = CaseInsensitiveDict(headers)
        if content_type:
            self.headers['Content-Type'] = content_type
        if data:
            self.data = json.dumps(data)
        else:
            self.data = {} 
def __call__(self, client, dnode):
        logger.info('Test download speed :  running...')
        start = time.clock()
        r = requests.get('http://{}'.format(dnode), stream=True)
        total_length = int(r.headers.get('content-length'))
        if total_length is None:
            logger.error("Empty file!")
        else:
            array_speed = []
            start_chunk = time.clock()
            for chunk in r.iter_content(1024):  # 1kB1024 1MB 1048576
                end_chunk = time.clock()
                delta = end_chunk - start_chunk
                start_chunk = end_chunk
                if delta <= 0:
                    break
                else:
                    array_speed.append(1//delta)  # kB / s

            end = time.clock()
            yield from self._queue.put(self.get_result(dnode, start, end, total_length, array_speed)) 
def acceleration(self, array_speed):
        """Caculate acceleration.

        By get the highest speed in the first cycle.

        Args:
            array_speed (list): list download times for each 1024 Byte

        Returns:
            acceleration (kB/s) : the deviation between highest speed and first byte speed
        """

        if len(array_speed) == 0:
            return 0
        speed_before = array_speed[0]
        for speed in array_speed:
            if speed < speed_before:
                break
            else:
                speed_before = speed

        return speed_before - array_speed[0] 
def get_by_url(url):
    # Get show data from svtplay.se.
    r = requests.get('%s?type=embed&output=json' % (url))
    r.raise_for_status()

    response_json = r.json()
    video = response_json.get('video')

    # Get the highest quality video stream.
    for vr in video.get('videoReferences'):
        if vr.get('playerType') == 'ios':
            unscrubbed_url = vr.get('url')
            try:
                # remove all getvars from link
                scrubbed_url = unscrubbed_url[:unscrubbed_url.index('.m3u8') + 5]
                return scrubbed_url
            except IndexError:
                if unscrubbed_url:
                    print('Stream url used old format without alt getvar. Trying old style...')
                    return unscrubbed_url
                else:
                    print('Empty url to stream. Exiting.') 
def test_repomd(self):
        content = b'An abacus falls from a fig tree'
        timestamp = 1234567890
        with self.repo_server_thread({
            'repomd.xml': {
                'size': len(content),
                'build_timestamp': timestamp,
                'content_bytes': content,
            }
        }) as (host, port):
            req = requests.get(f'http://{host}:{port}/repomd.xml')
            req.raise_for_status()
            self.assertEqual(content, req.content)
            self.assertEqual(
                timestamp,
                email.utils.parsedate_to_datetime(req.headers['last-modified'])
                    .timestamp(),
            )
            self.assertEqual('text/xml', req.headers['content-type']) 
def _check_bad_blob(self, bad_blob):
        with self.repo_server_thread({'bad_blob': bad_blob}) as (host, port):
            # Drive-by test of HEAD requests -- note that this doesn't
            # detect the error yet, so the next GET "succeeds".
            req_head = requests.head(f'http://{host}:{port}/bad_blob')
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(req_head.status_code, req.status_code)
            self.assertEqual(_no_date(req_head.headers), _no_date(req.headers))
            # You'd think that `requests` would error on this, but, no...
            # https://blog.petrzemek.net/2018/04/22/
            #   on-incomplete-http-reads-and-the-requests-library-in-python/
            self.assertEqual(200, req.status_code)
            self.assertLess(
                req.raw.tell(),  # Number of bytes that were read
                int(req.headers['content-length']),
            )
            # Ok, so we didn't get enough bytes, let's retry. This verifies
            # that the server memoizes integrity errors correctly.
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(500, req.status_code)
            self.assertIn(b'file_integrity', req.content)
            return req.content.decode() 
def init_inventory_container(container,headers=None, org_name=None):
    
    initialize_config()
    
    headers = headers if headers else TSC_HEADERS
    org_name = org_name if org_name else ORG_NAME
    
    def _container_url(container_id):
            return 'https://secure.transcriptic.com/{}/samples/{}.json'.format(org_name, container_id)

    response = requests.get(_container_url(container.id), headers=headers, verify=False)
    response.raise_for_status()

    container_json = response.json()   
    
    container.cover = container_json['cover']
    
    for well in container.all_wells():
        init_inventory_well(well,container_json=container_json)
    
   
#@TODO: this needs to be mocked in tests since it hits the transcriptic api 
def __init__(self, email: str, api_key: str, domain: str, proxied: bool):
        """
        Initialization. It will set the zone information of the domain for operation.
        It will also get dns records of the current zone.
        :param email:
        :param api_key:
        :param domain:
        :param proxied:
        """
        self.email = email
        self.api_key = api_key
        self.domain = domain
        self.proxied = proxied
        self.headers = {
            'X-Auth-Key': api_key,
            'X-Auth-Email': email
        }
        self.setup_zone() 
def setup_zone(self):
        """
        Setup zone for current domain.
        It will also setup the dns records of the zone
        :return:
        """
        # Initialize current zone
        zones_content = self.request(self.api_url, 'get')
        try:
            if len(self.domain.split('.')) == 3:
                domain = self.domain.split('.', 1)[1]
            else:
                domain = self.domain
            zone = [zone for zone in zones_content['result'] if zone['name'] == domain][0]
        except IndexError:
            raise ZoneNotFound('Cannot find zone information for the domain {domain}.'
                               .format(domain=self.domain))
        self.zone = zone

        # Initialize dns_records of current zone
        dns_content = self.request(self.api_url + zone['id'] + '/dns_records', 'get')
        self.dns_records = dns_content['result'] 
def convert_ensembl_to_entrez(self, ensembl):
        """Convert Ensembl Id to Entrez Gene Id"""
        if 'ENST' in ensembl:
            pass
        else:
            raise (IndexError)
        # Submit resquest to NCBI eutils/Gene database
        server = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?" + self.options + "&db=gene&term={0}".format(
            ensembl)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        # Process Request
        response = r.text
        info = xmltodict.parse(response)
        try:
            geneId = info['eSearchResult']['IdList']['Id']
        except TypeError:
            raise (TypeError)
        return geneId 
def convert_hgnc_to_entrez(self, hgnc):
        """Convert HGNC Id to Entrez Gene Id"""
        entrezdict = {}
        server = "http://rest.genenames.org/fetch/hgnc_id/{0}".format(hgnc)
        r = requests.get(server, headers={"Content-Type": "application/json"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        response = r.text
        info = xmltodict.parse(response)
        for data in info['response']['result']['doc']['str']:
            if data['@name'] == 'entrez_id':
                entrezdict[data['@name']] = data['#text']
            if data['@name'] == 'symbol':
                entrezdict[data['@name']] = data['#text']
        return entrezdict 
def convert_uniprot_to_entrez(self, uniprot):
        """Convert Uniprot Id to Entrez Id"""
        # Submit request to NCBI eutils/Gene Database
        server = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?" + self.options + "&db=gene&term={0}".format(
            uniprot)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        # Process Request
        response = r.text
        info = xmltodict.parse(response)
        geneId = info['eSearchResult']['IdList']['Id']
        # check to see if more than one result is returned
        # if you have more than more result then check which Entrez Id returns the same uniprot Id entered.
        if len(geneId) > 1:
            for x in geneId:
                c = self.convert_entrez_to_uniprot(x)
                c = c.lower()
                u = uniprot.lower()
                if c == u:
                    return x
        else:
            return geneId 
def resolve_reference_ucp(cls, design_uri):
        """Retrieve artifacts from a Airship service endpoint.

        Return a byte array of the response content. Assumes Keystone
        authentication required.

        :param design_uri: Tuple as returned by urllib.parse for the design reference
        """
        ks_sess = KeystoneUtils.get_session()
        (new_scheme, foo) = re.subn(r'^[^+]+\+', '', design_uri.scheme)
        url = urllib.parse.urlunparse(
            (new_scheme, design_uri.netloc, design_uri.path, design_uri.params,
             design_uri.query, design_uri.fragment))
        LOG.debug("Calling Keystone session for url %s" % str(url))
        resp = ks_sess.get(url, timeout=get_client_timeouts())
        if resp.status_code >= 400:
            raise errors.InvalidDesignReference(
                "Received error code for reference %s: %s - %s" %
                (url, str(resp.status_code), resp.text))
        return resp.content 
def client():
    with vcr.use_cassette('tests/fixtures/vcr_cassettes/client.yaml'):
        request = requests.get(URL,
                            headers={
                                'Host': 'swapi.graphene-python.org',
                                'Accept': 'text/html',
                            })
        request.raise_for_status()
        csrf = request.cookies['csrftoken']

        return Client(
            transport=RequestsHTTPTransport(url=URL,
                                            cookies={"csrftoken": csrf},
                                            headers={'x-csrftoken':  csrf}),
            fetch_schema_from_transport=True
        ) 
def __init__(self, name, site='https://roll20.net/compendium/dnd5e/'):
        self.name = name.rstrip().title()
        formatted_name = self.name.replace(' ', '_')
        url = site + formatted_name
        page = requests.get(url)
        if page.status_code != 200:
            raise IOError('{:s} not found at {:s}.'.format(name,
                                                           url))
        if 'marketplace' in page.url:
              raise IOError('{:s} not found at {:s}, '
                            'likely because this content is behind a paywall. '
                            'Encourage developer to add alternative back-ends to Roll20'.format(name, url))
        html = page.text
        soup = bs(html, 'html.parser')
        self.attributes = ({stringify(a.text):
                            stringify(a.find_next(attrs={'class':
                                                         'value'}).text)
                            for a in soup.find_all(attrs={'class':
                                                          'col-md-3 attrName'})})
        self.desc = '\n'.join([stringify(val.text)
                               for val in soup.find_all(id='origpagecontent',
                                                        attrs={'type':
                                                               'text/html'})]) 
def str_attributes(self):
        res = ''
        for k in ['HP', 'AC', 'Speed', 'Challenge Rating']:
            res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        res += '\n'
        for k in ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA']:
            res += k + '\t'
        res += '\n'
        for k in ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA']:
            s = self.get(k, None)
            res += '{:s} ({:s})\t'.format(s, score_to_mod(int(s)))
        res += '\n\n'
        for k in ['Type', 'Size', 'Alignment', 'Senses', 'Skills',
                  'Languages']:
            res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        return res 
def as_dungeonsheets_class(self):
        spell_name = self.name
        class_name = spell_name.replace(' ', '').replace('-', '')
        res = 'class {:s}(Spell):\n'.format(class_name)
        res += "    \"\"\"{:s}\n    \"\"\"\n".format(self.desc.replace('\n', '\n    '))
        res += "    name = \"{:s}\"\n".format(spell_name)
        res += "    level = {:d}\n".format(int(self.get('Level', -1)))
        res += "    casting_time = \"{:s}\"\n".format(self.get('Casting Time', '1 action'))
        res += "    casting_range = \"{:s}\"\n".format(self.get('Range', ''))
        str_components = self.get('Components', '').upper().split(' ')
        if len(str_components) == 0:
            res += "    components = ()\n"
        else:
            res += "    components = {:s}\n".format(str(tuple(str_components)))
        res += "    materials = \"\"\"{:s}\"\"\"\n".format(self.get('Material', ''))
        dur_text = "\"{:s}\"\n".format(self.get('Duration', 'Instantaneous'))
        dur_text = ("\"Concentration, {:s}".format(dur_text.lstrip('\"')) if
                    self.get('Concentration', '') else dur_text)
        duration = "    duration = " + dur_text
        res += duration
        res += "    ritual = {:}\n".format(bool(self.get('Ritual', '')))
        res += "    magic_school = \"{:s}\"\n".format(self.get('School', ''))
        res += "    classes = {:s}\n".format(str(tuple(self.get('Classes', '').split(', '))))
        return res + "\n" 
def get_vmprofiles(self):
        url = 'https://%s/php/vmprofiles.php' % self.atdserver

        try:
            r = requests.get(url, headers=self.sessionhdr, verify=False)
        except Exception as e:
            error_info = 'Error getting vmprofiles:\n%s' % e
            return(0, error_info)

        if r.status_code == 200:
            server_info = json.loads(r.content)

            if server_info['success'] is True:
                return (1, server_info['results'])

            else:
                error_info = 'Error getting vmprofiles, check credentials or content type header'
                return (0, error_info)
        else:
            error_info = 'Error getting vmprofiles, status code: %d' % r.status_code
            return (0, error_info) 
def getNetworkDevices(ticket):
    # URL for network device REST API call to get list of existing devices on the network.
    url = "https://" + controller + "/api/v1/network-device"

    #Content type must be included in the header as well as the ticket
    header = {"content-type": "application/json", "X-Auth-Token":ticket}

    # this statement performs a GET on the specified network-device url
    response = requests.get(url, headers=header, verify=False)

    # json.dumps serializes the json into a string and allows us to
    # print the response in a 'pretty' format with indentation etc.
    print ("Network Devices = ")
    print (json.dumps(response.json(), indent=4, separators=(',', ': ')))

  #convert data to json format.
    r_json=response.json()

  #Iterate through network device data and print the id and series name of each device
    for i in r_json["response"]:
        print(i["id"] + "   " + i["series"])

#call the functions 
def __call__(self, client, dnode):
        logger.info('Caculating time for download first byte...')
        r = requests.get('http://{}'.format(dnode), stream=True)
        total_length = int(r.headers.get('content-length'))
        if total_length is None:
            logger.info("empty file!")
        else:
            start_chunk = time.clock()
            for chunk in r.iter_content(1024):  # 1kB1024 1MB 1048576
                end_chunk = time.clock()
                break

            delta = end_chunk - start_chunk  # time to first byte
            yield from self._queue.put(self.get_result(dnode, delta)) 
def get_client_id():
    r = requests.get(CDN_BASE + 'global.js')
    if r.status_code >= 400:
        raise Exception('Error fetching global.js script.')

    # Find the client ID with a regex that totally wont match anything else /s
    client_ids = re.findall(r'clientID:"(\w*)"', r.text)
    if len(client_ids) != 1:
        raise Exception(
            'Error finding client ID in twitch global-frontend script. Got {}'.format(client_ids))
    return client_ids[0] 
def get_token_and_signature(channel, client_id):
    url = TOKEN_API.format(channel=channel)
    headers = {'Client-ID': client_id}
    r = requests.get(url, headers=headers)
    if r.status_code >= 400:
        raise Exception('Error requesting token from twitch: {}'.format(r.text))
    data = r.json()
    return data['token'], data['sig'] 
def get_live_stream(channel):
    client_id = get_client_id()
    token, sig = get_token_and_signature(channel, client_id)
    url = USHER_API.format(channel=channel, sig=sig, token=token, random=random.randint(0, 1E7))
    r = requests.get(url)
    m3u8_obj = m3u8.loads(r.text)
    return m3u8_obj 
def get_api_data(self):
        """
        Gets json file containing server information

        :return: server information in json format
        """
        try:
            resp = requests.get(api, timeout=5)
            if resp.status_code == requests.codes.ok:
                return resp.json()
            else:
                self.statusbar.showMessage("Get API failed", 2000)
        except Exception as ex:
            self.statusbar.showMessage("Get API failed", 2000) 
def get_ovpn(self):
        """
        Gets ovpn file from nord servers and saves it to a temporary location
        """
        # https://downloads.nordcdn.com/configs/files/ovpn_udp/servers/sg173.nordvpn.com.udp.ovpn
        self.ovpn_path = None
        ovpn_url = None
        udp_url = 'https://downloads.nordcdn.com/configs/files/ovpn_udp/servers/'
        tcp_url = 'https://downloads.nordcdn.com/configs/files/ovpn_tcp/servers/'
        udp_xor_url = 'https://downloads.nordcdn.com/configs/files/ovpn_xor_udp/servers/'
        tcp_xor_url = 'https://downloads.nordcdn.com/configs/files/ovpn_xor_tcp/servers/'

        if (self.server_type_select.currentText() == 'Obfuscated Server') and (self.connection_type_select.currentText() == 'UDP'):
            ovpn_url = udp_xor_url
        elif (self.server_type_select.currentText() == 'Obfuscated Server') and (self.connection_type_select.currentText() == 'TCP'):
            ovpn_url = tcp_xor_url
        elif (self.server_type_select.currentText() != 'Obfuscated Server') and (self.connection_type_select.currentText() == 'UDP'):
            ovpn_url = udp_url
        elif (self.server_type_select.currentText() != 'Obfuscated Server') and (self.connection_type_select.currentText() == 'TCP'):
            ovpn_url = tcp_url

        if self.connection_type_select.currentText() == 'UDP':
            filename = self.domain_list[self.server_list.currentRow()] + '.udp.ovpn'
            ovpn_file = requests.get(ovpn_url + filename, stream=True)
            if ovpn_file.status_code == requests.codes.ok:
                self.ovpn_path = os.path.join(self.config_path, filename)
                with open(self.ovpn_path, 'wb') as out_file:
                    shutil.copyfileobj(ovpn_file.raw, out_file)
            else: self.statusbar.showMessage('Error fetching configuration files', 2000)

        elif self.connection_type_select.currentText() == 'TCP':
            filename = self.domain_list[self.server_list.currentRow()] + '.tcp.ovpn'
            ovpn_file = requests.get(ovpn_url + filename, stream=True)
            if ovpn_file.status_code == requests.codes.ok:
                self.ovpn_path = os.path.join(self.config_path, filename)
                with open(self.ovpn_path, 'wb') as out_file:
                    shutil.copyfileobj(ovpn_file.raw, out_file)
            else: self.statusbar.showMessage('Error fetching configuration files', 2000)

        self.server_list.setFocus() 
def updateFactorio():
	

	file_name = "/tmp/latestFactorio.tar.gz"
	print("Downloading %s" % file_name)

	r = requests.get(DOWNLOADURL, stream=True)
	total_length = int(r.headers.get('content-length'))

	if not os.path.isfile(file_name) or total_length != os.path.getsize(file_name):
		with open(file_name, 'wb') as f:
			for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length/1024) + 1): 
				if chunk:
					f.write(chunk)
					f.flush()
			#os.chmod(file_name, stat.S_IWUSR | stat.S_IRUSR)
	else:
		print("File already exists and file sizes match. Skipping download.")	

	if os.access(FACTORIOPATH, os.W_OK):
		if os.path.isfile(file_name):
			tar = tarfile.open(file_name, "r:gz")
			tar.extractall(path="/tmp")
			tar.close()

			copytree("/tmp/factorio", FACTORIOPATH)
			print("Success.")
		else:
			print("Help! Can't find %s, but I should have!" % (file_name))
			sys.exit(1)			
	else:
		print("Can't write to %s" % (FACTORIOPATH))
		sys.exit(1) 
def get_dict_optional_value(d,keys_to_try_in_order, default_value=None):
    """
    Tries each key in order, if not value is found, returns default_value
    """
    
    for key in keys_to_try_in_order:
        if key in d and d.get(key):
            return d[key]
        
    return default_value 
def get_melting_temp(dna_sequence, oligo_concentration_uM,
                     pcr_settings='q5'):
    global IDT_COOKIE
    
    #@TODO: update this to use http://tmcalculator.neb.com/#!/ since its probably accounting for the salt concentration in the buffer
    
    if not IDT_COOKIE:
        r = requests.get('http://www.idtdna.com/calc/analyzer',allow_redirects=False)
        IDT_COOKIE = r.cookies['ASP.NET_SessionId']       
        
    headers = {"content-type":'application/json','Cookie':'ASP.NET_SessionId=%s'%IDT_COOKIE}
    
    idt_response = requests.post('https://www.idtdna.com/calc/analyzer/home/analyze',json={
        "settings": {
            "Sequence": dna_sequence,
            "NaConc": 0,
            "MgConc": 2,
            "DNTPsConc": 5, 
            "OligoConc": oligo_concentration_uM,
            "NucleotideType": "DNA"
        }
    }, verify=False
    ,headers=headers)    
    
    idt_response.raise_for_status()
    
    return idt_response.json()['MeltTemp'] 
def do(self):
        # logging.debug("{} {}: \n\tHeaders {}, \n\tData {}, \n\tParams {}, \n\tOther: {}".format(
        #     self.method.upper(), self.url, self.headers,
        #     self.data, self.params, self.kwargs
        # ))
        result = self.methods.get(self.method)(
            url=self.url, headers=self.headers,
            data=self.data, params=self.params,
            **self.kwargs
        )
        return result 
def do(self, api_name=None, pk=None, method='get', use_auth=True,
           data=None, params=None, content_type='application/json', **kwargs):

        if api_name in API_URL_MAPPING:
            path = API_URL_MAPPING.get(api_name)
            if pk and '%s' in path:
                path = path % pk
        else:
            path = api_name

        request_headers = kwargs.get('headers', {})
        default_headers = self.default_headers or {}
        headers = {k: v for k, v in default_headers.items()}
        headers.update(request_headers)
        kwargs['headers'] = headers
        url = self.endpoint.rstrip('/') + path
        req = HttpRequest(url, method=method, data=data,
                          params=params, content_type=content_type,
                          **kwargs)
        if use_auth:
            if not self.auth:
                msg = 'Authentication required, but not provide'
                logger.error(msg)
                raise RequestError(msg)
            else:
                self.auth.sign_request(req)

        try:
            resp = req.do()
        except (requests.ConnectionError, requests.ConnectTimeout) as e:
            msg = "Connect endpoint {} error: {}".format(self.endpoint, e)
            logger.error(msg)
            raise RequestError(msg)

        return self.clean_result(resp) 
def get(self, *args, **kwargs):
        kwargs['method'] = 'get'
        return self.do(*args, **kwargs) 
def create_record(self, dns_type, name, content, **kwargs):
        """
        Create a dns record
        :param dns_type:
        :param name:
        :param content:
        :param kwargs:
        :return:
        """
        data = {
            'type': dns_type,
            'name': name,
            'content': content
        }
        if kwargs.get('ttl') and kwargs['ttl'] != 1:
            data['ttl'] = kwargs['ttl']
        if kwargs.get('proxied') is True:
            data['proxied'] = True
        else:
            data['proxied'] = False
        content = self.request(
            self.api_url + self.zone['id'] + '/dns_records',
            'post',
            data=data
        )
        print('DNS record successfully created')
        return content['result'] 
def update_record(self, dns_type, name, content, **kwargs):
        """
        Update dns record
        :param dns_type:
        :param name:
        :param content:
        :param kwargs:
        :return:
        """
        record = self.get_record(dns_type, name)
        data = {
            'type': dns_type,
            'name': name,
            'content': content
        }
        if kwargs.get('ttl') and kwargs['ttl'] != 1:
            data['ttl'] = kwargs['ttl']
        if kwargs.get('proxied') is True:
            data['proxied'] = True
        else:
            data['proxied'] = False
        content = self.request(
            urllib.parse.urljoin(self.api_url, self.zone['id'] + '/dns_records/' + record['id']),
            'put',
            data=data
        )
        print('DNS record successfully updated')
        return content['result'] 
def search(self, type, q, territory='TW'):
        response = requests.get(self.API_BASE_URL + 'search', params={'type': type, 'q': q, 'territory': territory},
                                headers={'Authorization': 'Bearer ' + self.token})
        response.raise_for_status()
        response_json = response.json()

        if type == 'artist':
            return response_json['artists']['data'][0]['url']
        else:
            id = response_json[type + 's']['data'][0]['id']
            return 'https://widget.kkbox.com/v1/?id=' + id \
                   + '&type=' + ('song' if type == 'track' else type) 
def _get_cache_stale_secs(cache_stale=None):
    # overrides config
    caching_val = config.CONFIG.parser.get('cache', 'normal')
    if caching_val in ('never', 'false', 'False', 'off', 'Off'):
        return 0
    if caching_val in ('test', 'forever'):
        return CACHE_FOREVER
    if cache_stale is None:
        return 0
    return cache_stale 
def request_json(url, output_filename=None, cache_stale=None):
    """Sends a request expecting a json-formatted response.
    If output_filename is given, then the output is saved to file.
    This also enables basic caching, where cache_stale is the number of seconds
    since file is last modified before the cached file is considered stale (0 means disable the cache).
    """
    cache_stale = _get_cache_stale_secs(cache_stale)
    # Guard against very long filenames:
    if output_filename and len(output_filename) >= MAX_CACHE_FILENAME_LEN:
        output_filename = output_filename[0:MAX_CACHE_FILENAME_LEN-1]
    if output_filename and cache_stale:
        if output_filename in CACHE:
            return CACHE[output_filename]
        json_file = os.path.join(_get_cachedir(), '{}.json'.format(output_filename))
        if os.path.exists(json_file) and (int(time.time()) - os.path.getmtime(json_file) < cache_stale):
            with open(json_file) as jfh:
                CACHE[output_filename] = json.load(jfh)
            if config.DEBUG:
                LOG.info('Loaded from cache: %s', output_filename)
            return CACHE[output_filename]

    LOG.debug('Getting url=%s ...', url)
    headers = {
        'User-Agent': config.CONFIG.ua_iphone,
        'Connection': 'close'
    }
    util.log_http(url, 'get', headers, sys._getframe().f_code.co_name)
    response = requests.get(url, headers=headers, verify=config.VERIFY_SSL)
    response.raise_for_status()

    # Note: this fails on windows in some cases https://github.com/kennethreitz/requests-html/issues/171
    if output_filename is not None or (config.DEBUG and config.SAVE_JSON_FILE):
        json_file = os.path.join(_get_cachedir(), '{}.json'.format(output_filename))
        with open(json_file, 'w', encoding='utf-8') as out:  # write date to json_file
            out.write(response.text)
    if cache_stale:
        LOG.debug('Caching url=%s, filename=%s', url, output_filename)
        CACHE[output_filename] = response.json()
        return CACHE[output_filename]
    return response.json() 
def get_attrib(self, et_node, prefixed_attrib):
        """Get a prefixed attribute like 'rdf:resource' from ET node."""
        prefix, attrib = prefixed_attrib.split(':')
        return et_node.get('{{{0}}}{1}'.format(self.namespaces[prefix],
                                               attrib)) 
def __init__(self, namespaces=None, cc_resolver=None, source=None):
        """Init the remote loader."""
        super(RemoteFundRefLoader, self).__init__(
            namespaces=namespaces, cc_resolver=cc_resolver)
        self.source = source or \
            current_app.config['OPENAIRE_FUNDREF_ENDPOINT']
        headers = {"Content-Type": "application/rdf+xml"}
        obj = requests.get(self.source, stream=True, headers=headers)
        funders_xml = obj.text.encode('utf-8')
        self.doc_root = ET.fromstring(funders_xml) 
def resolve_by_id(self, funder_id):
        """Resolve the funder from the OpenAIRE funder id.

        If funder_id can be resolved, return a URI otherwise return None.
        """
        return self.data.get(funder_id) 
def resolve_by_oai_id(self, oai_id):
        """Resolve the funder from the OpenAIRE OAI record id.

        Hack for when funder is not provided in OpenAIRE.
        """
        if oai_id.startswith('oai:dnet:'):
            oai_id = oai_id[len('oai:dnet:'):]
        prefix = oai_id.split("::")[0]
        suffix = prefix.replace("_", "").upper()
        oaf = "{0}::{1}".format(prefix, suffix)
        return self.data.get(oaf) 
def resolve_by_doi(self, doi):
        """Resolve a DOI to an OpenAIRE id."""
        return self.inverse_data.get(doi) 
def forward(self, text):

        '''
        In PyTorch RNNs want the input with batch dim second, CNNs want the batch dim first
        we permute the input to make it the right shape for the CNN
        '''
        text = text.permute(1, 0)

        # Text passed through embedding layer to get embeddings
        embedded = self.embedding(text)

        '''
        A conv layer wants the second dim of the input to be a channel dim
        text does not have a channel dim, so the tensor is unsqueezed to create one
        '''
        embedded = embedded.unsqueeze(1)

        # Iterates through the list of conv layers applying each conv layer to get list of conv outputs
        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]

        '''
        Conv outputs are passed through a max pooling that takes the maximum value over a dimension
        the idea being that the "maximum value" is the most important feature for determining the sentiment
        which corresponds to the most important n-gram in the review
        '''
        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]

        '''
        The model has 100 filters of 3 different sizes, therefore 300 n-grams that could be important
        which we concatenate into a single vector and pass through a dropout layer and finally a linear layer
        (NOTE: dropout is set to 0 during inference time)
        '''
        cat = self.dropout(torch.cat(pooled, dim = 1))

        # passed through linear layer to make predictions
        return self.fc(cat) 
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
def nodeLatestVersion(dependency, project_id):
    r = requests.get('%s%s/latest' % (app.config['NPM_REGISTRY'], dependency))
    latestVersion = r.json().get('version')

    try:
        dep = ProjectDependency.by_project(project_id, dependency)
        dep.latest_version = latestVersion
        if LooseVersion(dep.actual_version) < LooseVersion(latestVersion):
            dep.status = 'ko'
        else:
            dep.status = 'ok'
        db.session.commit()
    except Exception, e:
        app.logger.error(e)
        db.session.rollback() 
def nodeDepsFetcher(project_id):
    # Get dependencies from package.json
    project = git.getproject(project_id)

    depFileEncoded = git.getfile(project_id, 'package.json',
                                 project['default_branch'])

    # Decode from base64
    deps = json.loads(depFileEncoded.get('content').decode('base64'))

    mainDeps = deps.get('dependencies')
    devDeps = deps.get('devDependencies')

    # Insert in project_dependency
    # TODO create single function for that
    for mDep, mVersion in list(mainDeps.items()):
        mdep, created = get_or_create(db.session, ProjectDependency,
                                      project_id=project_id, name=mDep,
                                      actual_version=mVersion)

        if not created:
            app.logger.info('[%s] Dep %s already exist' % (project_id, mDep))

        db.session.commit()
        nodeLatestVersion(mDep, project_id)

    for devDep, devVersion in list(devDeps.items()):
        ddep, created = get_or_create(db.session, ProjectDependency,
                                      project_id=project_id, name=devDep,
                                      actual_version=devVersion, dev=True)

        if not created:
            app.logger.info('[%s] Dev dep %s already exist' %
                            (project_id, devDep))

        db.session.commit()
        nodeLatestVersion(devDep, project_id)
    return True 
**************************************************


Python requests.get() Examples

def resolve_reference_http(cls, design_uri):
        """Retrieve design documents from http/https endpoints.

        Return a byte array of the response content. Support unsecured or
        basic auth

        :param design_uri: Tuple as returned by urllib.parse for the design reference
        """
        if design_uri.username is not None and design_uri.password is not None:
            response = requests.get(
                design_uri.geturl(),
                auth=(design_uri.username, design_uri.password),
                timeout=get_client_timeouts())
        else:
            response = requests.get(
                design_uri.geturl(), timeout=get_client_timeouts())

        return response.content 
def getTicket():
    # put the ip address or dns of your apic-em controller in this url
    url = "https://" + controller + "/api/v1/ticket"

    #the username and password to access the APIC-EM Controller
    payload = {"username":"usernae","password":"password"}

    #Content type must be included in the header
    header = {"content-type": "application/json"}

    #Performs a POST on the specified url to get the service ticket
    response= requests.post(url,data=json.dumps(payload), headers=header, verify=False)

    #convert response to json format
    r_json=response.json()

    #parse the json to get the service ticket
    ticket = r_json["response"]["serviceTicket"]

    return ticket 
def open_url(url: str) -> Iterator[BytesIO]:
    parsed_url = requests.utils.urlparse(url)
    if parsed_url.scheme == 'file':
        assert parsed_url.netloc == '', f'Bad file URL: {url}'
        with open(requests.utils.unquote(parsed_url.path), 'rb') as infile:
            yield infile
    elif parsed_url.scheme in ['http', 'https']:
        # verify=True is the default, but I want to be explicit about HTTPS,
        # since this function receives GPG key material.
        with requests.get(url, stream=True, verify=True) as r:
            r.raise_for_status()
            yield r.raw  # A file-like `io`-style object for the HTTP stream
            if r.raw.isclosed():   # Proxy for "all data was consumed"
                # Sadly, requests 2.x does not verify content-length :/
                # We could check r.raw.length_remaining, likely equivalent.
                actual_size = r.raw.tell()
                header_size = int(r.headers['content-length'])
                assert actual_size == header_size, (actual_size, header_size)
    else:  # pragma: no cover
        raise RuntimeError(f'Unknown URL scheme in {url}') 
def __init__(self, url, method='get', data=None, params=None,
                 headers=None, content_type='application/json', **kwargs):
        self.url = url
        self.method = method
        self.params = params or {}
        self.kwargs = kwargs

        if not isinstance(headers, dict):
            headers = {}
        self.headers = CaseInsensitiveDict(headers)
        if content_type:
            self.headers['Content-Type'] = content_type
        if data:
            self.data = json.dumps(data)
        else:
            self.data = {} 
def __call__(self, client, dnode):
        logger.info('Test download speed :  running...')
        start = time.clock()
        r = requests.get('http://{}'.format(dnode), stream=True)
        total_length = int(r.headers.get('content-length'))
        if total_length is None:
            logger.error("Empty file!")
        else:
            array_speed = []
            start_chunk = time.clock()
            for chunk in r.iter_content(1024):  # 1kB1024 1MB 1048576
                end_chunk = time.clock()
                delta = end_chunk - start_chunk
                start_chunk = end_chunk
                if delta <= 0:
                    break
                else:
                    array_speed.append(1//delta)  # kB / s

            end = time.clock()
            yield from self._queue.put(self.get_result(dnode, start, end, total_length, array_speed)) 
def acceleration(self, array_speed):
        """Caculate acceleration.

        By get the highest speed in the first cycle.

        Args:
            array_speed (list): list download times for each 1024 Byte

        Returns:
            acceleration (kB/s) : the deviation between highest speed and first byte speed
        """

        if len(array_speed) == 0:
            return 0
        speed_before = array_speed[0]
        for speed in array_speed:
            if speed < speed_before:
                break
            else:
                speed_before = speed

        return speed_before - array_speed[0] 
def get_by_url(url):
    # Get show data from svtplay.se.
    r = requests.get('%s?type=embed&output=json' % (url))
    r.raise_for_status()

    response_json = r.json()
    video = response_json.get('video')

    # Get the highest quality video stream.
    for vr in video.get('videoReferences'):
        if vr.get('playerType') == 'ios':
            unscrubbed_url = vr.get('url')
            try:
                # remove all getvars from link
                scrubbed_url = unscrubbed_url[:unscrubbed_url.index('.m3u8') + 5]
                return scrubbed_url
            except IndexError:
                if unscrubbed_url:
                    print('Stream url used old format without alt getvar. Trying old style...')
                    return unscrubbed_url
                else:
                    print('Empty url to stream. Exiting.') 
def test_repomd(self):
        content = b'An abacus falls from a fig tree'
        timestamp = 1234567890
        with self.repo_server_thread({
            'repomd.xml': {
                'size': len(content),
                'build_timestamp': timestamp,
                'content_bytes': content,
            }
        }) as (host, port):
            req = requests.get(f'http://{host}:{port}/repomd.xml')
            req.raise_for_status()
            self.assertEqual(content, req.content)
            self.assertEqual(
                timestamp,
                email.utils.parsedate_to_datetime(req.headers['last-modified'])
                    .timestamp(),
            )
            self.assertEqual('text/xml', req.headers['content-type']) 
def _check_bad_blob(self, bad_blob):
        with self.repo_server_thread({'bad_blob': bad_blob}) as (host, port):
            # Drive-by test of HEAD requests -- note that this doesn't
            # detect the error yet, so the next GET "succeeds".
            req_head = requests.head(f'http://{host}:{port}/bad_blob')
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(req_head.status_code, req.status_code)
            self.assertEqual(_no_date(req_head.headers), _no_date(req.headers))
            # You'd think that `requests` would error on this, but, no...
            # https://blog.petrzemek.net/2018/04/22/
            #   on-incomplete-http-reads-and-the-requests-library-in-python/
            self.assertEqual(200, req.status_code)
            self.assertLess(
                req.raw.tell(),  # Number of bytes that were read
                int(req.headers['content-length']),
            )
            # Ok, so we didn't get enough bytes, let's retry. This verifies
            # that the server memoizes integrity errors correctly.
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(500, req.status_code)
            self.assertIn(b'file_integrity', req.content)
            return req.content.decode() 
def init_inventory_container(container,headers=None, org_name=None):
    
    initialize_config()
    
    headers = headers if headers else TSC_HEADERS
    org_name = org_name if org_name else ORG_NAME
    
    def _container_url(container_id):
            return 'https://secure.transcriptic.com/{}/samples/{}.json'.format(org_name, container_id)

    response = requests.get(_container_url(container.id), headers=headers, verify=False)
    response.raise_for_status()

    container_json = response.json()   
    
    container.cover = container_json['cover']
    
    for well in container.all_wells():
        init_inventory_well(well,container_json=container_json)
    
   
#@TODO: this needs to be mocked in tests since it hits the transcriptic api 
def __init__(self, email: str, api_key: str, domain: str, proxied: bool):
        """
        Initialization. It will set the zone information of the domain for operation.
        It will also get dns records of the current zone.
        :param email:
        :param api_key:
        :param domain:
        :param proxied:
        """
        self.email = email
        self.api_key = api_key
        self.domain = domain
        self.proxied = proxied
        self.headers = {
            'X-Auth-Key': api_key,
            'X-Auth-Email': email
        }
        self.setup_zone() 
def setup_zone(self):
        """
        Setup zone for current domain.
        It will also setup the dns records of the zone
        :return:
        """
        # Initialize current zone
        zones_content = self.request(self.api_url, 'get')
        try:
            if len(self.domain.split('.')) == 3:
                domain = self.domain.split('.', 1)[1]
            else:
                domain = self.domain
            zone = [zone for zone in zones_content['result'] if zone['name'] == domain][0]
        except IndexError:
            raise ZoneNotFound('Cannot find zone information for the domain {domain}.'
                               .format(domain=self.domain))
        self.zone = zone

        # Initialize dns_records of current zone
        dns_content = self.request(self.api_url + zone['id'] + '/dns_records', 'get')
        self.dns_records = dns_content['result'] 
def convert_ensembl_to_entrez(self, ensembl):
        """Convert Ensembl Id to Entrez Gene Id"""
        if 'ENST' in ensembl:
            pass
        else:
            raise (IndexError)
        # Submit resquest to NCBI eutils/Gene database
        server = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?" + self.options + "&db=gene&term={0}".format(
            ensembl)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        # Process Request
        response = r.text
        info = xmltodict.parse(response)
        try:
            geneId = info['eSearchResult']['IdList']['Id']
        except TypeError:
            raise (TypeError)
        return geneId 
def convert_hgnc_to_entrez(self, hgnc):
        """Convert HGNC Id to Entrez Gene Id"""
        entrezdict = {}
        server = "http://rest.genenames.org/fetch/hgnc_id/{0}".format(hgnc)
        r = requests.get(server, headers={"Content-Type": "application/json"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        response = r.text
        info = xmltodict.parse(response)
        for data in info['response']['result']['doc']['str']:
            if data['@name'] == 'entrez_id':
                entrezdict[data['@name']] = data['#text']
            if data['@name'] == 'symbol':
                entrezdict[data['@name']] = data['#text']
        return entrezdict 
def convert_uniprot_to_entrez(self, uniprot):
        """Convert Uniprot Id to Entrez Id"""
        # Submit request to NCBI eutils/Gene Database
        server = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?" + self.options + "&db=gene&term={0}".format(
            uniprot)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        # Process Request
        response = r.text
        info = xmltodict.parse(response)
        geneId = info['eSearchResult']['IdList']['Id']
        # check to see if more than one result is returned
        # if you have more than more result then check which Entrez Id returns the same uniprot Id entered.
        if len(geneId) > 1:
            for x in geneId:
                c = self.convert_entrez_to_uniprot(x)
                c = c.lower()
                u = uniprot.lower()
                if c == u:
                    return x
        else:
            return geneId 
def resolve_reference_ucp(cls, design_uri):
        """Retrieve artifacts from a Airship service endpoint.

        Return a byte array of the response content. Assumes Keystone
        authentication required.

        :param design_uri: Tuple as returned by urllib.parse for the design reference
        """
        ks_sess = KeystoneUtils.get_session()
        (new_scheme, foo) = re.subn(r'^[^+]+\+', '', design_uri.scheme)
        url = urllib.parse.urlunparse(
            (new_scheme, design_uri.netloc, design_uri.path, design_uri.params,
             design_uri.query, design_uri.fragment))
        LOG.debug("Calling Keystone session for url %s" % str(url))
        resp = ks_sess.get(url, timeout=get_client_timeouts())
        if resp.status_code >= 400:
            raise errors.InvalidDesignReference(
                "Received error code for reference %s: %s - %s" %
                (url, str(resp.status_code), resp.text))
        return resp.content 
def client():
    with vcr.use_cassette('tests/fixtures/vcr_cassettes/client.yaml'):
        request = requests.get(URL,
                            headers={
                                'Host': 'swapi.graphene-python.org',
                                'Accept': 'text/html',
                            })
        request.raise_for_status()
        csrf = request.cookies['csrftoken']

        return Client(
            transport=RequestsHTTPTransport(url=URL,
                                            cookies={"csrftoken": csrf},
                                            headers={'x-csrftoken':  csrf}),
            fetch_schema_from_transport=True
        ) 
def __init__(self, name, site='https://roll20.net/compendium/dnd5e/'):
        self.name = name.rstrip().title()
        formatted_name = self.name.replace(' ', '_')
        url = site + formatted_name
        page = requests.get(url)
        if page.status_code != 200:
            raise IOError('{:s} not found at {:s}.'.format(name,
                                                           url))
        if 'marketplace' in page.url:
              raise IOError('{:s} not found at {:s}, '
                            'likely because this content is behind a paywall. '
                            'Encourage developer to add alternative back-ends to Roll20'.format(name, url))
        html = page.text
        soup = bs(html, 'html.parser')
        self.attributes = ({stringify(a.text):
                            stringify(a.find_next(attrs={'class':
                                                         'value'}).text)
                            for a in soup.find_all(attrs={'class':
                                                          'col-md-3 attrName'})})
        self.desc = '\n'.join([stringify(val.text)
                               for val in soup.find_all(id='origpagecontent',
                                                        attrs={'type':
                                                               'text/html'})]) 
def str_attributes(self):
        res = ''
        for k in ['HP', 'AC', 'Speed', 'Challenge Rating']:
            res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        res += '\n'
        for k in ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA']:
            res += k + '\t'
        res += '\n'
        for k in ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA']:
            s = self.get(k, None)
            res += '{:s} ({:s})\t'.format(s, score_to_mod(int(s)))
        res += '\n\n'
        for k in ['Type', 'Size', 'Alignment', 'Senses', 'Skills',
                  'Languages']:
            res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        return res 
def as_dungeonsheets_class(self):
        spell_name = self.name
        class_name = spell_name.replace(' ', '').replace('-', '')
        res = 'class {:s}(Spell):\n'.format(class_name)
        res += "    \"\"\"{:s}\n    \"\"\"\n".format(self.desc.replace('\n', '\n    '))
        res += "    name = \"{:s}\"\n".format(spell_name)
        res += "    level = {:d}\n".format(int(self.get('Level', -1)))
        res += "    casting_time = \"{:s}\"\n".format(self.get('Casting Time', '1 action'))
        res += "    casting_range = \"{:s}\"\n".format(self.get('Range', ''))
        str_components = self.get('Components', '').upper().split(' ')
        if len(str_components) == 0:
            res += "    components = ()\n"
        else:
            res += "    components = {:s}\n".format(str(tuple(str_components)))
        res += "    materials = \"\"\"{:s}\"\"\"\n".format(self.get('Material', ''))
        dur_text = "\"{:s}\"\n".format(self.get('Duration', 'Instantaneous'))
        dur_text = ("\"Concentration, {:s}".format(dur_text.lstrip('\"')) if
                    self.get('Concentration', '') else dur_text)
        duration = "    duration = " + dur_text
        res += duration
        res += "    ritual = {:}\n".format(bool(self.get('Ritual', '')))
        res += "    magic_school = \"{:s}\"\n".format(self.get('School', ''))
        res += "    classes = {:s}\n".format(str(tuple(self.get('Classes', '').split(', '))))
        return res + "\n" 
def get_vmprofiles(self):
        url = 'https://%s/php/vmprofiles.php' % self.atdserver

        try:
            r = requests.get(url, headers=self.sessionhdr, verify=False)
        except Exception as e:
            error_info = 'Error getting vmprofiles:\n%s' % e
            return(0, error_info)

        if r.status_code == 200:
            server_info = json.loads(r.content)

            if server_info['success'] is True:
                return (1, server_info['results'])

            else:
                error_info = 'Error getting vmprofiles, check credentials or content type header'
                return (0, error_info)
        else:
            error_info = 'Error getting vmprofiles, status code: %d' % r.status_code
            return (0, error_info) 
def getNetworkDevices(ticket):
    # URL for network device REST API call to get list of existing devices on the network.
    url = "https://" + controller + "/api/v1/network-device"

    #Content type must be included in the header as well as the ticket
    header = {"content-type": "application/json", "X-Auth-Token":ticket}

    # this statement performs a GET on the specified network-device url
    response = requests.get(url, headers=header, verify=False)

    # json.dumps serializes the json into a string and allows us to
    # print the response in a 'pretty' format with indentation etc.
    print ("Network Devices = ")
    print (json.dumps(response.json(), indent=4, separators=(',', ': ')))

  #convert data to json format.
    r_json=response.json()

  #Iterate through network device data and print the id and series name of each device
    for i in r_json["response"]:
        print(i["id"] + "   " + i["series"])

#call the functions 
def __call__(self, client, dnode):
        logger.info('Caculating time for download first byte...')
        r = requests.get('http://{}'.format(dnode), stream=True)
        total_length = int(r.headers.get('content-length'))
        if total_length is None:
            logger.info("empty file!")
        else:
            start_chunk = time.clock()
            for chunk in r.iter_content(1024):  # 1kB1024 1MB 1048576
                end_chunk = time.clock()
                break

            delta = end_chunk - start_chunk  # time to first byte
            yield from self._queue.put(self.get_result(dnode, delta)) 
def get_client_id():
    r = requests.get(CDN_BASE + 'global.js')
    if r.status_code >= 400:
        raise Exception('Error fetching global.js script.')

    # Find the client ID with a regex that totally wont match anything else /s
    client_ids = re.findall(r'clientID:"(\w*)"', r.text)
    if len(client_ids) != 1:
        raise Exception(
            'Error finding client ID in twitch global-frontend script. Got {}'.format(client_ids))
    return client_ids[0] 
def get_token_and_signature(channel, client_id):
    url = TOKEN_API.format(channel=channel)
    headers = {'Client-ID': client_id}
    r = requests.get(url, headers=headers)
    if r.status_code >= 400:
        raise Exception('Error requesting token from twitch: {}'.format(r.text))
    data = r.json()
    return data['token'], data['sig'] 
def get_live_stream(channel):
    client_id = get_client_id()
    token, sig = get_token_and_signature(channel, client_id)
    url = USHER_API.format(channel=channel, sig=sig, token=token, random=random.randint(0, 1E7))
    r = requests.get(url)
    m3u8_obj = m3u8.loads(r.text)
    return m3u8_obj 
def get_api_data(self):
        """
        Gets json file containing server information

        :return: server information in json format
        """
        try:
            resp = requests.get(api, timeout=5)
            if resp.status_code == requests.codes.ok:
                return resp.json()
            else:
                self.statusbar.showMessage("Get API failed", 2000)
        except Exception as ex:
            self.statusbar.showMessage("Get API failed", 2000) 
def get_ovpn(self):
        """
        Gets ovpn file from nord servers and saves it to a temporary location
        """
        # https://downloads.nordcdn.com/configs/files/ovpn_udp/servers/sg173.nordvpn.com.udp.ovpn
        self.ovpn_path = None
        ovpn_url = None
        udp_url = 'https://downloads.nordcdn.com/configs/files/ovpn_udp/servers/'
        tcp_url = 'https://downloads.nordcdn.com/configs/files/ovpn_tcp/servers/'
        udp_xor_url = 'https://downloads.nordcdn.com/configs/files/ovpn_xor_udp/servers/'
        tcp_xor_url = 'https://downloads.nordcdn.com/configs/files/ovpn_xor_tcp/servers/'

        if (self.server_type_select.currentText() == 'Obfuscated Server') and (self.connection_type_select.currentText() == 'UDP'):
            ovpn_url = udp_xor_url
        elif (self.server_type_select.currentText() == 'Obfuscated Server') and (self.connection_type_select.currentText() == 'TCP'):
            ovpn_url = tcp_xor_url
        elif (self.server_type_select.currentText() != 'Obfuscated Server') and (self.connection_type_select.currentText() == 'UDP'):
            ovpn_url = udp_url
        elif (self.server_type_select.currentText() != 'Obfuscated Server') and (self.connection_type_select.currentText() == 'TCP'):
            ovpn_url = tcp_url

        if self.connection_type_select.currentText() == 'UDP':
            filename = self.domain_list[self.server_list.currentRow()] + '.udp.ovpn'
            ovpn_file = requests.get(ovpn_url + filename, stream=True)
            if ovpn_file.status_code == requests.codes.ok:
                self.ovpn_path = os.path.join(self.config_path, filename)
                with open(self.ovpn_path, 'wb') as out_file:
                    shutil.copyfileobj(ovpn_file.raw, out_file)
            else: self.statusbar.showMessage('Error fetching configuration files', 2000)

        elif self.connection_type_select.currentText() == 'TCP':
            filename = self.domain_list[self.server_list.currentRow()] + '.tcp.ovpn'
            ovpn_file = requests.get(ovpn_url + filename, stream=True)
            if ovpn_file.status_code == requests.codes.ok:
                self.ovpn_path = os.path.join(self.config_path, filename)
                with open(self.ovpn_path, 'wb') as out_file:
                    shutil.copyfileobj(ovpn_file.raw, out_file)
            else: self.statusbar.showMessage('Error fetching configuration files', 2000)

        self.server_list.setFocus() 
def updateFactorio():
	

	file_name = "/tmp/latestFactorio.tar.gz"
	print("Downloading %s" % file_name)

	r = requests.get(DOWNLOADURL, stream=True)
	total_length = int(r.headers.get('content-length'))

	if not os.path.isfile(file_name) or total_length != os.path.getsize(file_name):
		with open(file_name, 'wb') as f:
			for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length/1024) + 1): 
				if chunk:
					f.write(chunk)
					f.flush()
			#os.chmod(file_name, stat.S_IWUSR | stat.S_IRUSR)
	else:
		print("File already exists and file sizes match. Skipping download.")	

	if os.access(FACTORIOPATH, os.W_OK):
		if os.path.isfile(file_name):
			tar = tarfile.open(file_name, "r:gz")
			tar.extractall(path="/tmp")
			tar.close()

			copytree("/tmp/factorio", FACTORIOPATH)
			print("Success.")
		else:
			print("Help! Can't find %s, but I should have!" % (file_name))
			sys.exit(1)			
	else:
		print("Can't write to %s" % (FACTORIOPATH))
		sys.exit(1) 
def get_dict_optional_value(d,keys_to_try_in_order, default_value=None):
    """
    Tries each key in order, if not value is found, returns default_value
    """
    
    for key in keys_to_try_in_order:
        if key in d and d.get(key):
            return d[key]
        
    return default_value 
def get_melting_temp(dna_sequence, oligo_concentration_uM,
                     pcr_settings='q5'):
    global IDT_COOKIE
    
    #@TODO: update this to use http://tmcalculator.neb.com/#!/ since its probably accounting for the salt concentration in the buffer
    
    if not IDT_COOKIE:
        r = requests.get('http://www.idtdna.com/calc/analyzer',allow_redirects=False)
        IDT_COOKIE = r.cookies['ASP.NET_SessionId']       
        
    headers = {"content-type":'application/json','Cookie':'ASP.NET_SessionId=%s'%IDT_COOKIE}
    
    idt_response = requests.post('https://www.idtdna.com/calc/analyzer/home/analyze',json={
        "settings": {
            "Sequence": dna_sequence,
            "NaConc": 0,
            "MgConc": 2,
            "DNTPsConc": 5, 
            "OligoConc": oligo_concentration_uM,
            "NucleotideType": "DNA"
        }
    }, verify=False
    ,headers=headers)    
    
    idt_response.raise_for_status()
    
    return idt_response.json()['MeltTemp'] 
def do(self):
        # logging.debug("{} {}: \n\tHeaders {}, \n\tData {}, \n\tParams {}, \n\tOther: {}".format(
        #     self.method.upper(), self.url, self.headers,
        #     self.data, self.params, self.kwargs
        # ))
        result = self.methods.get(self.method)(
            url=self.url, headers=self.headers,
            data=self.data, params=self.params,
            **self.kwargs
        )
        return result 
def do(self, api_name=None, pk=None, method='get', use_auth=True,
           data=None, params=None, content_type='application/json', **kwargs):

        if api_name in API_URL_MAPPING:
            path = API_URL_MAPPING.get(api_name)
            if pk and '%s' in path:
                path = path % pk
        else:
            path = api_name

        request_headers = kwargs.get('headers', {})
        default_headers = self.default_headers or {}
        headers = {k: v for k, v in default_headers.items()}
        headers.update(request_headers)
        kwargs['headers'] = headers
        url = self.endpoint.rstrip('/') + path
        req = HttpRequest(url, method=method, data=data,
                          params=params, content_type=content_type,
                          **kwargs)
        if use_auth:
            if not self.auth:
                msg = 'Authentication required, but not provide'
                logger.error(msg)
                raise RequestError(msg)
            else:
                self.auth.sign_request(req)

        try:
            resp = req.do()
        except (requests.ConnectionError, requests.ConnectTimeout) as e:
            msg = "Connect endpoint {} error: {}".format(self.endpoint, e)
            logger.error(msg)
            raise RequestError(msg)

        return self.clean_result(resp) 
def get(self, *args, **kwargs):
        kwargs['method'] = 'get'
        return self.do(*args, **kwargs) 
def create_record(self, dns_type, name, content, **kwargs):
        """
        Create a dns record
        :param dns_type:
        :param name:
        :param content:
        :param kwargs:
        :return:
        """
        data = {
            'type': dns_type,
            'name': name,
            'content': content
        }
        if kwargs.get('ttl') and kwargs['ttl'] != 1:
            data['ttl'] = kwargs['ttl']
        if kwargs.get('proxied') is True:
            data['proxied'] = True
        else:
            data['proxied'] = False
        content = self.request(
            self.api_url + self.zone['id'] + '/dns_records',
            'post',
            data=data
        )
        print('DNS record successfully created')
        return content['result'] 
def update_record(self, dns_type, name, content, **kwargs):
        """
        Update dns record
        :param dns_type:
        :param name:
        :param content:
        :param kwargs:
        :return:
        """
        record = self.get_record(dns_type, name)
        data = {
            'type': dns_type,
            'name': name,
            'content': content
        }
        if kwargs.get('ttl') and kwargs['ttl'] != 1:
            data['ttl'] = kwargs['ttl']
        if kwargs.get('proxied') is True:
            data['proxied'] = True
        else:
            data['proxied'] = False
        content = self.request(
            urllib.parse.urljoin(self.api_url, self.zone['id'] + '/dns_records/' + record['id']),
            'put',
            data=data
        )
        print('DNS record successfully updated')
        return content['result'] 
def search(self, type, q, territory='TW'):
        response = requests.get(self.API_BASE_URL + 'search', params={'type': type, 'q': q, 'territory': territory},
                                headers={'Authorization': 'Bearer ' + self.token})
        response.raise_for_status()
        response_json = response.json()

        if type == 'artist':
            return response_json['artists']['data'][0]['url']
        else:
            id = response_json[type + 's']['data'][0]['id']
            return 'https://widget.kkbox.com/v1/?id=' + id \
                   + '&type=' + ('song' if type == 'track' else type) 
def _get_cache_stale_secs(cache_stale=None):
    # overrides config
    caching_val = config.CONFIG.parser.get('cache', 'normal')
    if caching_val in ('never', 'false', 'False', 'off', 'Off'):
        return 0
    if caching_val in ('test', 'forever'):
        return CACHE_FOREVER
    if cache_stale is None:
        return 0
    return cache_stale 
def request_json(url, output_filename=None, cache_stale=None):
    """Sends a request expecting a json-formatted response.
    If output_filename is given, then the output is saved to file.
    This also enables basic caching, where cache_stale is the number of seconds
    since file is last modified before the cached file is considered stale (0 means disable the cache).
    """
    cache_stale = _get_cache_stale_secs(cache_stale)
    # Guard against very long filenames:
    if output_filename and len(output_filename) >= MAX_CACHE_FILENAME_LEN:
        output_filename = output_filename[0:MAX_CACHE_FILENAME_LEN-1]
    if output_filename and cache_stale:
        if output_filename in CACHE:
            return CACHE[output_filename]
        json_file = os.path.join(_get_cachedir(), '{}.json'.format(output_filename))
        if os.path.exists(json_file) and (int(time.time()) - os.path.getmtime(json_file) < cache_stale):
            with open(json_file) as jfh:
                CACHE[output_filename] = json.load(jfh)
            if config.DEBUG:
                LOG.info('Loaded from cache: %s', output_filename)
            return CACHE[output_filename]

    LOG.debug('Getting url=%s ...', url)
    headers = {
        'User-Agent': config.CONFIG.ua_iphone,
        'Connection': 'close'
    }
    util.log_http(url, 'get', headers, sys._getframe().f_code.co_name)
    response = requests.get(url, headers=headers, verify=config.VERIFY_SSL)
    response.raise_for_status()

    # Note: this fails on windows in some cases https://github.com/kennethreitz/requests-html/issues/171
    if output_filename is not None or (config.DEBUG and config.SAVE_JSON_FILE):
        json_file = os.path.join(_get_cachedir(), '{}.json'.format(output_filename))
        with open(json_file, 'w', encoding='utf-8') as out:  # write date to json_file
            out.write(response.text)
    if cache_stale:
        LOG.debug('Caching url=%s, filename=%s', url, output_filename)
        CACHE[output_filename] = response.json()
        return CACHE[output_filename]
    return response.json() 
def get_attrib(self, et_node, prefixed_attrib):
        """Get a prefixed attribute like 'rdf:resource' from ET node."""
        prefix, attrib = prefixed_attrib.split(':')
        return et_node.get('{{{0}}}{1}'.format(self.namespaces[prefix],
                                               attrib)) 
def __init__(self, namespaces=None, cc_resolver=None, source=None):
        """Init the remote loader."""
        super(RemoteFundRefLoader, self).__init__(
            namespaces=namespaces, cc_resolver=cc_resolver)
        self.source = source or \
            current_app.config['OPENAIRE_FUNDREF_ENDPOINT']
        headers = {"Content-Type": "application/rdf+xml"}
        obj = requests.get(self.source, stream=True, headers=headers)
        funders_xml = obj.text.encode('utf-8')
        self.doc_root = ET.fromstring(funders_xml) 
def resolve_by_id(self, funder_id):
        """Resolve the funder from the OpenAIRE funder id.

        If funder_id can be resolved, return a URI otherwise return None.
        """
        return self.data.get(funder_id) 
def resolve_by_oai_id(self, oai_id):
        """Resolve the funder from the OpenAIRE OAI record id.

        Hack for when funder is not provided in OpenAIRE.
        """
        if oai_id.startswith('oai:dnet:'):
            oai_id = oai_id[len('oai:dnet:'):]
        prefix = oai_id.split("::")[0]
        suffix = prefix.replace("_", "").upper()
        oaf = "{0}::{1}".format(prefix, suffix)
        return self.data.get(oaf) 
def resolve_by_doi(self, doi):
        """Resolve a DOI to an OpenAIRE id."""
        return self.inverse_data.get(doi) 
def forward(self, text):

        '''
        In PyTorch RNNs want the input with batch dim second, CNNs want the batch dim first
        we permute the input to make it the right shape for the CNN
        '''
        text = text.permute(1, 0)

        # Text passed through embedding layer to get embeddings
        embedded = self.embedding(text)

        '''
        A conv layer wants the second dim of the input to be a channel dim
        text does not have a channel dim, so the tensor is unsqueezed to create one
        '''
        embedded = embedded.unsqueeze(1)

        # Iterates through the list of conv layers applying each conv layer to get list of conv outputs
        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]

        '''
        Conv outputs are passed through a max pooling that takes the maximum value over a dimension
        the idea being that the "maximum value" is the most important feature for determining the sentiment
        which corresponds to the most important n-gram in the review
        '''
        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]

        '''
        The model has 100 filters of 3 different sizes, therefore 300 n-grams that could be important
        which we concatenate into a single vector and pass through a dropout layer and finally a linear layer
        (NOTE: dropout is set to 0 during inference time)
        '''
        cat = self.dropout(torch.cat(pooled, dim = 1))

        # passed through linear layer to make predictions
        return self.fc(cat) 
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
def nodeLatestVersion(dependency, project_id):
    r = requests.get('%s%s/latest' % (app.config['NPM_REGISTRY'], dependency))
    latestVersion = r.json().get('version')

    try:
        dep = ProjectDependency.by_project(project_id, dependency)
        dep.latest_version = latestVersion
        if LooseVersion(dep.actual_version) < LooseVersion(latestVersion):
            dep.status = 'ko'
        else:
            dep.status = 'ok'
        db.session.commit()
    except Exception, e:
        app.logger.error(e)
        db.session.rollback() 
def nodeDepsFetcher(project_id):
    # Get dependencies from package.json
    project = git.getproject(project_id)

    depFileEncoded = git.getfile(project_id, 'package.json',
                                 project['default_branch'])

    # Decode from base64
    deps = json.loads(depFileEncoded.get('content').decode('base64'))

    mainDeps = deps.get('dependencies')
    devDeps = deps.get('devDependencies')

    # Insert in project_dependency
    # TODO create single function for that
    for mDep, mVersion in list(mainDeps.items()):
        mdep, created = get_or_create(db.session, ProjectDependency,
                                      project_id=project_id, name=mDep,
                                      actual_version=mVersion)

        if not created:
            app.logger.info('[%s] Dep %s already exist' % (project_id, mDep))

        db.session.commit()
        nodeLatestVersion(mDep, project_id)

    for devDep, devVersion in list(devDeps.items()):
        ddep, created = get_or_create(db.session, ProjectDependency,
                                      project_id=project_id, name=devDep,
                                      actual_version=devVersion, dev=True)

        if not created:
            app.logger.info('[%s] Dev dep %s already exist' %
                            (project_id, devDep))

        db.session.commit()
        nodeLatestVersion(devDep, project_id)
    return True 
**************************************************


Python requests.post() Examples

def getTicket():
    # put the ip address or dns of your apic-em controller in this url
    url = "https://" + controller + "/api/v1/ticket"

    #the username and password to access the APIC-EM Controller
    payload = {"username":"usernae","password":"password"}

    #Content type must be included in the header
    header = {"content-type": "application/json"}

    #Performs a POST on the specified url to get the service ticket
    response= requests.post(url,data=json.dumps(payload), headers=header, verify=False)

    #convert response to json format
    r_json=response.json()

    #parse the json to get the service ticket
    ticket = r_json["response"]["serviceTicket"]

    return ticket 
def bindiff_export(self, sample, is_64_bit = True, timeout = None):
        """
        Load a sample into IDA Pro, perform autoanalysis and export a BinDiff database.
        :param sample: The sample's path
        :param is_64_bit: If the sample needs to be analyzed by the 64 bit version of IDA
        :param timeout: Timeout for the analysis in seconds
        :return: The file name of the exported bindiff database. The file needs
        to be deleted by the caller. Returns None on error.
        """

        data_to_send = {
            "timeout": timeout,
            "is_64_bit": is_64_bit}
        url = "%s/binexport" % next(self._urls)
        log.debug("curl -XPOST --data '%s' '%s'", json.dumps(data_to_send), url)
        response = requests.post(url, data = data_to_send, files = {os.path.basename(sample): open(sample, "rb")})
        if response.status_code == 200:
            handle, output = tempfile.mkstemp(suffix = ".BinExport")
            with os.fdopen(handle, "wb") as f:
                map(f.write, response.iter_content(1024))
            return output
        else:
            log.error("Bindiff server responded with status code %d: %s", response.status_code, response.content)
            return None 
def answer_ponies(query_id, results, timed_out):
    result = requests.post(
        "https://api.telegram.org/bot{}/answerInlineQuery".format(settings.TELEGRAM_TOKEN),
        headers={"Content-Type": "application/json"},
        json={
            'inline_query_id': query_id,
            'cache_time': settings.CACHE_TIME if timed_out == 0 else settings.PARTIAL_RESULT_CACHE_TIME,
            'is_personal': False,
            'results': [
                {
                    'type': 'mpeg4_gif',
                    'id': url,
                    'mpeg4_url': url,
                    'thumb_url': thumb,
                    'mpeg4_width': dimensions[0],
                    'mpeg4_height': dimensions[1],
                } for url, thumb, id_number, dimensions in results
            ]
        })
    print(result.content)
    result.raise_for_status() 
def processfile(inputfile, serverurl):
    headers = {'content-type': 'application/json'}
    try:
        with open(inputfile) as json_file:

            file_data = json_file.read()
            file_data = file_data.replace("\n", "")

            print(json.dumps(file_data, sort_keys=True, indent=4, separators=(',', ': ')))
            try:
                r = requests.post(serverurl, data=file_data, headers=headers, timeout=5)
            except Exception as err:

                print("COMMUNICATION ERROR : " + format(err))
                sys.exit(2)
    except Exception as err:
        print("File ERROR : " + format(err))

        return False

    print (inputfile + " sent to " + serverurl + ". Status code: " + str(r.status_code) + ".")

    return True 
def sendNotification(url, msg):
    """Send a notification using a Slack webhook URL. See https://api.slack.com/incoming-webhooks

    Arguments:
        url (string): Slack incoming webhook URL for sending the message.
        msg (string): The message to be sent (can use markdown for formatting)
    """
    try:
        res = requests.post(url, data=json.dumps(
            {"text": msg, "mrkdwn": True}))
        if res.status_code != 200:
            print(f'Falied to send notification "{msg}" to "{url}"')
            print('Response', res.content)
            return False
    except Exception as e:
        print(f'Falied to send notification "{msg}" to "{url}"')
        print(e)
        return False
    return True 
def fj_login(name=USERNAME, password=PASSWORD, email_mode=False, _print=False):
    ''' ([str, str, bool, bool]) -> dict
    name: your username. If email_mode == True, your email address
    password: your password
    email_mode: whether name is your email or username
    _print: debug

    returns authentication information'''
    
    if email_mode:
        url = 'https://account.freejamgames.com/api/authenticate/email/web'
        body_json = {'EmailAddress':name, 'Password':password}
        response = requests.post(url, json=body_json)
    else:
        url = 'https://account.freejamgames.com/api/authenticate/displayname/web'
        body_json = {'DisplayName':name, 'Password':password}
        response = requests.post(url, json=body_json)
    if response.status_code != 200:
        if _print:
            print('FJ Auth returned error', response.status_code)
    return response.json() 
def pickle_export(self, sample, is_64_bit = True, timeout = None):
        """
        Load a sample into IDA Pro, perform autoanalysis and export a pickle file. 
        :param sample: The sample's path
        :param is_64_bit: If the sample needs to be analyzed by the 64 bit version of IDA
        :param timeout: Timeout for the analysis in seconds
        :return: The file name of the exported pickle database. The file needs
        to be deleted by the caller. Returns None on error.
        """

        data_to_send = {
            "timeout": timeout,
            "is_64_bit": is_64_bit}
        url = "%s/pickle" % next(self._urls)
        log.debug("curl -XPOST --data '%s' '%s'", json.dumps(data_to_send), url)
        response = requests.post(url, data = data_to_send, files = {os.path.basename(sample): open(sample, "rb")})
        if response.status_code == 200:
            handle, output = tempfile.mkstemp(suffix = ".pickle")
            with os.fdopen(handle, "wb") as f:
                map(f.write, response.iter_content(1024))
            return output
        else:
            log.error("Bindiff server responded with status code %d: %s", response.status_code, response.content)
            return None 
def compare(self, primary, secondary, timeout = None):
        """
        Run BinDiff on the two BinDiff databases.
        :param primary: The first BinExport database
        :param secondary: The second BinExport database
        :param timeout: Timeout for the command in seconds
        :returns: The directory name of the directory with the generated data on the shared volume
        """

        url = "%s/compare" % next(self._urls)
        log.debug("curl -XPOST --form 'timeout=%s' --form '[email protected]%s' --form '[email protected]%s' '%s'", str(timeout), primary, secondary, url)
        response = requests.post(url, data = {"timeout": timeout}, \
                files = {"primary": open(primary, "rb"), "secondary": open(secondary, "rb")})

        if response.status_code == 200:
            handle, path = tempfile.mkstemp(suffix = ".bindiff.sqlite3")
            with os.fdopen(handle, "wb") as f:
                map(f.write, response.iter_content(1024))
            return path
        else:
            log.error("Bindiff server responded with status code %d: %s", response.status_code, response.content)
            return None 
def apply_configuration():
    applyConfigurationResponse = requests.post(applyConfigurationURI, 
        headers={
            'Authorization': iotHubSasToken,
            'Content-Type': 'application/json'
        },
        data = get_config_file_contents()
    )

    print(applyConfigurationURI)
    print(applyConfigurationResponse.status_code)
    print(applyConfigurationResponse.text)

    if applyConfigurationResponse.status_code == 204:
        print("Configuration successfully applied.  Please run `docker logs edgeAgent -f` to see the change applied.")
    else:
        print("There was an error applying the configuration. You should see an error message above that indicates the issue.") 
def convert_to_mp4(url):
    cached = check_pony_cache(url)
    if cached is not None:
        return cached
    print("Converting {} to mp4...".format(url))
    result = requests.post("https://api.imgur.com/3/image", {
        "image": url,
        "type": "URL"
    }, headers={
        'Authorization': 'Client-ID {}'.format(settings.IMGUR_TOKEN),
        'Content-Type': 'application/x-www-form-urlencoded',
    })
    try:
        result.raise_for_status()
    except requests.HTTPError as e:
        print(e.response.content)
        return None
    mp4_url = result.json()['data'].get('mp4', None)
    if mp4_url is not None:
        cache_pony(url, mp4_url)
    return mp4_url 
def sendToCityIO(data, endpoint=-1, token=None):
    config = get_config()
    if endpoint == -1 or endpoint == None:
        post_address = config['CITY_SCOPE']['TABLE_URL_RESULT_POST'] # default endpoint
    else:
        post_address = json.loads(config['CITY_SCOPE']['TABLE_URL_RESULT_POST_LIST'])[endpoint] # user endpoint

    if token is None:
        r = requests.post(post_address, json=data, headers={'Content-Type': 'application/json'})
    else: # with authentication
        r = requests.post(post_address, json=data, headers={'Content-Type': 'application/json', 'Authorization': 'Bearer '+token})
    print(r)
    if not r.status_code == 200:
        print("could not post result to cityIO", post_address)
        print("Error code", r.status_code)
    else:
        print("Successfully posted to cityIO", post_address, r.status_code)

# checks for updates on the cityIO grid
# If the grid changes the city-scope parser is called to create a new buildings.json
# The noise calculation is triggered 
def __card_login(self):
        card_url = 'https://pass.neu.edu.cn/tpass/login?service=http://ecard.neu.edu.cn/selflogin/login.aspx'
        response = requests.get(card_url, cookies=self.pass_cookies, proxies=proxies['index'])

        data = {
            'username': re.findall("<input type=hidden name='username' id='username' value='(.*?)'/>", response.text)[
                0],
            'timestamp':
                re.findall("<input type=hidden name='timestamp' id='timestamp' value='(.*?)'/>", response.text)[0],
            'auid': re.findall("<input type=hidden name='auid' id='auid' value='(.*?)'/>", response.text)[0]
        }

        get_session = requests.post('http://ecard.neu.edu.cn/selfsearch/SSOLogin.aspx',
                                    cookies=response.cookies,
                                    data=data,
                                    headers=self.__headers,
                                    proxies=proxies['card'])

        self.card_cookies = {
            '.ASPXAUTSSM': get_session.history[0].cookies['.ASPXAUTSSM'],
            'ASP.NET_SessionId': response.cookies['ASP.NET_SessionId']
        }

    # 通过一网通办登陆教务处，私有方法 
def borrow_info(self):
        post_url = 'https://portal.neu.edu.cn/tp_up/up/subgroup/getLibraryInfo'
        my_headers = {
            'Referer': 'https://portal.neu.edu.cn/tp_up/view?m=up',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36',
            'Origin': 'https://portal.neu.edu.cn',
            'Content-Type': 'application/json;charset=UTF-8'
        }
        response = requests.post(post_url,
                                headers=my_headers,
                                cookies=self.index_cookies,
                                data='{}',
                                proxies=proxies['index'])
        return response.json()


    # 卡是否挂失 
def _get_song_lyrics(self, song):
        lyric_url = "https://music.163.com/weapi/song/lyric"
        raw_data = {
            "csrf_token": "",
            "id": song.id,
            "lv": -1,
            "tv": -1
        }
        post_data = get_encrypted_post_data(raw_data)
        r = requests.post(lyric_url, data=post_data, headers=self.headers)
        json_data = r.json()

        lyric = ""
        if "lrc" in json_data and "lyric" in json_data["lrc"]:
            lyric = json_data["lrc"]["lyric"]

        return lyric 
def new_post(self, text):

        header = {
            "Content-Type": "application/json",
            "User-Agent" : self.UA,
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "postInfo" : { "readPermission" : { "type" : "ALL" } },
            "sourceType" : "TIMELINE",
            "contents" : { "text" : text }
        }

        r = requests.post(
            "http://" + self.host + "/mh/api/v24/post/create.json",
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
def postPhoto(self,text,path):
        header = {
            "Content-Type": "application/json",
            "User-Agent" : self.UA,
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "postInfo" : { "readPermission" : { "type" : "ALL" } },
            "sourceType" : "TIMELINE",
            "contents" : { "text" : text ,"media" :  [{u'objectId': u'F57144CF9ECC4AD2E162E68554D1A8BD1a1ab0t04ff07f6'}]}
        }
        r = requests.post(
            "http://" + self.host + "/mh/api/v24/post/create.json",
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
def like(self, mid, postid, likeType=1001):

        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "likeType" : likeType,
            "activityExternalId" : postid,
            "actorId" : mid
        }

        r = requests.post(
            "http://" + self.host + "/mh/api/v23/like/create.json?homeId=" + mid,
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
def comment(self, mid, postid, text):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "commentText" : text,
            "activityExternalId" : postid,
            "actorId" : mid
        }

        r = requests.post(
            "http://" + self.host + "/mh/api/v23/comment/create.json?homeId=" + mid,
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
def createAlbum(self,gid,name):
        header = {
                    "Content-Type": "application/json",
                    "User-Agent" : self.UA,
                    "X-Line-Mid" : self.mid,
                    "x-lct" : self.channel_access_token,
        }
        payload = {
                "type" : "image",
                "title" : name
        }
        r = requests.post(
            "http://" + self.host + "/mh/album/v3/album?count=1&auto=0&homeId=" + gid,
            headers = header,
            data = json.dumps(payload)
        )
        return r.json() 
def querylanguage(auth):
    """Query user's language that's available on v2c."""
    default = 'en'

    r = requests.post(
        url=api_url.replace('index.php', 'api.php'),
        data={
            'action': 'query',
            'format': 'json',
            'meta': 'userinfo',
            'uiprop': 'options'
        },
        auth=auth
    )

    try:
        language = r.json()['query']['userinfo']['options']['language']
    except (NameError, KeyError):
        return default

    if not language:
        return default

    return language 
def configAuthenticate(username, password):
	FACTORIOPATH = getFactorioPath()

	url = "https://auth.factorio.com/api-login"
	params = {'username': username, 'password': password, 'apiVersion': 2}


	if not os.path.isfile("%s/bin/x64/factorio" % (FACTORIOPATH) ):
		print("Could not find factorio at %s" % (FACTORIOPATH))
		sys.exit(1)


	print("Fetching token for %s" %  (username))
	myResponse = requests.post(url,data=params, verify=True)
	if(myResponse.ok):

	    jData = json.loads(myResponse.text)
	    print("Writing %s to settings.json" % (jData[0]))
	    
	else:
	  # If response code is not ok (200), print the resulting http error code with description
	    myResponse.raise_for_status()
	    sys.exit(1)
	

	try:
		with codecs.open(getSettingsFile(), 'r', encoding='utf-8') as settings_file:
			settingsJson = json.load(settings_file)
			settingsJson['token'] = jData[0]
			settingsJson['username'] = username
				


		with codecs.open("%s/config/settings.json" % (FACTORIOPATH), 'w', encoding='utf-8') as settings_file:
			json.dump(settingsJson, settings_file, indent=4)
	except Exception as e:
		print(e)
		print("Help! Can't deal with the settings file!") 
def get_melting_temp(dna_sequence, oligo_concentration_uM,
                     pcr_settings='q5'):
    global IDT_COOKIE
    
    #@TODO: update this to use http://tmcalculator.neb.com/#!/ since its probably accounting for the salt concentration in the buffer
    
    if not IDT_COOKIE:
        r = requests.get('http://www.idtdna.com/calc/analyzer',allow_redirects=False)
        IDT_COOKIE = r.cookies['ASP.NET_SessionId']       
        
    headers = {"content-type":'application/json','Cookie':'ASP.NET_SessionId=%s'%IDT_COOKIE}
    
    idt_response = requests.post('https://www.idtdna.com/calc/analyzer/home/analyze',json={
        "settings": {
            "Sequence": dna_sequence,
            "NaConc": 0,
            "MgConc": 2,
            "DNTPsConc": 5, 
            "OligoConc": oligo_concentration_uM,
            "NucleotideType": "DNA"
        }
    }, verify=False
    ,headers=headers)    
    
    idt_response.raise_for_status()
    
    return idt_response.json()['MeltTemp'] 
def post(self, *args, **kwargs):
        kwargs['method'] = 'post'
        return self.do(*args, **kwargs) 
def _get_token(self):
        response = requests.post(self.AUTH_URL, data={'grant_type': 'client_credentials'}, auth=(self.id, self.secret))
        response.raise_for_status()
        return response.json()['access_token'] 
def nli(self, text, cusid=None):
        response = requests.post(self.URL, params=self._gen_parameters('nli', text, cusid))
        response.raise_for_status()
        response_json = response.json()
        if response_json['status'] != 'ok':
            raise NliStatusError("NLI responded status != 'ok': {}".format(response_json['status']))
        else:
            nli_obj = response_json['data']['nli'][0]
            return self.intent_detection(nli_obj) 
def _isAsthamaPump(self, imageWidth, imageHeight, imageString):
        result = {}
        coordinates = {}
        metadata = {}
        isPresent = False

        try :
            self._printLogs("Sending Image To DL Server...", "NORMAL")

            url = DL_SERVER_URL
            payload = {
                        "imageWidth"   : imageWidth,
                        "imageHeight"  : imageHeight,
                        "image_string" : base64.b64encode(imageString),
                        "imageID"      : self.imageNo2d
                        }
            headers = {'content-type': 'application/json'}

            res = requests.post(url, data=json.dumps(payload), headers=headers)
            result = res.json()
            self._printLogs("[*] Sent to  : " + str(url), "OKBLUE")
            self._printLogs("[*] Response : " + str(result), "OKBLUE")

        except Exception, err:
            self._printLogs("Error Found on connecting to server : " + str(err), "FAIL")
            self._printLogs("+", "LINE") 
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
def execute(self, document, variable_values=None, timeout=None):
        query_str = print_ast(document)
        payload = {
            'query': query_str,
            'variables': variable_values or {}
        }

        data_key = 'json' if self.use_json else 'data'
        post_args = {
            'headers': self.headers,
            'auth': self.auth,
            'cookies': self.cookies,
            'timeout': timeout or self.default_timeout,
            data_key: payload
        }
        request = requests.post(self.url, **post_args)
        request.raise_for_status()

        result = request.json()
        assert 'errors' in result or 'data' in result, 'Received non-compatible response "{}"'.format(result)
        return ExecutionResult(
            errors=result.get('errors'),
            data=result.get('data')
        ) 
def main():
    module = AnsibleModule(
      argument_spec = dict(
        host = dict(required=True),
        username = dict(required=True),
        password = dict(required=True)
      )
    )
    
    device = module.params.get('host')
    username = module.params.get('username')
    password = module.params.get('password')

    url='http://' + host + '/ins'
    switchuser=username
    switchpassword=password

    myheaders={'content-type':'application/json-rpc'}
    
    payload=[
      {
        "jsonrpc": "2.0",
        "method": "cli",
        "params": {
          "cmd": "show version",
          "version": 1.2
        },
        "id": 1
      }
    ]
    response = requests.post(url,data=json.dumps(payload), headers=myheaders,auth=(switchuser,switchpassword)).json()

    version = response['result']['body']['sys_ver_str']
    data = json.dumps({"version": version})
    module.exit_json(changed=False, msg=str(data)) 
def add(self, db, **kwargs):
        db_data = db.data.copy()
        db_data["functions"] = _filter_functions(db.data["functions"], **kwargs)
        data = pickle.dumps(db_data)
        result = requests.post("{:s}/function".format(self.url), files = {"file": BytesIO(data)})
        if result.status_code != 200:
            raise RuntimeError("Request failed with status code {:d}".format(result.status_code)) 
def find_raw(self, db, **kwargs):
        db_data = db.data.copy()
        db_data["functions"] = _filter_functions(db.data["functions"], **kwargs)
        data = pickle.dumps(db_data)
        result = requests.post("{:s}/function/find/raw".format(self.url), files = {"file": BytesIO(data)})
        if result.status_code == 200:
            return True
        elif result.status_code == 404:
            return False
        else:
            raise RuntimeError("Request failed with status code {:d}".format(result.status_code)) 
def find_mnem(self, db, **kwargs):
        db_data = db.data.copy()
        db_data["functions"] = _filter_functions(db.data["functions"], **kwargs)
        data = pickle.dumps(db_data)
        result = requests.post("{:s}/function/find/mnem".format(self.url), files = {"file": BytesIO(data)})
        if result.status_code == 200:
            return True
        elif result.status_code == 404:
            return False
        else:
            raise RuntimeError("Request failed with status code {:d}".format(result.status_code)) 
def main(args, env):
    response = requests.post("{:s}/whitelist".format(args.url), files = {"file": open(args.sample, "rb")})
    if response.status_code != 200:
        print("Server returned error {:d}: {:s}".format(response.status_code, response.content)) 
def add_sample(self, paths):
        if isinstance(paths, str):
            paths = [paths]
        reply = requests.post("%s/job/%d/add_sample" % (self.url, self.id), files = [(path, open(path, "rb")) for path in paths[0].split(",")])
        if reply.status_code != 200:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
def submit(self):
        reply = requests.post("%s/job/%d/submit" % (self.url, self.id))
        if reply.status_code != 200:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
def create_job(self):
        reply = requests.post("%s/job" % self.url)
        if reply.status_code == 200:
            return Job(self.url, reply.json()["job"])
        else:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
def find_station(self, search_term):

        LOG.debug("pre-alias search_term: " + search_term);
        search_term = self.apply_aliases(search_term)
        LOG.debug("aliased search_term: " + search_term);

        payload = { "query" : search_term }
        # get the response from the TuneIn API
        res = requests.post(base_url, data=payload, headers=headers)
        dom = parseString(res.text)
        # results are each in their own <outline> tag as defined by OPML (https://en.wikipedia.org/wiki/OPML)
        entries = dom.getElementsByTagName("outline")

        # Loop through outlines in the lists
        for entry in entries:
            # Only look at outlines that are of type=audio and item=station
            if (entry.getAttribute("type") == "audio") and (entry.getAttribute("item") == "station"):
                if (entry.getAttribute("key") != "unavailable"):
                    # stop the current stream if we have one running
                    if (self.audio_state == "playing"):
                        self.stop()
                    # Ignore entries that are marked as unavailable
                    self.mpeg_url = entry.getAttribute("URL")
                    self.station_name = entry.getAttribute("text")
                    # this URL will return audio/x-mpegurl data. This is just a list of URLs to the real streams
                    self.stream_url = self.get_stream_url(self.mpeg_url)
                    self.audio_state = "playing"
                    self.speak_dialog("now.playing", {"station": self.station_name} )
                    wait_while_speaking()
                    LOG.debug("Found stream URL: " + self.stream_url)
                    self.process = play_mp3(self.stream_url)
                    return

        # We didn't find any playable stations
        self.speak_dialog("not.found")
        wait_while_speaking()
        LOG.debug("Could not find a station with the query term: " + search_term) 
def callback(request):
    body = json.loads(request.body)
    text = body['message']['text'].split(' ')
    token = None
    if len(text) > 1:
        token = text[1]

    bot_key = os.environ.get('TELEGRAM_API_KEY')
    chat_id = body['message']['chat']['id']

    try:
        notification = Notification.objects.get(channel='telegram', connect_token=token)
        notification.channel_id = chat_id
        notification.save()

        text = "Welcome to the MuN"
        send_message_url = f'https://api.telegram.org/bot{bot_key}/sendMessage?chat_id={chat_id}&text={text}'
        requests.post(send_message_url)

        return HttpResponse()
    except Notification.DoesNotExist:
        text = "Sorry, seems like the MuN is too far..."
        send_message_url = f'https://api.telegram.org/bot{bot_key}/sendMessage?chat_id={chat_id}&text={text}'
        requests.post(send_message_url)

        return HttpResponse() 
def _client_wrapper(self, rpc_name, rpc_signature):
        def _rpc_call(*args, **kargs):
            for k,v in zip(rpc_signature.parameters, args):
                 kargs[k] = v
            res = requests.post("http://%s:%s/%s" % (self.ip, self.port, rpc_name), params=kargs)
            return res.json() if res.status_code == 200 else None
        return _rpc_call 
def get_token_from_code(auth_code, redirect_uri):
    # Build the post form for the token request
    post_data = {'grant_type': 'authorization_code',
                 'code': auth_code,
                 'redirect_uri': redirect_uri,
                 'scope': ' '.join(str(i) for i in scopes),
                 'client_id': client_id,
                 'client_secret': client_secret}

    r = requests.post(token_url, data=post_data)
    try:
        return r.json()
    except:
        return 'Error retrieving token: {0} - {1}'.format(r.status_code, r.text) 
def jenkins_post(url, config_xml):

    try:

        log.info('Posting data to jenkins: %s' % url)
        headers = {'Content-Type': 'text/xml'}
        auth = HTTPBasicAuth(jenkins_user, jenkins_pass)
        r = requests.post(url, verify=False, headers=headers, auth=auth, data=config_xml)
    
        if r.status_code == requests.codes.ok:
            log.info('Success: %s' % r.status_code)
            return r
        else:
            msg = 'There was an error posting to Jenkins: http_status_code={0}s,reason={1},request={2}'.format(r.status_code, r.reason, url)
            log.error(msg)
            raise Exception(msg)

    except Exception, e:
        msg = 'Failed to create jenkins conf job: {0}'.format(e)
        log.error(msg)
        raise Exception(msg) 
def send(self, msg):
        payload = msg
        r = requests.post(self.url, data=json.dumps(payload))

        if (r.status_code == requests.codes.ok):
            print "FlowMod Succeeded - "+str(r.status_code)
        else:
            print "FlowMod Failed - "+str(r.status_code) 
def demo__custom_identity_verify(identity_dict):
    """
    For CC98 identity verify

    :type identity_dict: dict
    """
    import hashlib
    import requests
    import config

    if 'cc98_username' not in identity_dict or 'cc98_password' not in identity_dict:
        return False

    try:
        pass_md5 = hashlib.md5()
        pass_md5.update(identity_dict['cc98_password'].encode())
        pass_md5 = pass_md5.hexdigest()
        if config.is_use_proxy:
            proxy = config.requests_proxies
        else:
            proxy = None
        r = requests.post('http://www.cc98.org/sign.asp', data={
            'a': 'i',
            'u': identity_dict['cc98_username'],
            'p': pass_md5,
            'userhidden': 2
        }, proxies=proxy)
        if r.text == '9898':
            return True
        else:
            return False
    except:
        return False


# Demo for Twitter 
def test_decision_tree(self):
        from requests import post
        from os import system
        from pandas import DataFrame, read_json
        from sklearn.datasets import load_iris
        from sklearn.tree import DecisionTreeClassifier

        iris = load_iris()
        input_df = DataFrame(data=iris['data'], columns=iris['feature_names'])
        clf = DecisionTreeClassifier(max_depth=2)
        clf.fit(input_df.values, iris['target'])

        # convert classifier to Docker container
        from sklearn2docker.constructor import Sklearn2Docker
        s2d = Sklearn2Docker(
            classifier=clf,
            feature_names=iris['feature_names'],
            class_names=iris['target_names'].tolist(),
        )
        s2d.save(
            name="classifier",
            tag="iris",
        )

        # run your Docker container as a detached process
        system("docker run -d -p {}:5000 --name {} classifier:iris && sleep 5".format(self.port, self.container_name))

        # send your training data as a json string
        request = post("http://localhost:{}/predict/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(list(result), ['prediction'])
        self.assertGreater(len(result), 0)

        request = post("http://localhost:{}/predict_proba/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(list(result), ['setosa', 'versicolor', 'virginica'])
        self.assertGreater(len(result), 0) 
def test_barebones_keras(self):
        from sklearn.datasets import load_iris
        from pandas import DataFrame
        from numpy import array
        from os import system
        from pandas import read_json
        from requests import post

        iris = load_iris()
        input_df = DataFrame(data=iris['data'], columns=iris['feature_names'])
        model = self.create_categorical_classification_model()
        X, Y = input_df.values, array(iris['target'])
        model.fit(X, Y)

        # convert classifier to Docker container
        from sklearn2docker.constructor import Sklearn2Docker
        s2d = Sklearn2Docker(
            classifier=model,
            feature_names=list(input_df),
            class_names=iris['target_names'].tolist(),
        )
        s2d.save(
            name="classifier",
            tag="keras",
        )

        # # run your Docker container as a detached process
        system("docker run -d -p {}:5000 --name {} classifier:keras && sleep 5".format(self.port, self.container_name))

        # send your training data as a json string
        request = post("http://localhost:{}/predict/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 1)
        self.assertEqual(len(result), len(input_df))

        request = post("http://localhost:{}/predict_proba/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 3)
        self.assertEqual(len(result), len(input_df)) 
def _post(self):
        if self.data_type == "json":
            return requests.post(self.config['url'], json=self.data, headers=self.headers, timeout=10, proxies=self.proxy)
        elif self.data_type == "urlencoded":
            return requests.post(self.config['url'], data=self.data, headers=self.headers, timeout=10, proxies=self.proxy) 
def track(self, page):
        url = 'https://ssl.google-analytics.com/collect'
        payload = {
            'v': 1,
            'tid': 'UA-23742434-4',
            'cid': self._get_visitorid(),
            't': 'screenview',
            'an': 'Lynda.com Kodi Addon',
            'av': self.version,
            'cd': page
        }

        headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:11.0) Gecko/20100101 Firefox/11.0'}
        r = requests.post(url, data=payload, headers=headers) 
def __index_login(self):
        login_page = requests.get('https://pass.neu.edu.cn/tpass/login', proxies=proxies['index'])
        # 生成登录参数
        lt = re.findall("input type=\"hidden\" id=\"lt\" name=\"lt\" value=\"(.*?)\" />", login_page.text)[0]
        execution = re.findall("input type=\"hidden\" name=\"execution\" value=\"(.*?)\" />", login_page.text)[0]
        rsa = self.id + self.password + lt
        ul = len(self.id)
        pl = len(self.password)

        # JESESSIONID是一个必不可少的cookie
        self.pass_cookies['jsessionid_tpass'] = login_page.cookies['jsessionid_tpass']

        post_data = {
            'rsa': rsa,
            'ul': ul,
            'pl': pl,
            'lt': lt,
            'execution': execution,
            '_eventId': 'submit'
        }

        login_post = requests.post('https://pass.neu.edu.cn/tpass/login',
                                   headers=self.__headers,
                                   cookies=login_page.cookies,
                                   proxies=proxies['index'],
                                   data=post_data)
        for i in login_post.history:
            if 'CASTGC' in i.cookies:
                self.pass_cookies['CASTGC'] = i.cookies['CASTGC']
            if 'tp_up' in i.cookies:
                self.index_cookies = i.cookies
                self.success = True

    # 通过一网通办登录图书馆，私有方法 
def card_info(self):
        res = requests.post('https://portal.neu.edu.cn/tp_up/up/subgroup/getCardMoney',
                            cookies=self.index_cookies,
                            headers=self.__headers,
                            data='{}',
                            proxies=proxies['index'])
        return res.json()

    # 校园网使用情况 
**************************************************


Python requests.Session() Examples

def requests_retry_session(
    retries=3,
    backoff_factor=0.3,
    status_forcelist=(500, 502, 504),
    session=None,
):
    session = session or requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session 
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    dates = date_h.split('-')
    year = dates[0]
    month =  dates[1]
    day =  dates[2]
    try:
        resp =s.get('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExternal.do?&tripType=OW&searchType=FARE&flexibleSearch=false&directFlightsOnly=false&fareOptions=1.FAR.X&outboundOption.originLocationCode='+from_h+'&outboundOption.destinationLocationCode='+to_h+'&outboundOption.departureDay='+day+'&outboundOption.departureMonth='+month+'&outboundOption.departureYear='+year+'&outboundOption.departureTime=NA&guestTypes%5B0%5D.type=ADT&guestTypes%5B0%5D.amount=1&guestTypes%5B1%5D.type=CNN&guestTypes%5B1%5D.amount=0&pos=AIRCHINA_CN&lang=zh_CN&guestTypes%5B2%5D.type=INF&guestTypes%5B2%5D.amount=0',headers=h1,timeout=60)
        resp2 = s.post('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExt.do?ajaxAction=true',headers=h1,timeout=60)
        resp1 = s.get('http://et.airchina.com.cn/InternetBooking/AirFareFamiliesFlexibleForward.do',headers=h1,timeout=60)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2

# 解析数据 
def __init__(self, url, mutual_auth, cert=None, verify='true', **kwargs):

        self._logger = logging.getLogger("SPOT.INGEST.HDFS_client")
        session = Session()

        if verify == 'true':
            self._logger.info('SSL verification enabled')
            session.verify = True
            if cert is not None:
                self._logger.info('SSL Cert: ' + cert)
                if ',' in cert:
                    session.cert = [path.strip() for path in cert.split(',')]
                else:
                    session.cert = cert
        elif verify == 'false':
            session.verify = False

        super(SecureKerberosClient, self).__init__(url, mutual_auth, session=session, **kwargs) 
def __init__(self, url, mutual_auth, cert=None, verify='true', **kwargs):

        self._logger = logging.getLogger("SPOT.INGEST.HDFS_client")
        session = Session()

        if verify == 'true':
            self._logger.info('SSL verification enabled')
            session.verify = True
            if cert is not None:
                self._logger.info('SSL Cert: ' + cert)
                if ',' in cert:
                    session.cert = [path.strip() for path in cert.split(',')]
                else:
                    session.cert = cert
        elif verify == 'false':
            session.verify = False

        super(SecureKerberosClient, self).__init__(url, mutual_auth, session=session, **kwargs) 
def __init__(self, user_agent, token_url_template, platform):
        self.user_agent = user_agent
        self.token_url_template = token_url_template
        self.platform = platform

        self.session = requests.Session()
        self.session.cookies = http.cookiejar.LWPCookieJar()
        if not os.path.exists(COOKIE_FILE):
            self.session.cookies.save(COOKIE_FILE)
        self.session.cookies.load(COOKIE_FILE, ignore_discard=True)
        self.session.headers = {"User-agent": user_agent}
        if os.path.exists(SESSION_FILE):
            self.load()
        else:
            self._state = {
                'api_key': None,
                'client_api_key': None,
                'token': None,
                'access_token': None,
                'access_token_expiry': None
            }
        self.login() 
def __init__(self, **kwargs):
        super(XueQiuClient, self).__init__()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:32.0) Gecko/20100101 Firefox/32.0',
            'Host': 'xueqiu.com',
            'Pragma': 'no-cache',
            'Connection': 'keep-alive',
            'Accept': '*/*',
            'Accept-Encoding': 'gzip,deflate,sdch',
            'Cache-Control': 'no-cache',
            'Referer': 'http://xueqiu.com/P/ZH003694',
            'X-Requested-With': 'XMLHttpRequest',
            'Accept-Language': 'zh-CN,zh;q=0.8'
        }
        self.session = requests.Session()
        self.session.headers.update(headers)
        self.account_config = None
        self.config.update({
            "create_cubes_url": "https://xueqiu.com/cubes/create.json",
            "get_token_url": "https://xueqiu.com/service/csrf",
            "get_cubes_list": "https://xueqiu.com/v4/stock/portfolio/stocks.json",
            "get_cubes_detail": "https://xueqiu.com/cubes/quote.json",
        }) 
def __init__(self, scheme='http', marker=None, timeout=None):
        self.logger = logging.getLogger(__name__)
        self.__session = requests.Session()

        self.set_auth()

        self.marker = marker
        self.__session.headers.update({'X-Context-Marker': marker})

        self.prom_url = self._get_prom_url()
        self.port = self.prom_url.port
        self.host = self.prom_url.hostname
        self.scheme = scheme

        if self.port:
            self.base_url = "%s://%s:%s/api/" % (self.scheme, self.host,
                                                 self.port)
        else:
            # assume default port for scheme
            self.base_url = "%s://%s/api/" % (self.scheme, self.host)

        self.default_timeout = self._calc_timeout_tuple((20, 30), timeout) 
def test_port_mapping_single_port(self):
        env_name = self._env_name()
        proj_name, py_version = 'test-proj', '3.7'

        proj_dir = self._create_project_dir(proj_name)
        self._commander.run(
            f'create --name={env_name} --version={py_version} {str(proj_dir)}')
        with self._commander.active_env(env_name) as env:
            os.chdir(proj_dir)

            port = 8000
            out = self._commander.run(
                f'run -d -p {port} -- python -m http.server {port}', env=env)
            self.assertCommandOk(out)
            self.assertPortMapperExists(env_name, port)

            s = requests.Session()
            s.mount('http://', HTTPAdapter(
                max_retries=Retry(connect=3, backoff_factor=1)))
            r = s.get(f'http://localhost:{port}')

            self.assertEqual(r.status_code, 200, msg=r.content) 
def test_port_mapping_multi_ports(self):
        env_name = self._env_name()
        proj_name, py_version = 'test-proj', '3.7'

        proj_dir = self._create_project_dir(proj_name)
        self._commander.run(
            f'create --name={env_name} --version={py_version} {str(proj_dir)}')
        with self._commander.active_env(env_name) as env:
            os.chdir(proj_dir)

            for port in range(8000, 8003):
                out = self._commander.run(
                    f'run -d -p {port} -- python -m http.server {port}',
                    env=env
                )
                self.assertCommandOk(out)
                self.assertPortMapperExists(env_name, port)

                s = requests.Session()
                s.mount('http://', HTTPAdapter(
                    max_retries=Retry(connect=3, backoff_factor=1)))
                r = s.get(f'http://localhost:{port}')

                self.assertEqual(r.status_code, 200, msg=r.content) 
def requests_retry_session(
    retries=3,
    backoff_factor=0.3,
    status_forcelist=(500, 502, 504),
    session=None,
):
    session = session or requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session 
def get_raw(stocks) -> dict:
    req = requests.Session()
    req.get(SESSION_URL, proxies=get_proxies())

    r = req.get(
        STOCKINFO_URL.format(
            stock_id=_join_stock_id(stocks),
            time=int(time.time()) * 1000))

    if sys.version_info < (3, 5):
        try:
            return r.json()
        except ValueError:
            return {'rtmessage': 'json decode error', 'rtcode': '5000'}
    else:
        try:
            return r.json()
        except json.decoder.JSONDecodeError:
            return {'rtmessage': 'json decode error', 'rtcode': '5000'} 
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    dates = date_h.split('-')
    year = dates[0]
    month =  dates[1]
    day =  dates[2]
    try:
        resp =s.get('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExternal.do?&tripType=OW&searchType=FARE&flexibleSearch=false&directFlightsOnly=false&fareOptions=1.FAR.X&outboundOption.originLocationCode='+from_h+'&outboundOption.destinationLocationCode='+to_h+'&outboundOption.departureDay='+day+'&outboundOption.departureMonth='+month+'&outboundOption.departureYear='+year+'&outboundOption.departureTime=NA&guestTypes%5B0%5D.type=ADT&guestTypes%5B0%5D.amount=1&guestTypes%5B1%5D.type=CNN&guestTypes%5B1%5D.amount=0&pos=AIRCHINA_CN&lang=zh_CN&guestTypes%5B2%5D.type=INF&guestTypes%5B2%5D.amount=0',headers=h1,timeout=60)
        resp2 = s.post('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExt.do?ajaxAction=true',headers=h1,timeout=60)
        resp1 = s.get('http://et.airchina.com.cn/InternetBooking/AirFareFamiliesFlexibleForward.do',headers=h1,timeout=60)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2

# 解析数据 
def get_object(self, name, is_private=False):
        method = 'get'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)
        s = requests.Session()
        if is_private:
            auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
            Authorization = {'Authorization': auth.get_authorization()}
            s.headers.update(Authorization)

        r = s.get(url)
        return r 
def put_object(self, name, content):
        method = 'put'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)

        s = requests.Session()
        auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
        Authorization = {'Authorization': auth.get_authorization()}
        s.headers.update(Authorization)

        r = s.put(url, data=content)
        if r.status_code == 200:
            return r
        else:
            LOGGER.info(r.content) 
def head_object(self, name, is_private=False):
        method = 'head'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)
        s = requests.Session()
        if is_private:
            auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
            Authorization = {'Authorization': auth.get_authorization()}
            s.headers.update(Authorization)

        r = s.head(url)
        return r 
def delete_object(self, name):
        method = 'delete'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)

        s = requests.Session()
        auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
        Authorization = {'Authorization': auth.get_authorization()}
        s.headers.update(Authorization)

        r = s.delete(url)
        if r.status_code == 204:
            return True 
def _init_session(self):
        """_init_session() is a private method to perfom command
        session initializaton actions.
        As this creates a session without a logged in user, only
        public profile content is available, until a login is
        performed on this session.
        """

        s = self._session = requests.Session()

        s.headers['Accept-charset'] = "utf-8"

        if self._format == "json":
            pass
        elif self._format == 'xmlfm':
            s.headers['Accept'] = "application/xml"
            s.headers['Accept'] = "text/xml"
        else:
            raise ValueError("Invalid format: " + repr(self._format)) 
def setup_connector(app, name='default', **options):
	if not hasattr(app, 'extensions'):
		app.extensions = {}

	if 'connectors' not in app.extensions:
		app.extensions['connectors'] = {}
	session = Session()

	if 'auth' in options:
		session.auth = options['auth']
	headers = options.get('headers', {})

	if 'Content-Type' not in headers:
		headers['Content-Type'] = 'application/json'
	session.headers.update(headers)

	app.extensions['connectors'][name] = session
	return session 
def setup_connector(app, name='default', **options):
	if not hasattr(app, 'extensions'):
		app.extensions = {}

	if 'connectors' not in app.extensions:
		app.extensions['connectors'] = {}
	session = Session()

	if 'auth' in options:
		session.auth = options['auth']
	headers = options.get('headers', {})

	if 'Content-Type' not in headers:
		headers['Content-Type'] = 'application/json'
	session.headers.update(headers)

	app.extensions['connectors'][name] = session
	return session 
def paging(endpoint, request_json) -> tuple:
    """Split input list into pages"""
    result_pages = {}
    session = requests.Session()
    success = True
    while True:
        r_json = utils.vmaas_post_request(endpoint, request_json, session)
        if r_json is None:
            LOGGER.info("Downloading ERROR.")
            success = False
            break
        response_to_list = [(k, v) for k, v in r_json.items()]
        data_index = response_to_list[0][0]
        data = response_to_list[0][1]
        result_pages.setdefault(data_index, {}).update(data)
        LOGGER.info("Downloading CVE/REPOs metadata (page: %s, page_size: %s, pages: %s)",
                    request_json['page'], r_json["page_size"], r_json['pages'])
        if request_json['page'] >= r_json['pages']:
            break
        request_json['page'] += 1
    session.close()

    if success:
        result_pages.update({"page": r_json["page"], "page_size": r_json["page_size"], "pages": r_json["pages"]})
    return (success, result_pages) 
def __init__(self):
        """init"""
        self.session = requests.Session()
        self.eln_session_id = None
        self.headers = { 
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36'
                        ' (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36',
        'X-Requested-With': 'XMLHttpRequest',
        } 
def __init__(self, base_url, apikey):
        # The URL in the config should end in /MAAS/, but the api is behind /MAAS/api/2.0/
        self.base_url = base_url + "/api/2.0/"
        self.apikey = apikey

        self.signer = MaasOauth(apikey)
        self.http_session = requests.Session()

        # TODO(sh8121att) Get logger name from config
        self.logger = logging.getLogger('drydock') 
def __init__(self,
                 host,
                 port=None,
                 scheme='http',
                 auth_gen=None,
                 marker=None,
                 end_user=None,
                 timeout=None):
        self.logger = logging.getLogger(__name__)
        self.__session = requests.Session()
        self.auth_gen = auth_gen

        self.set_auth()

        self.marker = marker
        self.end_user = end_user
        self.__session.headers.update({'X-Context-Marker': marker})

        if end_user:
            self.__session.headers.update({'X-End-User': end_user})

        self.host = host
        self.scheme = scheme

        if port:
            self.port = port
            self.base_url = "%s://%s:%s/api/" % (self.scheme, self.host,
                                                 self.port)
        else:
            # assume default port for scheme
            self.base_url = "%s://%s/api/" % (self.scheme, self.host)

        self.default_timeout = self._calc_timeout_tuple((20, 30), timeout) 
def get_ks_session(**kwargs):
        # Establishes a keystone session
        if 'token' in kwargs:
            auth = v3.TokenMethod(token=kwargs.get('token'))
        else:
            auth = v3.Password(**kwargs)
        return session.Session(auth=auth) 
def __init__(self, url, user, password):
        """
            Create a session with the server.
            :param user: User name
            :param password: Password
            :except: Raises RuntimeError if server replies with an error code.
        """
        self.url = url
        self.session = Session()
        self._login(user, password) 
def requests_retry_session(
    retries=3,
    backoff_factor=5,
    session=None,
):
    session = requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    #session.mount('https://', adapter)
    return session

########### Declare Type of station: AWS,ARG or AGRO ########
#station = 'aws' 
def do_network_work(args) -> None:
        network_resource, *_ = args
        Session = network_resource
        with Session() as s:
            adapter = HTTPAdapter(max_retries=3)
            s.mount('http://', adapter)
            s.get('http://localhost:8080/') 
def get_session(domain):
    """
    获取一个此域名的 keep-alive 的session
    :param domain: 域名
    :type domain: str
    :rtype: requests.Session
    """
    if domain not in pool:
        pool[domain] = []

    if not hasattr(locked_session, "session"):
        # 这个变量用于存储本线程中被锁定的session
        # 当一个session被拿出来使用时, 会从 pool 中被移除, 加入到下面这个变量中
        # 当线程结束后, 需要调用 release_lock() 来释放被锁定的session
        #    此时被锁定的session会重新进入session池
        locked_session.session = []

    if not pool[domain]:
        # 线程池空, 新建一个 session
        session = {
            "domain": domain,
            "session": requests.Session(),
        }
    else:
        # 从线程池中取出最近的一个
        session = pool[domain].pop()

    session["active"] = time()

    locked_session.session.append(session)

    return session["session"] 
def __init__(self, logger, user_name, password):
        this_func_name = sys._getframe().f_code.co_name

        self.logger = logger
        self.user_name = user_name
        self.password = password

        session = requests.Session()
        session.headers = {
                'User-Agent': random.choice(pc_browser_ua)
                }
        self.session = session

        self.logger.debug("%s(): user_name: %s\tpassword: %s" % (this_func_name, user_name, password))
        self.logger.debug("%s(): start ..." % this_func_name) 
def __init__(self, host, username, password, ssl, verify_ssl=True):
        self.host = host
        self.session = requests.Session()
        self.session.auth = (username, password)
        self.ssl = ssl
        self.verify_ssl = verify_ssl 
def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(
            {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; \
             Linux x86_64; rv:28.0) Gecko/20100101 Firefox/28.0'}) 
def __init__(self, cookiejar=None):
        # Initialise the session
        self._s = requests.Session()
        self._user_cached = None
        self.logged_in = False

        if cookiejar:
            self._s.cookies = cookiejar

            # Check if the given cookies log the user in
            user = self.user()
            if user:
                self.logged_in = True 
def refresh_login(self):
        """Deletes persisted cookies which forces a login attempt with current credentials"""

        s = requests.Session()
        empty_cookie_jar = s.cookies
        if util.save_data(addon, self.COOKIE_FILE_NAME, empty_cookie_jar):
            xbmcgui.Dialog().ok(addonname, "Cleared cookies. Please exit the addon and open it again.")
        else:
            xbmcgui.Dialog().ok(addonname, "Could not refresh lynda session cookies") 
def __init__(
        self, url: str, auth: Auth = None, verify: Verify = True
    ) -> None:
        self.url = url
        self.session = requests.Session()
        if auth is not None:
            self.session.auth = auth
        self.session.verify = verify 
def list_sessions(self) -> List[Session]:
        """List all the active sessions in Livy."""
        data = self._client.get("/sessions")
        return [Session.from_json(item) for item in data["sessions"]] 
def get_session(self, session_id: int) -> Optional[Session]:
        """Get information about a session.

        :param session_id: The ID of the session.
        """
        try:
            data = self._client.get(f"/sessions/{session_id}")
        except requests.HTTPError as e:
            if e.response.status_code == 404:
                return None
            else:
                raise
        return Session.from_json(data) 
def change_params_and_get_the_session():
    global params, datas, login_url, post_url, s, dl_session
    tag = 'Change_Params_And_Get_The_Session'
    print_with_tag(tag, 'Changing Request params..')
    datas['pixiv_id'] = pixiv_user_name
    datas['password'] = pixiv_user_pass
    print_with_tag(tag, 'Post data params changed.')
    s = requests.Session()
    s.headers = params
    # dl_session = requests.Session()
    print_with_tag(tag, 'Session started.') 
def run_job(id):
    s = requests.Session()

    r = s.post("http://127.0.0.1:5000/api/v1/auth/",
               data={"email": "[email protected]", "password": "123456", "method": "login"})

    s.get("http://127.0.0.1:5000/test_run/auto/%s" % id) 
def check_version():
    f = codecs.open('version.txt', 'r')
    version = f.readline()
    s = requests.Session()
    r_version = s.get("https://gitee.com/lym51/AutoLine/raw/master/version.txt").text
    if version != r_version:
        print("*" * 25)
        print("本地版本：v%s" % version)
        print("github版本: v%s" % r_version)
        print("AutoLine开源平台代码已有更新，请到下面的地址更新代码:")
        print("https://github.com/small99/AutoLine")
        print("*" * 25)
        exit(0)
    f.close() 
def get_chaohua_list(cookie, sinceId):
    url = "https://m.weibo.cn/api/container/getIndex?containerid=100803_-_page_my_follow_super"
    if sinceId != '':
        url = url + "&since_id=%s" % sinceId
    headers = {
        'Cookie': cookie
    }
    session = requests.Session()
    response = session.get(url, headers=headers)
    response = response.json()
    return response 
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    start_url = 'http://b2c.csair.com/B2C40/modules/bookingnew/main/flightSelectDirect.html?t=S&c1='+from_h+'&c2='+to_h+'&d1='+date_h+'&at=1&ct=0&it=0&preUrl=360BUY'
    h2 = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
          'Accept-Encoding':'gzip, deflate, sdch',
          'Accept-Language':'zh-CN,zh;q=0.8',
          'X-Requested-With':'XMLHttpRequest',
          #Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140663&ltime=1464140662; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140663&ltime=1464140662&compid=671
          'Referer':start_url,
          'Origin':'http://b2c.csair.com',
          'Host':'b2c.csair.com',
          'Proxy-Connection':'keep-alive',
          'Upgrade-Insecure-Requests':1,
          'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
          }
    date_h = date_h.replace('-','')
    data = '{"depcity":"'+from_h+'", "arrcity":"'+to_h+'", "flightdate":"'+date_h+'", "adultnum":"1", "childnum":"0", "infantnum":"0", "cabinorder":"0","airline":"1", "flytype":"0", "international":"0", "action":"0", "segtype":"1", "cache":"0", "preUrl":"360BUY", "isMember":""}'
    data = urllib.quote(data)
    res_url ='http://b2c.csair.com/B2C40/query/jaxb/direct/query.ao?json='+data
    try:
        re =s.get(start_url,headers = h1,timeout = 15)
        resp1 = s.post(res_url,headers = h2,timeout = 15)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    start_url = 'http://b2c.csair.com/B2C40/modules/bookingnew/main/flightSelectDirect.html?t=S&c1='+from_h+'&c2='+to_h+'&d1='+date_h+'&at=1&ct=0&it=0&preUrl=360BUY'
    h2 = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
          'Accept-Encoding':'gzip, deflate, sdch',
          'Accept-Language':'zh-CN,zh;q=0.8',
          'X-Requested-With':'XMLHttpRequest',
          #Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140663&ltime=1464140662; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140663&ltime=1464140662&compid=671
          'Referer':start_url,
          'Origin':'http://b2c.csair.com',
          'Host':'b2c.csair.com',
          'Proxy-Connection':'keep-alive',
          'Upgrade-Insecure-Requests':1,
          'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
          }
    date_h = date_h.replace('-','')
    data = '{"depcity":"'+from_h+'", "arrcity":"'+to_h+'", "flightdate":"'+date_h+'", "adultnum":"1", "childnum":"0", "infantnum":"0", "cabinorder":"0","airline":"1", "flytype":"0", "international":"0", "action":"0", "segtype":"1", "cache":"0", "preUrl":"360BUY", "isMember":""}'
    data = urllib.quote(data)
    res_url ='http://b2c.csair.com/B2C40/query/jaxb/direct/query.ao?json='+data
    try:
        re =s.get(start_url,headers = h1,timeout = 15)
        resp1 = s.post(res_url,headers = h2,timeout = 15)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
def data_Crawling(from_h,to_h,date_h,SC):
    s = requests.Session()
    try:
        resp1 = s.get('http://new.hnair.com/hainanair/ibe/deeplink/ancillary.do?DD1='+date_h+'&DD2=&TA=1&TC=0&TI=&ORI='+from_h+'&DES='+to_h+'&SC='+SC+'&ICS=F&PT=F&PT=&FLC=1&NOR=&PACK=T',headers=h1,timeout=15)

        resp2 = s.post('http://new.hnair.com/hainanair/ibe/deeplink/ancillary.do?DD1='+date_h+'&DD2=&TA=1&TC=0&TI=&ORI='+from_h+'&DES='+to_h+'&SC='+SC+'&ICS=F&PT=F&PT=&FLC=1&NOR=&PACK=T&redirected=true',headers=h2,timeout=15)

        resp3 = s.get('http://new.hnair.com/hainanair/ibe/deeplink/entryPointRedirect.do?QUERY=ancillaryIBESearch',headers=h3,timeout=15)

        #resp4 = s.post('http://new.hnair.com/hainanair/ibe/deeplink/entryPointRedirect.do?redirected=true')

        resp5 = s.get('http://new.hnair.com/hainanair/ibe/common/processSearchEntry.do?fromEntryPoint=true',headers=h5,timeout=15)

        resp6 = s.get('http://new.hnair.com/hainanair/ibe/common/spinner.do',headers=h6,timeout=15)

        #respwait = s.get('http://www.hnair.com/qt/dkggpic/wait/')

        resp7 = s.post('http://new.hnair.com/hainanair/ibe/common/processSearch.do',headers=h7,timeout=15)

        resp8 = s.get('http://new.hnair.com/hainanair/ibe/air/processSearch.do',headers=h8,timeout=15)

        resp = s.get('http://new.hnair.com/hainanair/ibe/air/searchResults.do',headers=h9,timeout=15)
        return resp.text,resp.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
# 解析数据 
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    try:
        #resp1 = s.post('http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=%E5%8C%97%E4%BA%AC&cityCodeOrg=PEK&cityNameDes=%E5%8E%A6%E9%97%A8&cityCodeDes=XMN&takeoffDate=2016-05-28&returnDate=2016-05-28&cabinStage=0&adultNum=1&childNum=0',headers=h1,timeout=15)
        url = 'http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=&cityCodeOrg='+from_h+'&cityNameDes=&cityCodeDes='+to_h+'&takeoffDate='+date_h+'&returnDate=&cabinStage=0&adultNum=1&childNum=0'
        resp1 = s.post(url,headers = h1,timeout=15)
        h2 = {
                'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Encoding':'gzip, deflate',
                'Accept-Language':'zh-CN,zh;q=0.8',
                'Cache-Control':'max-age=0',
                #'Content-Length':234
                'Content-Type':'application/x-www-form-urlencoded',
               # Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140688&ltime=1464140663; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140688&ltime=1464140663&compid=671
                'Host':'sc.travelsky.com',
                'Origin':'http://sc.travelsky.com',
                'Proxy-Connection':'keep-alive',
                'Referer':url,
                'Upgrade-Insecure-Requests':1,
                'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
        }
        id = re.search(r'<input type="hidden" name ="airAvailId" value="(.*?)" />',resp1.text)
        resp= s.post('http://sc.travelsky.com/scet/airAvail.do?airAvailId='+id.group(1)+'&cityCodeOrg='+from_h+'&cityCodeDes='+to_h+'&cityNameOrg=&cityNameDes=&takeoffDate='+date_h+'&returnDate=&travelType=0&countrytype=0&needRT=0&cabinStage=0&adultNum=1&childNum=0',headers = h2,timeout=15)
        return resp.text,resp.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
# 解析数据 
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    try:
        #resp1 = s.post('http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=%E5%8C%97%E4%BA%AC&cityCodeOrg=PEK&cityNameDes=%E5%8E%A6%E9%97%A8&cityCodeDes=XMN&takeoffDate=2016-05-28&returnDate=2016-05-28&cabinStage=0&adultNum=1&childNum=0',headers=h1,timeout=15)
        url = 'http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=&cityCodeOrg='+from_h+'&cityNameDes=&cityCodeDes='+to_h+'&takeoffDate='+date_h+'&returnDate=&cabinStage=0&adultNum=1&childNum=0'
        resp1 = s.post(url,headers = h1,timeout=15)
        h2 = {
                'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Encoding':'gzip, deflate',
                'Accept-Language':'zh-CN,zh;q=0.8',
                'Cache-Control':'max-age=0',
                #'Content-Length':234
                'Content-Type':'application/x-www-form-urlencoded',
               # Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140688&ltime=1464140663; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140688&ltime=1464140663&compid=671
                'Host':'sc.travelsky.com',
                'Origin':'http://sc.travelsky.com',
                'Proxy-Connection':'keep-alive',
                'Referer':url,
                'Upgrade-Insecure-Requests':1,
                'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
        }
        id = re.search(r'<input type="hidden" name ="airAvailId" value="(.*?)" />',resp1.text)
        time.sleep(2)
        resp= s.post('http://sc.travelsky.com/scet/airAvail.do?airAvailId='+id.group(1)+'&cityCodeOrg='+from_h+'&cityCodeDes='+to_h+'&cityNameOrg=&cityNameDes=&takeoffDate='+date_h+'&returnDate=&travelType=0&countrytype=0&needRT=0&cabinStage=0&adultNum=1&childNum=0',headers = h2,timeout=15)
        return resp.text,resp.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
def data_Crawling(from_h,to_h,date_h,i_orgcity, i_dstCity):
    s = requests.Session()
    data = '{"AirlineType":"Single","IsFixedCabin":false,"RouteList":[{"RouteIndex":1,"RouteName":"单    程","OrgCity":"'+from_h+'","DesCity":"'+to_h+'","OrgCityName":"'+i_orgcity+'","DesCityName":"'+i_dstCity+'","FlightDate":"'+date_h+'"}],"AVType":0}'
    #data = urllib.urlencode(data)
    data = urllib.quote(data)
    data = 'http://www.scal.com.cn/Web/ETicket/AirlineList?AirlineParamJSON='+data
    try:
        resp = s.post(data,timeout=15)
        url = re.search(r'arrPageValue.AirlineParamJSON = (.*?);',resp.text)
        #print url.group(1)
        data = json.loads( url.group(1))
        #print(data)
        data1 = re.search(r'arrPageValue.AirlineParamJSON = .*\[(.*?)\].*;',resp.text).group(1).replace("}","")
        #data1 = str(data['RouteList'][0]).replace("}","")
        data11 = data['AirlineType']
        data1 += ',\"AirlineType\":\"'+data11+'\"'
        data11 = data['AVType']
        data1 += ',\"AVType\":'+str(data11)
        data1 += ',\"CardFlag\":null'
        data11 = data['Flag']
        data1 += ',\"Flag\":null'
        data11 = data['BuyerType']
        data1 += ',\"BuyerType\":'+str(data11)
        data11 = data['IsFixedCabin']
        data1 += ',\"IsFixedCabin\":'+str(data11).lower()
        data11 = data['PassKey']
        data1 += ',\"PassKey\":\"'+data11+'\"}'
        data1 = json.loads(data1)
        resp1 = s.post('http://www.scal.com.cn/Web/ETicket/GetSingleChina',json=data1)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
def data_Crawling(from_h,to_h,date_h,i_orgcity, i_dstCity):
    s = requests.Session()
    data = '{"AirlineType":"Single","IsFixedCabin":false,"RouteList":[{"RouteIndex":1,"RouteName":"单    程","OrgCity":"'+from_h+'","DesCity":"'+to_h+'","OrgCityName":"'+i_orgcity+'","DesCityName":"'+i_dstCity+'","FlightDate":"'+date_h+'"}],"AVType":0}'
    #data = urllib.urlencode(data)
    data = urllib.quote(data)
    data = 'http://www.scal.com.cn/Web/ETicket/AirlineList?AirlineParamJSON='+data
    try:
        resp = s.post(data,timeout=15)
        url = re.search(r'arrPageValue.AirlineParamJSON = (.*?);',resp.text)
        #print url.group(1)
        data = json.loads( url.group(1))
        #print(data)
        data1 = re.search(r'arrPageValue.AirlineParamJSON = .*\[(.*?)\].*;',resp.text).group(1).replace("}","")
        #data1 = str(data['RouteList'][0]).replace("}","")
        data11 = data['AirlineType']
        data1 += ',\"AirlineType\":\"'+data11+'\"'
        data11 = data['AVType']
        data1 += ',\"AVType\":'+str(data11)
        data1 += ',\"CardFlag\":null'
        data11 = data['Flag']
        data1 += ',\"Flag\":null'
        data11 = data['BuyerType']
        data1 += ',\"BuyerType\":'+str(data11)
        data11 = data['IsFixedCabin']
        data1 += ',\"IsFixedCabin\":'+str(data11).lower()
        data11 = data['PassKey']
        data1 += ',\"PassKey\":\"'+data11+'\"}'
        data1 = json.loads(data1)
        resp1 = s.post('http://www.scal.com.cn/Web/ETicket/GetSingleChina',json=data1)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************************


Python requests.put() Examples

def _send_raw_http_request(self, method, url, data=None):
        self.__logger.debug('%s %s' % (method, url))
        if method in ['POST', 'PUT', 'PATCH']:
            self.__logger.log(TINTRI_LOG_LEVEL_DATA, 'Data: %s' % data)

        headers = {'content-type': 'application/json'}
        if self.__session_id:
            headers['cookie'] = 'JSESSIONID=%s' % self.__session_id

        if method in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE']:
            if method == 'GET': httpresp = requests.get(url, headers=headers, verify=False)
            elif method == 'POST': httpresp = requests.post(url, data, headers=headers, verify=False)
            elif method == 'PUT': httpresp = requests.put(url, data, headers=headers, verify=False)
            elif method == 'PATCH': httpresp = requests.patch(url, data, headers=headers, verify=False)
            elif method == 'DELETE': httpresp = requests.delete(url, headers=headers, verify=False)
            self._httpresp = httpresp # self._httpresp is for debugging only, not thread-safe
            return httpresp
        else:
            raise TintriError(None, message='Invalid HTTP method: ' + method) # This should never happen 
def put_well_data(container_id, well_index, data_obj, headers=None, org_name=None,container_json=None):
    """Update a well with new data"""
    
    initialize_config()
        
    headers = headers if headers else TSC_HEADERS
    org_name = org_name if org_name else ORG_NAME    
    
    def _well_url(container_id, well_index):
        return 'https://secure.transcriptic.com/{}/inventory/samples/{}/{}'.format(org_name, container_id, well_index)

    headers['content-type'] = 'application/json'
   
    response = requests.put(_well_url(container_id, well_index), headers=headers,
                            data=json.dumps(data_obj),
                            verify=False
                            )
    
    response.raise_for_status() 
def notify_party_and_respondent_account_locked(respondent_id, email_address, status=None):
    logger.info('Notifying respondent and party service that account is locked')
    url = f'{app.config["PARTY_URL"]}/party-api/v1/respondents/edit-account-status/{respondent_id}'

    data = {
        'respondent_id': respondent_id,
        'email_address': email_address,
        'status_change': status
    }

    response = requests.put(url, json=data, auth=app.config['PARTY_AUTH'])

    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        logger.error('Failed to notify party', respondent_id=respondent_id, status=status)
        raise ApiError(logger, response)

    logger.info('Successfully notified respondent and party service that account is locked', respondent_id=respondent_id, status=status) 
def changeAlbumName(self,gid,name,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        payload = {
            "title": name
        }
        r = requests.put(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            data = json.dumps(payload),
        )
        return r.json() 
def _publish(etag):
  """Publish local template to Firebase server.

  Args:
    etag: ETag for safe (avoid race conditions) template updates.
        * can be used to force template replacement.
  """
  with open('config.json', 'r', encoding='utf-8') as f:
    content = f.read()
  headers = {
    'Authorization': 'Bearer ' + _get_access_token(),
    'Content-Type': 'application/json; UTF-8',
    'If-Match': etag
  }
  resp = requests.put(REMOTE_CONFIG_URL, data=content.encode('utf-8'), headers=headers)
  if resp.status_code == 200:
    print('Template has been published.')
    print('ETag from server: {}'.format(resp.headers['ETag']))
  else:
    print('Unable to publish template.')
    print(resp.text) 
def changeAlbumName(self,gid,name,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        payload = {
            "title": name
        }
        r = requests.put(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            data = json.dumps(payload),
        )
        return r.json() 
def run(self):
        try:
            self.sse = ClosableSSEClient(self.url)
            for msg in self.sse:
                event = msg.event
                if event is not None and event in ('put', 'patch'):
                    response = json.loads(msg.data)
                    if response is not None:
                        # Default to CHILD_CHANGED event
                        occurred_event = FirebaseEvents.CHILD_CHANGED
                        if response['data'] is None:
                            occurred_event = FirebaseEvents.CHILD_DELETED

                        # Get the event I'm trying to listen to
                        ev = FirebaseEvents.id(self.event_name)
                        if occurred_event == ev or ev == FirebaseEvents.CHILD_CHANGED:
                            self.callback(event, response)
        except socket.error:
            pass 
def keepalive_listen_key(self, listen_key):
        """
        Ping a listenkey to keep it alive

        :param listen_key: the listenkey you want to keepalive
        :type listen_key: str

        :return: the response
        :rtype: str or False
        """
        logging.debug("BinanceWebSocketApiRestclient->keepalive_listen_key(" + str(listen_key) + ")")
        method = "put"
        try:
            return self._request(method, self.path_userdata, False, {'listenKey': str(listen_key)})
        except KeyError:
            return False
        except TypeError:
            return False 
def on_teams_file_consent_accept(
            self,
            turn_context: TurnContext,
            file_consent_card_response: FileConsentCardResponse
    ):
        """
        The user accepted the file upload request.  Do the actual upload now.
        """

        file_path = "files/" + file_consent_card_response.context["filename"]
        file_size = os.path.getsize(file_path)

        headers = {
            "Content-Length": f"\"{file_size}\"",
            "Content-Range": f"bytes 0-{file_size-1}/{file_size}"
        }
        response = requests.put(
            file_consent_card_response.upload_info.upload_url, open(file_path, "rb"), headers=headers
        )

        if response.status_code != 200:
            await self._file_upload_failed(turn_context, "Unable to upload file.")
        else:
            await self._file_upload_complete(turn_context, file_consent_card_response) 
def send_response(event, context, status, reason, data):
    import requests

    body = json.dumps(
        {
            'Status': status,
            'RequestId': event['RequestId'],
            'StackId': event['StackId'],
            'PhysicalResourceId': context.log_stream_name,
            'Reason': reason,
            'LogicalResourceId': event['LogicalResourceId'],
            'Data': data
        }
    )

    headers = {
        'content-type': '',
        'content-length': len(body)
    }

    r = requests.put(event['ResponseURL'], data=body, headers=headers) 
def setupDomain(domain, folder=False):
    endpoint = config.get("hsds_endpoint")
    headers = getRequestHeaders(domain=domain)
    req = endpoint + "/"
    rsp = requests.get(req, headers=headers)
    if rsp.status_code == 200:
        return  # already have domain
    if rsp.status_code != 404:
        # something other than "not found"
        raise ValueError(f"Unexpected get domain error: {rsp.status_code}")
    parent_domain = getParentDomain(domain)
    if parent_domain is None:
        raise ValueError(f"Invalid parent domain: {domain}")
    # create parent domain if needed
    setupDomain(parent_domain, folder=True)

    headers = getRequestHeaders(domain=domain)
    body=None
    if folder:
        body = {"folder": True}
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
    else:
        rsp = requests.put(req, headers=headers)
    if rsp.status_code != 201:
        raise ValueError(f"Unexpected put domain error: {rsp.status_code}") 
def testPutInvalid(self):
        print("testPutInvalid", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_id = rspJson["root"]

        # try creating an attribute with an invalid type
        attr_name = "attr1"
        attr_payload = {'type': 'H5T_FOOBAR', 'value': 42}
        req = self.endpoint + "/groups/" + root_id + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(attr_payload), headers=headers)
        self.assertEqual(rsp.status_code, 400)  # invalid request 
def setupDomain(domain):
    endpoint = config.get("hsds_endpoint")
    print("setupdomain: ", domain)
    headers = getRequestHeaders(domain=domain)
    req = endpoint + "/"
    rsp = requests.get(req, headers=headers)
    if rsp.status_code == 200:
        return  # already have domain
    if rsp.status_code != 404:
        # something other than "not found"
        raise ValueError("Unexpected get domain error: {}".format(rsp.status_code))

    parent_domain = getParentDomain(domain)
    if parent_domain is None:
        raise ValueError("Invalid parent domain: {}".format(domain))
    # create parent domain if needed
    setupDomain(parent_domain)  
     
    headers = getRequestHeaders(domain=domain)
    rsp = requests.put(req, headers=headers)
    if rsp.status_code != 201:
        raise ValueError("Unexpected put domain error: {}".format(rsp.status_code)) 
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
def set_settings(self, settings):
        h=headers
        h.update({
          'Authorization'   : 'OAuth="'+ self.oauth + '"',
          'Content-Length'  :  '1089', #@TODO figure out length calculation
          'Content-Type'    : 'application/json'})

        # Happn preferences
        url = 'https://api.happn.fr/api/users/' + self.id
        try:
            r = requests.put(url, headers=h, data = json.dumps(settings))
        except Exception as e:
            raise HTTP_MethodError('Error Setting Settings: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Updated Settings')
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
def update_activity(self):
        """ Updates User activity """

        # Create and send HTTP PUT to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'update_activity' :  'true'
        }
        url = 'https://api.happn.fr/api/users/'+self.id
        try:
            r = requests.put(url, headers=h, data = payload)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Updated User activity')
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
def _try_upload(url, chunk, heads):
    response = None
    for n in range(0, 11):
        if n > 0:
            print("Upload re-try #{}...".format(n))
        try:
            print("Uploading...".format(n))
            response = requests.put(url, data=chunk, headers=heads)
            print("Done.")
            if response.status_code not in [requests.codes.ok, requests.codes.accepted, requests.codes.created]:
                print("Response status: {} ({}).".format(response.status_code, response.reason))
                raise IOError
            return response
        except IOError as e:
            print("Exception: " + str(e))
            time.sleep(2 ** n)
        finally:
            if response is not None:
                response.close()
    raise IOError("Filed to upload file") 
def put(self, *args, **kwargs):
        kwargs['method'] = 'put'
        return self.do(*args, **kwargs) 
def api_submit(request, user=None, password=None):

    # Fetch the list of deploys for the application
    # This becomes the api call
    api_url = (api_protocol
               + '://'
               + api_host
               + request)

    if user:
        logging.info('Submitting data to API: %s' % api_url)
        r = requests.put(api_url, verify=verify_ssl, auth=HTTPBasicAuth(user, password))
    else:
        logging.info('Requesting data from API: %s' % api_url)
        r = requests.get(api_url, verify=verify_ssl)

    if r.status_code == requests.codes.ok:

        logging.debug('Response data: %s' % r.json())
        return r.json()

    elif r.status_code == requests.codes.conflict:

        logging.info('Artifact location/revision combination '
                     'is not unique. Nothing to do.')

        logging.info('twoni-plete')
        print ""
        sys.exit(0)

    else:

        logging.error('There was an error querying the API: '
                      'http_status_code=%s,reason=%s,request=%s'
                      % (r.status_code, r.reason, api_url))
        logging.info('twoni-plete')
        print ""
        sys.exit(2) 
def change_password(password, token):
    logger.info('Attempting to change password through the party service')

    data = {'new_password': password}
    url = f"{app.config['PARTY_URL']}/party-api/v1/respondents/change_password/{token}"
    response = requests.put(url, auth=app.config['PARTY_AUTH'], json=data)

    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        logger.error('Failed to send change password request to party service', token=token)
        raise ApiError(logger, response)

    logger.info('Successfully changed password through the party service') 
def verify_email(token):
    logger.info('Attempting to verify email address', token=token)

    url = f"{app.config['PARTY_URL']}/party-api/v1/emailverification/{token}"
    response = requests.put(url, auth=app.config['PARTY_AUTH'])

    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        logger.error('Failed to verify email', token=token)
        raise ApiError(logger, response)

    logger.info('Successfully verified email address', token=token) 
def set(self, payload):
        return requests.put(self.current_url, json=payload) 
def _put_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.put(request_url, json=requests_data, headers=request_header) 
def __on_or_off(self, operation):
		url = 'http://'+self.IP+'/api/'+self.username+'/lights/'+self.ID+'/state'
		if operation == 'on':
			payload = '{"on": true}'
		else:
			payload = '{"on": false}'
		r = requests.put(url, data=payload)
		if r.status_code == 200:
			HueBridge.log.success(self.name + ' ' + operation)
		else:
			HueBridge.log.err(self.name + ' ' + operation)
		return r.json() 
def __init__(self, config):
        if not have_requests:
            raise ImportError('requests module required for RequestsTransport')
        TransportBase.__init__(self, config, self.__module__)
        self.REQ_MAP = {
            'GET': requests.get,
            'POST': requests.post,
            'DELETE': requests.delete,
            'PUT': requests.put
        }
        self._timeout = self._config.get('timeout', None)
        if isinstance(self._timeout, list) and len(self._timeout) == 2:
            self._timeout = tuple(self._timeout) 
def update(self, api_obj, data, obj_id=0, url_params=''):
        if not data:
            raise TypeError("Missing object data.")
        if url_params:
            url_params = '?' + url_params.lstrip("?")
        if not obj_id:
            obj_id = data['id']
        url = self.server + '/' + api_obj + '/' + str(obj_id) + url_params
        r = requests.put(url, data=json.dumps(data), headers=self.tokenHeaderJson, verify=self.sslVerify)
        return self.__check_result(r)


    # Delete object using HTTP DELETE request. 
def rest_api_put(self, rest_url, body, api_version):
        """
        PUT request to the REST API - Not tested
        :return: JSON string of the PUT response
        """
        response = requests.put(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            data=body,
            headers=self.sf_headers
        )

        return response 
def _put(self, endpoint, params=None, data=None):
        response = requests.put(self.BASE_URL + endpoint, params=params, json=data, auth=(self.user, self.password))
        return self._parse(response) 
def put(url):
    url = url.strip('/')
    text = random.randint(100000000, 200000000)
    payload = '/{}.txt'.format(text)
    url = url + payload
    data = {'{}'.format(text): '{}'.format(text)}
    r = requests.put(url, data=data, allow_redirects=False, verify=False, headers=get_ua())
    if r.status_code == 201:
        return 'HTTP METHOD PUT url: {}'.format(url) 
def check(url, ip, ports, apps):
    result = ''
    try:
        probe = get_list(ip, ports)
        for url in probe:
            result = put(url)
    except Exception as e:
        pass
    if result:
        return result 
def clean_consul(port, token=''):
    # remove all data from the instance, to have a clean start
    base_uri = 'http://127.0.0.1:%s/v1/' % port
    params = {'recurse': 1}
    if token:
        params['token'] = token
    requests.delete(base_uri + 'kv/', params=params)
    services = requests.get(base_uri + 'agent/services',
                            params=params).json().keys()
    for s in services:
        requests.put(base_uri + 'agent/service/deregister/%s' % s)

    if token:
        acl_tokens = requests.get(base_uri + 'acl/list', params=params).json()
        for t in acl_tokens:
            if t['ID'] != token:
                requests.put(base_uri + 'acl/destroy/%s' % t['ID'],
                             params=params)

        acl_policys = requests.get(base_uri + 'acl/policies',
                                   params=params).json()
        for pls in acl_policys:
            if pls['ID'] != token:
                requests.delete(base_uri + 'acl/policy/%s' % pls['ID'],
                                params=params)

        acl_roles = requests.get(base_uri + 'acl/roles',
                                 params=params).json()
        for role in acl_roles:
            if role['ID'] != token:
                requests.delete(base_uri + 'acl/role/%s' % role['ID'],
                                params=params) 
def handle(event, context):
    response = {
        "Status": "SUCCESS",
        "StackId": event["StackId"],
        "RequestId": event["RequestId"],
        "LogicalResourceId": event["LogicalResourceId"]
    }

    try:
        converted = cogito.to_json(
            event["ResourceProperties"]["Policy"],
            event["ResourceProperties"].get("Substitutions", {})
        )

        response["PhysicalResourceId"] = hashlib.md5(converted.encode("utf-8")).hexdigest()
        response["Data"] = {}
        response["Data"]["PolicyDocument"] = json.dumps({
            "Version": "2012-10-17",
            "Statement": json.loads(converted)
        })
    except cogito.CogitoError as exception:
        response["Status"] = "FAILED"
        response["Resource"] = exception.message

    requests.put(event["ResponseURL"], json.dumps(response))
    return response 
def _put(self, request, data, headers=None):
        url = '{0}{1}'.format(self._url(), request)
        headers = self.headers if headers is None else headers
        response = requests.put(url, data=json.dumps(data), headers=headers, verify=self.verify_cert,
                                timeout=self.timeout)
        return self._validate(response) 
def jsonput(url, data={}, *arg):
    """
    自动将 PUT 请求转换为 JSON
    """
    if url.__class__.__name__ == 'function':
        url = url()
    try:
        return json_moudle.loads(requests.put(url, *arg, data=data, headers=Session.headers,
                                              verify=verify, timeout=3).text)
    except json_moudle.decoder.JSONDecodeError as e:
        log(f'JSON 解析错误,请检查知乎 API 的 URL 是否变化,当前 URL 为:{url}') 
def testCompound(self):
        # test Dataset with compound type
        domain = self.base_domain + "/testCompound.h5"
        helper.setupDomain(domain)
        print("testCompound", domain)
        headers = helper.getRequestHeaders(domain=domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        fields = ({'name': 'temp', 'type': 'H5T_STD_I32LE'},
                    {'name': 'pressure', 'type': 'H5T_IEEE_F32LE'})
        datatype = {'class': 'H5T_COMPOUND', 'fields': fields }
        payload = {'type': datatype, 'shape': 10}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link the new dataset
        name = "dset"
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201) 
def testEmptyShapeAttr(self):
        print("testEmptyShapeAttr", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        attr_name = "attr_empty_shape"
        attr_payload = {'type': 'H5T_STD_I32LE', 'shape': [], 'value': 42}
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, headers=headers, data=json.dumps(attr_payload))
        self.assertEqual(rsp.status_code, 201)  # created

        # read back the attribute
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)  # OK
        rspJson = json.loads(rsp.text)
        self.assertTrue("name" in rspJson)
        self.assertEqual(rspJson["name"], "attr_empty_shape")
        self.assertTrue("type" in rspJson)
        attr_type = rspJson["type"]
        self.assertEqual(attr_type["base"], "H5T_STD_I32LE")
        self.assertTrue("hrefs" in rspJson)
        self.assertEqual(len(rspJson["hrefs"]), 3)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], 42)
        self.assertTrue("shape" in rspJson)
        attr_shape = rspJson["shape"]
        self.assertTrue("class" in attr_shape)
        self.assertEqual(attr_shape["class"], "H5S_SCALAR") 
def testPutVLenString(self):
        # Test PUT value for 1d attribute with variable length string types
        print("testPutVLenString", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        words = ["Parting", "is such", "sweet", "sorrow."]
        fixed_str_type = {"charSet": "H5T_CSET_ASCII",
                "class": "H5T_STRING",
                "length": "H5T_VARIABLE",
                "strPad": "H5T_STR_NULLTERM" }
        data = { "type": fixed_str_type, "shape": 4,
            "value": words}
        attr_name = "str_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], words)
        self.assertTrue("type" in rspJson)
        type_json = rspJson["type"]
        self.assertTrue("class" in type_json)
        self.assertEqual(type_json["class"], "H5T_STRING")
        self.assertTrue("length" in type_json)
        self.assertEqual(type_json["length"], "H5T_VARIABLE") 
def testGetAttributeJsonValue(self):
        # Test GET Attribute value with JSON response
        print("testGetAttributeJsonValue", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        value = [2,3,5,7,11,13]
        data = { "type": 'H5T_STD_I32LE', "shape": 6, "value": value}
        attr_name = "int_arr_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name + "/value"
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertFalse("type" in rspJson)
        self.assertFalse("shape" in rspJson)
        self.assertEqual(rspJson["value"], value) 
def testCreateFolder(self):
        domain = self.base_domain + "/newfolder"
        print("testCreateFolder", domain)
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)
        self.assertFalse("root" in rspJson)  # no root -> folder

        # verify that putting the same domain again fails with a 409 error
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 409)

        # do a get on the new folder
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)

        self.assertTrue("owner" in rspJson)
        self.assertTrue("class" in rspJson)
        self.assertEqual(rspJson["class"], "folder")

        # try doing a un-authenticated request
        if config.get("test_noauth") and config.get("default_public"):
            headers = helper.getRequestHeaders()
            req = helper.getEndpoint() + "/?host=" + domain
            # do a get on the folder with a query arg for host
            rsp = requests.get(req)
            self.assertEqual(rsp.status_code, 200)
            rspJson = json.loads(rsp.text)
            for k in ("class", "owner"):
                self.assertTrue(k in rspJson)
            self.assertFalse("root" in rspJson) 
def testInvalidChildDomain(self):
        domain = self.base_domain + "/notafolder/newdomain.h5"
        # should fail assuming "notafolder" doesn't exist
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.put(req, headers=headers)
        self.assertEqual(rsp.status_code, 404) 
def add_users_to_siteAccess(token, access_mode, allowed_principal_ids):
    headers = {'Authorization': 'Bearer ' + token}
    r = requests.put(CATTLE_AUTH_PROVIDER_URL, json={
        'allowedPrincipalIds': allowed_principal_ids,
        'accessMode': access_mode,
        'responseType': 'json',
    }, verify=False, headers=headers)
    print(r.json()) 
def set_position(self, latitude, longitude):
        """ Set the position of the user using Happn's API
            :param latitude Latitude to position the User
            :param longitude Longitude to position the User
        """

        # Create & Send the HTTP Post to Happn server
        h=headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Length': '342', #@TODO figure out length calculation
            'Content-Type'  : 'application/json'
            })

        url = 'https://api.happn.fr/api/users/' + self.id + '/devices/'+config('DEVICE_ID')
        payload = {
            "alt"       : 20 + random.uniform(-10,10),
            "latitude"  : round(latitude,7),
            "longitude" : round(longitude,7),
        }
        r = requests.put(url,headers=h,data=json.dumps(payload))

        # Check status of Position Update
        if r.status_code == 200:    #OK HTTP status
            self.lat = latitude
            self.lon = longitude
            logging.debug('Set User position at %f, %f', self.lat, self.lon)
        else:
            # Status failed, get the current location according to the server
            #@TODO IMPLEMENT ^
            self.lat = latitude
            self.lon = longitude

            logging.warning("""Server denied request for position change: %s,
                                will revert to server known location""", httpErrors[r.status_code])

            # If unable to change location raise an exception
            raise HTTP_MethodError(httpErrors[r.status_code]) 
def set_matching_age_min(self, age):
        """ Set matching min. age
            :mininum age to like
        """

        # Create and send HTTP PUT to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'matching_age_min' : age
        }
        url = 'https://api.happn.fr/api/users/' + self.id
        try:
            r = requests.put(url, headers=h, data = payload,verify=False)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Set minimum accept age to '+str(age))
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
def set_matching_age_max(self, age):
        """ Set matching max. age
            :maximum age to like
        """

        # Create and send HTTP PUT to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'matching_age_max' : age
        }
        url = 'https://api.happn.fr/api/users/' + self.id
        try:
            r = requests.put(url, headers=h, data = payload,verify=False)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Set maximum accept age to '+str(age))
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
def updateticket(ticket,priority,status):
  """api call for update a tiket in freshdesk"""
  headers = {
    'Content-Type': 'application/json',
  }
  data = { "priority": priority, "status": status }
  json_data=json.dumps(data);
  url=ticket_url+'/'+str(ticket)

  response = requests.put(url, headers=headers, data=json_data, auth=(apikey, 'X'))
  return response 
def state_save(self):
        try:
            data = '{"put": {"state":' + str(json.dumps(self.state)) + '}}'
            response = requests.put(self.config['database']['url'], headers=self.config['database']['headers'], data=data)
            self.log_add_text('helper', str(response.text))
            self.log_add_text('helper', 'saved state ' + str(self.state))
            return
        except Exception as e:
            self.log_add_text('helper', str(e)) 
def upload_file(body, fileName, contentType, contentLength):

    # 1. GET FILE STORAGE URI
    fileUploadPartsResponse = requests.post(fileUploadRequestURI, 
        headers={
            'Authorization': iotHubSasToken,
            'Content-Type': 'application/json'
        },
        data = '{ "blobName": "%s"}' % (fileName)
    )

    print(fileUploadRequestURI)
    print(fileUploadPartsResponse.status_code)
    print(fileUploadPartsResponse.text)

    if fileUploadPartsResponse.status_code == 200:
 
        fileUploadParts = fileUploadPartsResponse.json()
        fileUploadURI = fileUploadURITemplate % (fileUploadParts["hostName"], fileUploadParts["containerName"], fileUploadParts["blobName"], fileUploadParts["sasToken"])
        
        # 2. UPLOAD FILE TO BLOB STORAGE
        uploadResponse = requests.put(fileUploadURI, 
            headers={
                'Content-Type': contentType,
                'Content-Length': contentLength,
                'x-ms-blob-type': 'BlockBlob',
                
            },
            data = body
        )

        print(fileUploadURI)
        print(uploadResponse.status_code)
        print(uploadResponse.text)
        
        if uploadResponse.status_code == 201:

            # 3. GET UPLOAD FILE NOTIFICATION
            notificationResponse = requests.post(notificationURI, 
                headers={
                    'Authorization': iotHubSasToken,
                    'Content-Type': 'application/json'
                },
                data = '{"correlationId": "%s" }' % (fileUploadParts["correlationId"])
            )
    
            print(notificationURI)
            print(notificationResponse.status_code)
            print(notificationResponse.text) 
def _request(self, method, path, query=False, data=False):
        """
        Do the request

        :param method: choose the method to use (post, put or delete)
        :type method: str

        :param path: choose the path to use
        :type path: str

        :param query: choose the query to use
        :type query: str

        :param data: the payload for the post method
        :type data: str

        :return: the response
        :rtype: str or False
        """
        requests_headers = {'Accept': 'application/json',
                            'User-Agent': 'oliver-zehentleitner/unicorn-binance-websocket-api/' +
                                          self.unicorn_binance_websocket_api_version,
                            'X-MBX-APIKEY': str(self.api_key)}
        if query is not False:
            uri = self.restful_base_uri + path + "?" + query
        else:
            uri = self.restful_base_uri + path
        try:
            if method == "post":
                request_handler = requests.post(uri, headers=requests_headers)
            elif method == "put":
                request_handler = requests.put(uri, headers=requests_headers, data=data)
            elif method == "delete":
                request_handler = requests.delete(uri, headers=requests_headers)
            else:
                request_handler = False
        except requests.exceptions.ConnectionError as error_msg:
            logging.critical("BinanceWebSocketApiRestclient->_request() - error_msg: " + str(error_msg))
            return False
        except socket.gaierror as error_msg:
            logging.critical("BinanceWebSocketApiRestclient->_request() - error_msg: " + str(error_msg))
            return False
        if request_handler.status_code == "418":
            logging.critical("BinanceWebSocketApiRestclient->_request() received status_code 418 from binance! You got"
                             "banned from the binance api! Read this: https://github.com/binance-exchange/binance-"
                             "official-api-sphinx/blob/master/rest-api.md#limits")
        elif request_handler.status_code == "429":
            logging.critical("BinanceWebSocketApiRestclient->_request() received status_code 429 from binance! Back off"
                             "or you are going to get banned! Read this: https://github.com/binance-exchange/binance-"
                             "official-api-sphinx/blob/master/rest-api.md#limits")

        try:
            respond = request_handler.json()
        except simplejson.errors.JSONDecodeError as error_msg:
            logging.critical(str(error_msg))
            return False
        self.binance_api_status['weight'] = request_handler.headers.get('X-MBX-USED-WEIGHT')
        self.binance_api_status['timestamp'] = time.time()
        self.binance_api_status['status_code'] = request_handler.status_code
        request_handler.close()
        return respond 
def push_modification(self, modification):
        url = self.API_ROOT + "/repos/{}/{}/contents/{}".format(
            self.head_owner, self.head_repo, modification.file_path
        )

        r = requests.get(url, params={"ref": self.head_ref})
        if not r.ok:
            raise Exception("Can not access to the {}/{}'s content.".format(
                self.head_owner, self.head_repo
            ))
        encoding = r.encoding
        body = r.json()
        content = body["content"]
        content = base64.b64decode(content).decode(encoding)
        sha = body["sha"]
        fix_position = int(modification.line_no) - 1  # read file lines start with 0
        fixed = content
        with StringIO(content) as c:
            lines = c.readlines()
            words = lines[fix_position].split(" ")
            for i, w in enumerate(words):
                _w = SpellChecker.strip(w.strip())
                if _w == modification.target_word:
                    words[i] = words[i].replace(_w, modification.candidates[0])
            
            fixed = " ".join(words) + "\n"
            lines[fix_position] = fixed
            fixed = "".join(lines)
        
        if content != fixed:
            encoded = base64.b64encode(fixed.encode(encoding)).decode(encoding)
            message = "fix typo: {} to {}, line {}".format(
                modification.target_word,
                modification.candidates[0],
                modification.line_no
                )

            payload = {
                "message": message,
                "content": encoded,
                "sha": sha,
                "branch": self.head_ref
            }
            r = requests.put(url, json=payload,headers=make_auth_header(self.installation_id))

            if not r.ok:
                print(r.json())
                r.raise_for_status()
            return True
        
        return False 
def testPostNullSpace(self):
        # test Dataset with null dataspace type
        domain = self.base_domain + "/testPostNullSpace.h5"
        helper.setupDomain(domain)

        print("testNullSpace", domain)
        headers = helper.getRequestHeaders(domain=domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # pass H5S_NULL for shape
        payload = {'type': 'H5T_IEEE_F32LE', 'shape': 'H5S_NULL'}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset1'
        name = 'dset1'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify the dataspace is has a null dataspace
        req = self.endpoint + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        shape = rspJson['shape']
        self.assertEqual(shape['class'], 'H5S_NULL')
        # verify type
        type_json = rspJson["type"]
        self.assertEqual(type_json["class"], 'H5T_FLOAT')
        self.assertEqual(type_json['base'], 'H5T_IEEE_F32LE') 
**************************************************


Python requests.session() Examples

def __init__(self, username, password):
        self.session = requests.session()
        self.session.proxies = urllib.getproxies()
        self.username = username
        self.password = password
        self.headers = {
            "Accept": "*/*",
            "Accept-Encoding": "gzip, deflate",
            "Accept-Language": "en;q=1, fr;q=0.9, de;q=0.8, ja;q=0.7, nl;q=0.6, it;q=0.5",
            "Content-Type": "application/x-www-form-urlencoded; charset=utf-8",
            "X-Robinhood-API-Version": "1.0.0",
            "Connection": "keep-alive",
            "User-Agent": "Robinhood/823 (iPhone; iOS 7.1.2; Scale/2.00)"
        }
        self.session.headers = self.headers
        self.login() 
def __init__(self, product_link, domain):
        '''
        (str, str) -> eBae
        Given a link to an eBay product <product_link> and a catch-all domain
        address <domain>, a random email address is generated and an eBae
        object is returned.
        
        REQ: domain is a catch-all domain
        REQ: product_link is a link to a product listed on eBay
        '''
        self.s = requests.session()
        self.product_link = product_link
        self.s.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36"
        }
        self.proxy_list = read_from_txt("proxies.txt")
        self.email = gen_email(domain) 
def yt(query):
    with requests.session() as s:
         isi = []
         if query == "":
             query = "S1B tanysyz"   
         s.headers['user-agent'] = 'Mozilla/5.0'
         url    = 'http://www.youtube.com/results'
         params = {'search_query': query}
         r    = s.get(url, params=params)
         soup = BeautifulSoup(r.content, 'html5lib')
         for a in soup.select('.yt-lockup-title > a[title]'):
            if '&list=' not in a['href']:
                if 'watch?v' in a['href']:
                    b = a['href'].replace('watch?v=', '')
                    isi += ['youtu.be' + b]
         return isi 
def get_captcha(API_KEY,sitekey,captcha_url):
    global active_threads

    active_threads += 1

    session = requests.session()
    session.cookies.clear()
    randomID = random.getrandbits(16)
    log('Generating Captcha for task ID: ' + str(randomID))
    captcha_id = session.post("http://2captcha.com/in.php?key={}&method=userrecaptcha&googlekey={}&pageurl={}".format(API_KEY, sitekey, captcha_url)).text.split('|')[1]
    recaptcha_answer = session.get("http://2captcha.com/res.php?key={}&action=get&id={}".format(API_KEY, captcha_id)).text
    while 'CAPCHA_NOT_READY' in recaptcha_answer:
        print(recaptcha_answer)
        time.sleep(3)
        recaptcha_answer = session.get("http://2captcha.com/res.php?key={}&action=get&id={}".format(API_KEY, captcha_id)).text
    recaptcha_answer = recaptcha_answer.split('|')[1]
    log('Captcha successfully obtained, task ID: ' + str(randomID))
    saveCaptcha(recaptcha_answer,randomID)
    log('Task ID ' + str(randomID) + ' is closing...')
    active_threads -= 1 
def _input_and_send_code(self, data, factor):
        # Format for user experience
        display_name = DISPLAY_NAMES.get(factor) if DISPLAY_NAMES.get(factor) else factor
        mfa_code = input('Enter {} code: '.format(display_name))
        url = data['_links']['next']['href']
        resp = self.session.post(
            url=url,
            json={
                'stateToken': data['stateToken'],
                'passCode': mfa_code
            }
        )
        if resp.status_code == 200:
            return resp
        elif resp.status_code == 403:
            print('Incorrect or stale code.\n'
                  'Please check code...')
            return self._input_and_send_code(data, factor)
        else:
            raise Exception('Something went wrong.\nresp: {}\n'
                            'You may be locked out of Okta'.format(resp.content)) 
def download_song(song_info, session, mp3_option, download_folder):
    if(song_info['data']):
        if not mp3_option and song_info['size'] < 10:
            logger.info("%s-%s 文件大小小于 10MB, 放弃下载。" %
                        (song_info['songname'], song_info['artist']))
            return None
        else:
            filename = "{0}-{1}.flac".format(
                validate_file_name(song_info['songname']),
                validate_file_name(song_info['artist']))

            filepath = os.path.join(download_folder, filename)
            logger.info("下载中: %s" % filepath)
            try:
                r = session.get(song_info['link'], headers=HEADERS, timeout=3)
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                logger.info("下载完成: %s " % filepath)
            except requests.exceptions.Timeout as err:
                logger.error("%s during download filepath" % err) 
def download_song(song_info, session, mp3_option, download_folder):
    if(song_info['data']):
        if not mp3_option and song_info['size'] < 10:
            logger.info("%s-%s 文件大小小于 10MB, 放弃下载。" %
                        (song_info['songname'], song_info['artist']))
            return None
        else:
            filename = "{0}-{1}.flac".format(
                validate_file_name(song_info['songname']),
                validate_file_name(song_info['artist']))

            filepath = os.path.join(download_folder, filename)
            logger.info("下载中: %s" % filepath)
            try:
                r = session.get(song_info['link'], headers=HEADERS, timeout=3)
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                logger.info("下载完成: %s " % filepath)
            except requests.exceptions.Timeout as err:
                logger.error("%s during download filepath" % err) 
def _login(self, force_login: bool = False):
        try:
            if force_login:
                self._clear_session()
            if not self._session.cookies:
                self._session = self._create_or_load_session()
                self._serial_number = self._load_serial_number_from_file()

                if not self._session.cookies:
                    _LOGGER.info(
                        'No previous session found, will try to logging with username: %s and smartphoneId: %s',
                        self._user, self._smart_phone_Id)

                    authtoken = self._request_token()
                    self._get_cookies(authtoken)

            if not self._serial_number:
                self._get_serial_number()
        except ApiError:
            raise
        except Exception as e:
            raise ApiError('Error during login', None) from e 
def get_html(url,max_delay=15):
    '''
    This function extract raw_html file
    :param url: url
    :type url:str
    :return: html data
    '''
    time.sleep(create_random_sleep(max_time=max_delay))
    if internet()==True:
        new_session=requests.session()
        new_session.cookies.clear()
        raw_html=new_session.get(url)
        new_session.close()
        raw_data=raw_html.text
        return raw_data
    else:
        print("Error In Internet") 
def serch_images(self, generate_query, maximum):
        results = []
        total = 0
        while True:
            # search
            html = self.session.get(next(generate_query)).text
            soup = BeautifulSoup(html, "lxml")
            elements = soup.select(".rg_meta.notranslate")
            jsons = [json.loads(e.get_text()) for e in elements]
            image_url_list = [js["ou"] for js in jsons]

            # add search results
            if not image_url_list:
                cprint("No more images.", "yellow")
                break
            elif len(image_url_list) > maximum - total:
                results += image_url_list[: maximum - total]
                break
            else:
                results += image_url_list
                total += len(image_url_list)

        cprint(f"Found {len(results)} images.", "green")
        return results 
def put_object(self, container_name, key, data):
        """
        Put an object in Swift. Override the object if the key already exists.
        :param key: key of the object.
        :param data: data of the object
        :type data: str/bytes
        :return: None
        """
        url = '/'.join([self.endpoint, container_name, key])
        try:
            res = self.session.put(url, data=data)
            status = 'OK' if res.status_code == 201 else 'Error'
            try:
                logger.debug('PUT Object {} - Size: {} - {}'.format(key, sizeof_fmt(len(data)), status))
            except Exception:
                logger.debug('PUT Object {} - {}'.format(key, status))
        except Exception as e:
            print(e) 
def head_object(self, container_name, key):
        """
        Head object from Swift with a key. Throws StorageNoSuchKeyError if the given key does not exist.
        :param key: key of the object
        :return: Data of the object
        :rtype: str/bytes
        """
        url = '/'.join([self.endpoint, container_name, key])
        try:
            res = self.session.head(url)
            if res.status_code == 200:
                return res.headers
            elif res.status_code == 404:
                raise StorageNoSuchKeyError(container_name, key)
            else:
                raise Exception('{} - {}'.format(res.status_code, key))
        except Exception as e:
            raise StorageNoSuchKeyError(container_name, key) 
def delete_objects(self, container_name, key_list):
        """
        Delete a list of objects from Swift.
        :param bucket: bucket name
        :param key: data key
        """
        headers={'X-Auth-Token': self.token,
                 'X-Bulk-Delete': 'True'}

        keys_to_delete = []
        for key in key_list:
            keys_to_delete.append('/{}/{}'.format(container_name, key))

        keys_to_delete = '\n'.join(keys_to_delete)
        url = '/'.join([self.endpoint, '?bulk-delete'])
        return self.session.delete(url, data=keys_to_delete, headers=headers) 
def list_objects(self, container_name, prefix=''):
        """
        Lists the objects in a bucket. Throws StorageNoSuchKeyError if the given bucket does not exist.
        :param key: key of the object
        :return: Data of the object
        :rtype: str/bytes
        """
        if prefix:
            url = '/'.join([self.endpoint, container_name, '?format=json&prefix='+prefix])
        else:
            url = '/'.join([self.endpoint, container_name, '?format=json'])
        try:
            res = self.session.get(url)
            objects = res.json()

            # TODO: Adapt to Key and Size
            return objects
        except Exception as e:
            raise e 
def download_song(song_info, session, mp3_option, download_folder, min_size):
    if(song_info['data']):
        if not mp3_option and song_info['size'] < min_size:
            logger.info("%s-%s 文件大小小于 10MB, 放弃下载。" %
                        (song_info['songname'], song_info['artist']))
            return None
        else:
            filename = "{0}-{1}.flac".format(
                validate_file_name(song_info['songname']),
                validate_file_name(song_info['artist']))

            filepath = os.path.join(download_folder, filename)
            logger.info("下载中: %s" % filepath)
            try:
                r = session.get(song_info['link'], headers=HEADERS, timeout=3)
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                logger.info("下载完成: %s " % filepath)
            except requests.exceptions.Timeout as err:
                logger.error("%s during download filepath" % err) 
def dynamic_global_properties(self):
        """Returns the globals used in the game.

        Example result:
            ```
            {
                'daily_percent': 3,
                'heist_percent': 3,
                'last_prod_update': '2019-03-04T12:55:44.001Z',
                 'drug_production_rate': 3671.530999999977,
                 'heist_pool': 82403306,
                 'balance': '66403.257 STEEM',
                 'steemprice': 0.3730699512
            }
            ```

        :return (dict): Game data
        """
        return self.session.get(
            self.base_url
        ).json() 
def login(self):
        data = "password=%s&username=%s" % (self.password, self.username)
        res = self.session.post(self.endpoints['login'], data=data)
        res = res.json()
        self.auth_token = res['token']
        self.headers['Authorization'] = 'Token '+self.auth_token 
def investment_profile(self):
        self.session.get(self.endpoints['investment_profile']) 
def instruments(self, stock=None):
        res = self.session.get(self.endpoints['instruments'], params={'query':stock.upper()})
        res = res.json()
        return res['results'] 
def quote_data(self, stock):
        params = { 'symbols': stock }
        res = self.session.get(self.endpoints['quotes'], params=params)
        res = res.json()
        return res['results'][0] 
def WriteDB(information):
    for data in information:
        insert_data = GooglePlay(
            App=data['app'],
            Link=data['link'],
            Autor=data['autor'],
            Rate=data['rate'],
            Download=data['download'],
            Publish=datetime.datetime.strptime(data['publish'], "%Y年%m月%d日").date(),
            Item=data['item'],
        )
        db.session.add(insert_data)
    db.session.commit() 
def get_yzmjpg(url):
    data={
        'login_site': 'E',
        'module': 'login',
        'rand': 'sjrand',
    }
    res=session.get(url,params=data)
    with open('yzm.jpg','wb') as f:
        f.write(res.content) 
def check_jpg(url):
    answer=get_point(input('请输入验证码位置'))
    data={
        'answer': answer,
        'rand': 'sjrand',
        'login_site': 'E',
    }
    res=session.get(url,params=data)
    print(res.content.decode()) 
def __init__(self):
    self.Talk = Talk()
    self._session = requests.session()
    self._headers = {'X-Line-Application': 'IOSIPAD\t7.14.0\tiPhone OS\t10.12.0', 'X-Line-Access': 'Emp1jl3qOjxCjXEhmaN5.QdLXoVPaKOU6WpvD80Sijq.NcwnmLOaI/dIyi3Y84WTCOxbNTN27m3ODDpkMLDPY64=', 'User-Agent': 'Line/7.14.0'} 
def __init__(self, proxies=None):
        self.session = requests.session()
        if proxies is not None:
            self.session.proxies = proxies
        self.session.headers.update(UA) 
def get(self, url, **kwargs):
        """
        :rtype: requests.Response
        """
        if 'timeout' in kwargs:
            kwargs.pop('timeout')
        return self.session.get(url, timeout=(2, 30), **kwargs) 
def __init__(self, okta_org: str, usr: str, pw: str, app_url: str, mfa_choice: str):
        self.okta: OktaEndpoints = OktaEndpoints(okta_org, app_url)
        self.usr = usr
        self.pw = pw
        self.mfa_choice = mfa_choice
        self.interactive: bool = True
        self.session: requests.Session = requests.session()
        self.session.headers['Accept'] = 'application/json'
        self.session.headers['Content-Type'] = 'application/json' 
def _authenticate_primary(self):
        self._get_credentials()
        data = {
            "username": self.usr,
            "password": self.pw,
            "options": {
                "multiOptionalFactorEnroll": True,
                "warnBeforePasswordExpired": True,
            }
        }
        resp = self.session.post(url=self.okta.authn, json=data)
        if resp.status_code == requests.codes.ok:
            return resp
        else:
            resp.raise_for_status() 
def _initiate_mfa(self, factor, state_token):
        data = {
            'stateToken': state_token
        }
        return self.session.post(
            url=factor['_links']['verify']['href'],
            json=data
        ) 
def _get_token(self, data):
        if data.get('status') not in HANDLED_STATUS:
            raise Exception("Something went wrong.\n"
                            "Don't know how to handle status '{}'".format(data.get('status')))
        if data['status'] != 'SUCCESS':
            data = self._verify_via_mfa(data)
        token = data.get('sessionToken')
        if not token:
            raise Exception('No session token found in response: \n{}'.format(data))
        return token 
def get_cookies(self):
        base_url = 'https://yz.chsi.com.cn/apply/cjcx'
        session = requests.session()
        base_resp = session.get(base_url, headers=self.headers)
        self.cookies = base_resp.cookies 
def main():
    start = time.time()

    if not os.path.exists(DOWNLOAD_DIR):
        os.mkdir(DOWNLOAD_DIR)

    url, mp3_option = get_args()
    if mp3_option:
        logger.info("将下载所有歌曲, 包括 MP3 格式.")
    song_list_name, song_list = fetch_song_list(url)
    logger.info("歌单中包含的歌曲有: %s" % song_list)
        
    download_folder = os.path.join(DOWNLOAD_DIR, validate_file_name(song_list_name))
    if not os.path.exists(download_folder):
        os.mkdir(download_folder)

    with ThreadPoolExecutor(max_workers=10) as executor:
        song_ids = executor.map(get_songid, song_list)
        song_infos = executor.map(get_song_info, song_ids)
        logger.info("获取歌曲信息完成，开始下载。")
        session = requests.session()
        download = partial(download_song, session=session, mp3_option=mp3_option,
                           download_folder=download_folder)
        executor.map(download, song_infos)

    end = time.time()
    logger.info("共耗时 %s s", str(end - start))


# 禁止 requests 模组使用系统代理 
def __init__(self, game):
        if game not in self.games:
            raise NotImplementedError(""""parser for game "{}" doesn't exist""".format(game))
        if game == 'all':
            game = ''
        self.game_url = self.url_base + game
        self.session = requests.session() 
def download_matches(self, crawl_stream: bool = True) -> List[Match]:
        """
        Downloads live and upcoming matches.
        :return: list of Match objects
        """
        resp = self.session.get(self.game_url)
        if resp.status_code != 200:
            raise ConnectionRefusedError('Got response error {}'.format(resp.status_code))
        sel = Selector(text=resp.text)
        matches = list(self.find_matches(sel))
        if crawl_stream:
            matches = self.update_match_streams(matches)
        return matches 
def download_history(self, crawl_stream: bool = True) -> List[Match]:
        """
        Downloads recent matches.
        :return: list of Match objects
        """
        resp = self.session.get('{}/gosubet'.format(self.game_url))
        if resp.status_code != 200:
            raise ConnectionRefusedError('Got response error {}'.format(resp.status_code))
        sel = Selector(text=resp.text)
        matches = list(self.find_history(sel))
        if crawl_stream:
            matches = self.update_match_streams(matches)
        return matches 
def update_match_streams(self, matches: List[Match]) -> List[Match]:
        """Populate Match objects with stream urls"""
        updated = []
        for item in matches:
            # Populate stream data if match is live
            if not item['time_secs']:
                resp = self.session.get(item['url'])
                sel_detailed = Selector(text=resp.text)
                item['stream'] = sel_detailed.xpath("//div[@class='matches-streams']"
                                                    "/span[.//a[re:test(text(),'english', 'i')]]"
                                                    "//iframe/@src").extract_first()
                item['stream'] = clean_stream_url(item['stream'])
            updated.append(item)
        return updated 
def _create_or_load_session(self):
        session = requests.Session()
        cookies = self._load_cookies_from_file()
        _LOGGER.debug('Found cookies %s', cookies)
        if cookies is not None:
            session.cookies = cookies
        return session 
def _clear_session(self):
        self._clear_cookie()
        self._clear_serial_number()
        self._session.close()
        self._session = requests.session()
        FileUtils.delete_dir(self._file_path) 
def get_first_page(tag):
    # step 1, 访问网站,有新asp cookie的header
    new_header = build_valid_header()
    # step 2, login, 不确定是不是必须的步骤
    session.get(constants.login_uri, headers=new_header)
    # step 3, 使用分类tag初始化后端
    session.get(constants.search_handler_uri, params=build_search_handler_query(tag), headers=new_header)
    # step 4, 获取分组id,即ctl的html
    group_response = session.get(constants.group_uri, params=build_group_query(), headers=new_header)
    # step 5, get ctl
    ctl = find_doctor_ctl(group_response.text)
    # step 6 获取第一页,主要目的是queryId和总条数
    res = session.get(constants.ith_page_uri, params=build_first_page_query(ctl), headers=new_header)
    page_html = res.text
    return ctl, new_header, page_html 
def build_paper_url(parent_tag_tag_tuple):
    """

    :param parent_tag_tag_tuple: tuple
    :return: PaperURL Object or None
    """
    parent_tag, tag = parent_tag_tag_tuple

    result = cnki_class.PaperURL([], tag, parent_tag)

    ctl, new_header, first_page_html = get_first_page(tag)
    item_num = find_item_num(first_page_html)
    page_num = calculate_page_num(item_num)

    if page_num == 1:
        paper_list = parse_url_list(first_page_html)
        result.urls = paper_list
    else:
        query_id = parse_query_id(first_page_html)
        for index in range(page_num):
            current_page = index + 1
            ith_page = session.get(constants.ith_page_uri,
                                   params=build_ith_page_query(ctl, current_page, query_id),
                                   headers=new_header).text
            if is_check_code_page(ith_page):
                ctl, new_header, first_page_html = get_first_page(tag)
                ith_page = session.get(constants.ith_page_uri,
                                       params=build_ith_page_query(ctl, current_page, query_id),
                                       headers=new_header).text
            paper_list = parse_url_list(ith_page)
            result.urls += paper_list
    if len(result.urls) == 0:
        return None
    collection_utils.unique(result.urls, lambda x, y: cmp(x, y))
    result.urls = [uri.replace('kns', 'KCMS') for uri in result.urls]
    return result


############### build paper url end ###############
############### other process ############### 
def login(username, password):
    '''
    Function to log into user's google account.
    '''
    # prepare requests session object. It will be used in all the consequent requests.
    session = requests.session()

    # TODO: Don;t hard code, see https://github.com/HashGrowth/py-google-auth/issues/2 for details.
    # url to finally redirect to.
    play_console_base_url = "https://play.google.com/apps/publish"

    # login normally
    response, error, session = normal_login(session, username, password, play_console_base_url)

    return response, error, session 
def serialize_session(session):
    '''
    Takes a session object and serializes its attribute dictionary.
    '''

    session_dict = session.__dict__
    encoded = jsonpickle.encode(session_dict)
    return encoded 
def deserialize_session(session):
    '''
    Takes a dictionary having a session object's atributes and deserializes it into a sessoin
    object.
    '''

    decoded = jsonpickle.decode(session)
    new_session = requests.session()
    new_session.__dict__.update(decoded)
    return new_session 
def clean_session(session):
    '''
    We embedded some extra variables while sending session to network,
    These are not part of requests session, so we need to remove them.
    This method removes those extra attributes.
    '''

    attrs = ['next_url', 'q_params', 'select_method_url', 'prev_payload']
    for attr in attrs:
        if attr in session.__dict__:
            session.__delattr__(attr)

    return session 
def handle_default_method(default_method, response, session):
    '''
    This function is used when the default method is not available.
    '''
    response_data = {}

    # create payload from response text
    payload = make_payload(response.text)

    # current response url is used to make next POST call for second step of login and
    # payload contains parameters that are to be sent with POST request, since we need
    # these in the function that is called on step two end point, we save it in the
    # session object and send in response so that we get it back with next request.

    session.next_url = response.url
    session.prev_payload = payload

    # Google prompt need two variables from the response page which are used to make
    # POST request to an api where prompt's respose is recorded to know what user has
    # responded for prompt. saving them into query_params.
    if default_method == 1:
        query_params = get_query_params(response.text)
        session.query_params = query_params

    # if default method is text message, get the phone number to which otp was sent.
    if default_method == 3:
        phone_num = get_phone_number(response.text)
        response_data['number'] = phone_num

    response_data['default_method'] = default_method

    return response_data, session 
def __init__(self):
        self.GOOGLE_IMAGE_SEARCH_URL = "https://www.google.co.jp/search"
        self.session = requests.session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (X11; Linux x86_64; rv:10.0) \
                    Gecko/20100101 Firefox/10.0"
            }
        ) 
def __init__(self, endpoint, namespace, api_key=None, auth=None, insecure=False, user_agent=None):
        """
        OpenWhiskClient Constructor

        :param endpoint: OpenWhisk endpoint.
        :param namespace: User namespace.
        :param api_key: User AUTH Key.  HTTP Basic authentication.
        :param auth: Authorization token string "Basic eyJraWQiOiIyMDE5MDcyNCIsImFsZ...".
        :param insecure: Insecure backend. Disable cert verification.
        :param user_agent: User agent on requests.
        """
        self.endpoint = endpoint.replace('http:', 'https:')
        self.namespace = namespace
        self.api_key = api_key
        self.auth = auth

        if self.api_key:
            api_key = str.encode(self.api_key)
            auth_token = base64.encodebytes(api_key).replace(b'\n', b'')
            self.auth = 'Basic %s' % auth_token.decode('UTF-8')

        self.session = requests.session()

        if insecure:
            self.session.verify = False

        self.headers = {
            'content-type': 'application/json',
            'Authorization': self.auth,
        }

        if user_agent:
            default_user_agent = self.session.headers['User-Agent']
            self.headers['User-Agent'] = default_user_agent + ' {}'.format(user_agent)

        self.session.headers.update(self.headers)
        adapter = requests.adapters.HTTPAdapter()
        self.session.mount('https://', adapter) 
def create_action(self, package, action_name, image_name, code=None, memory=None,
                      timeout=30000, kind='blackbox', is_binary=True, overwrite=True):
        """
        Create an IBM Cloud Functions action
        """
        data = {}
        limits = {}
        cfexec = {}
        limits['memory'] = memory
        limits['timeout'] = timeout
        data['limits'] = limits

        cfexec['kind'] = kind
        if kind == 'blackbox':
            cfexec['image'] = image_name
        cfexec['binary'] = is_binary
        cfexec['code'] = base64.b64encode(code).decode("utf-8") if is_binary else code
        data['exec'] = cfexec

        logger.debug('I am about to create a new cloud function action: {}'.format(action_name))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package,
                        action_name + "?overwrite=" + str(overwrite)])

        res = self.session.put(url, json=data)
        resp_text = res.json()

        if res.status_code == 200:
            logger.debug("OK --> Created action {}".format(action_name))
        else:
            msg = 'An error occurred creating/updating action {}: {}'.format(action_name, resp_text['error'])
            raise Exception(msg) 
def get_action(self, package, action_name):
        """
        Get an IBM Cloud Functions action
        """
        logger.debug("I am about to get a cloud function action: {}".format(action_name))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package, action_name])
        res = self.session.get(url)
        return res.json() 
def list_actions(self, package):
        """
        List all IBM Cloud Functions actions in a package
        """
        logger.debug("I am about to list all actions from: {}".format(package))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package, ''])
        res = self.session.get(url)
        if res.status_code == 200:
            return res.json()
        else:
            return [] 
**************************************************


Python requests.delete() Examples

def _send_raw_http_request(self, method, url, data=None):
        self.__logger.debug('%s %s' % (method, url))
        if method in ['POST', 'PUT', 'PATCH']:
            self.__logger.log(TINTRI_LOG_LEVEL_DATA, 'Data: %s' % data)

        headers = {'content-type': 'application/json'}
        if self.__session_id:
            headers['cookie'] = 'JSESSIONID=%s' % self.__session_id

        if method in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE']:
            if method == 'GET': httpresp = requests.get(url, headers=headers, verify=False)
            elif method == 'POST': httpresp = requests.post(url, data, headers=headers, verify=False)
            elif method == 'PUT': httpresp = requests.put(url, data, headers=headers, verify=False)
            elif method == 'PATCH': httpresp = requests.patch(url, data, headers=headers, verify=False)
            elif method == 'DELETE': httpresp = requests.delete(url, headers=headers, verify=False)
            self._httpresp = httpresp # self._httpresp is for debugging only, not thread-safe
            return httpresp
        else:
            raise TintriError(None, message='Invalid HTTP method: ' + method) # This should never happen 
def run(self):
        
        if os.stat("{date}.mrc.bz2".format(date=self.date)).st_size > 0:
            path="{date}-data".format(date=self.date)
            for index in os.listdir(path):
                for f in os.listdir(path+"/"+index):
                    cmd="esbulk -z -verbose -server {host} -w {workers} -index {index} -type schemaorg -id identifier {fd}".format(**self.config,index=index,fd=path+"/"+index+"/"+f)
                    output=shellout(cmd)
        #for f in os.listdir(path+"/resources"):
        #    cmd=". ~/git/efre-lod-elasticsearch-tools/init_environment.sh && "
        #    cmd+="~/git/efre-lod-elasticsearch-tools/processing/merge2move.py -server {host} -stdin < {fd} | ".format(**self.config,fd=path+"/resources/"+f)
        #    cmd+="~/git/efre-lod-elasticsearch-tools/enrichment/sameAs2id.py  -searchserver {host} -stdin  | ".format(**self.config,fd=path+"/resources/"+f)
        #    cmd+="esbulk -verbose -server {rawdata_host} -w {workers} -index {index} -type schemaorg -id identifier".format(**self.config,index="resources-fidmove")
        #    output=shellout(cmd)
        put_dict("{host}/date/actual/4".format(**self.config),{"date":str(self.now)})
        with gzip.open("slub_resources_sourceid0.ldj","wt") as outp:
            for record in esgenerator(host="{host}".format(**self.config).rsplit("/")[2].rsplit(":")[0],port="{host}".format(**self.config).rsplit("/")[2].rsplit(":")[1],index="resources",type="schemaorg",body={"query":{"bool":{"must":[{"match":{"offers.offeredBy.branchCode.keyword":"DE-14"}},{"match":{"_sourceID.keyword":"0"}}]}}},headless=True):
                print(json.dumps(record),file=outp)
        #delete("{host}/slub-resources/schemaorg".format(**self.config))
        #put_dict("{host}/slub-resources".format(**self.config),{"mappings":{"schemaorg":{"date_detection":False}}})
        #cmd="esbulk -z -verbose -server {host} -w {workers} -index slub-resources -type schemaorg -id identifier slub_resources_sourceid0.ldj".format(**self.config)
        #output=shellout(cmd) 
def autoscale(self, proc_type, autoscale):
        """
        Set autoscale rules for the application
        """
        name = '{}-{}'.format(self.id, proc_type)
        # basically fake out a Deployment object (only thing we use) to assign to the HPA
        target = {'kind': 'Deployment', 'metadata': {'name': name}}

        try:
            # get the target for autoscaler, in this case Deployment
            self._scheduler.hpa.get(self.id, name)
            if autoscale is None:
                self._scheduler.hpa.delete(self.id, name)
            else:
                self._scheduler.hpa.update(
                    self.id, name, proc_type, target, **autoscale
                )
        except KubeHTTPException as e:
            if e.response.status_code == 404:
                self._scheduler.hpa.create(
                    self.id, name, proc_type, target, **autoscale
                )
            else:
                # let the user know about any other errors
                raise ServiceUnavailable(str(e)) from e 
def delete_listen_key(self, listen_key):
        """
        Delete a specific listen key

        :param listen_key: the listenkey you want to delete
        :type listen_key: str

        :return: the response
        :rtype: str or False
        """
        logging.debug("BinanceWebSocketApiRestclient->delete_listen_key(" + str(listen_key) + ")")
        method = "delete"
        try:
            return self._request(method, self.path_userdata, False, {'listenKey': str(listen_key)})
        except KeyError:
            return False
        except TypeError:
            return False 
def delete_post(self, pk, force=False):
        """
        Delete a Post.

        Arguments
        ---------

        pk : int
            The post id you want to delete.
        force : bool
            Whether to bypass trash and force deletion.
        """
        resp = self._delete('posts/{0}'.format(pk), params=locals())

        if resp.status_code == 200:
            return True
        else:
            raise Exception(resp.json())

    # Post Reivion Methods 
def delete_request(common_name, user="root"):
    # Validate CN
    if not re.match(const.RE_COMMON_NAME, common_name):
        raise ValueError("Invalid common name")

    path, buf, csr, submitted = get_request(common_name)
    os.unlink(path)

    logger.info("Rejected signing request %s by %s" % (
        common_name, user))

    # Publish event at CA channel
    push.publish("request-deleted", common_name)

    # Write empty certificate to long-polling URL
    requests.delete(
        config.LONG_POLL_PUBLISH % hashlib.sha256(buf).hexdigest(),
        headers={"User-Agent": "Certidude API"}) 
def _call(self, method, endpoint, payload=None):
        """
        Call the endpoint and return the response
        """
        resp = None
        shuffle(self.hosts)
        for index in xrange(len(self.hosts)):
            url = "http://%s/v1%s" % (self.hosts[index], endpoint)
            req_args = {'timeout': 10, 'headers': {'Content-Type': 'application/json'}}
            try:
                if method == _GET:
                    resp = requests.get(url, **req_args)
                elif method == _POST:
                    resp = requests.post(
                        url, data=payload, **req_args)
                elif method == _DELETE:
                    resp = requests.delete(url, **req_args)
                break
            except requests.exceptions.RequestException:
                continue
        if resp is None:
            raise DkronClientException("No valid host found")
        return resp 
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
def unsubscribe(self, user_id):
        """Unsubscribe the given user.

        Args:
            user_id: ID of the user to unsubscribe.

        Returns: If successful, returns the ID of the unsubscribed user.

        """
        request_url = API_URL + 'users/' + str(user_id) + '/subscriptions'
        r = requests.delete(url=request_url, cookies={'jwt_token': self.jwt})

        json_response = r.json()
        removed_subscription = json_response['removedSubscription']

        return removed_subscription

    # --- Deck CRUD 
def delete_deck(self, deck_id):
        """Delete an existing deck.

        Args:
            deck_id (str): The ID of the Deck to delete.

        Returns:
            Deck: The deleted Deck object if deletion was successful.

        """
        if not isinstance(deck_id, str):
            raise ValueError("'deck_id' parameter must be of type str")

        headers = DEFAULT_HEADERS

        r = requests.delete(url=API_URL + 'decks/' + deck_id, headers=headers,
                            cookies={'jwt_token': self.jwt})

        json_data = r.json()
        deleted_deck = json_converter.json_to_deck(json_data)

        return deleted_deck

    # --- Favorites CR(U)D 
def remove_favorite(self, user_id, favorite_id):
        """Add a deck to the current user's favorites.

        Args:
            user_id (int): ID of the user to favorite the deck for.
            favorite_id (str): The ID of the favorite to be removed.

        Returns:
            str: The ID of the removed favorite.

        """
        request_url = API_URL + 'users/%d/favorites/%s' % (user_id,
                                                           favorite_id)
        r = requests.delete(url=request_url, cookies={'jwt_token': self.jwt})

        json_response = r.json()
        removed_favorite_id = json_response['removedFavoriteId']

        return removed_favorite_id

    # --- Search 
def del_user(self, username, asserts_in=None):
        """ Delete user.

        Name:        "DELETE_users",
        Method:      "DELETE",
        Pattern:     "users/{username}",

        Args:
            username: name of user that is going to be deleted
            asserts_in: assert values for this call and this method
        """
        pattern = "users/{}".format(username)
        request = requests.delete(
            CONF.config["usmqe"]["api_url"] + pattern,
            auth=self._auth)
        self.print_req_info(request)
        self.check_response(request, asserts_in) 
def send_msg(self, _type, url, message, **kwargs):
        response = None
        try:
            if _type == 'post':
                response = requests.post(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'put':
                response = requests.put(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'get':
                response = requests.get(url, headers=WebClient.headers, data=message, **kwargs)
            else:
                response = requests.delete(url, headers=WebClient.headers, data=message, **kwargs)
        except requests.RequestException as exception:
            logger.info('Requests fail - exception %s', exception)
            response = None
        finally:
            reply = self.__process_msg_response(response)
            logger.info('Requests - response %s', response)
            if reply:
                return reply.text
            return reply 
def disconnect(self):
        '''
        Description: Disconnection method.
        Input:       No input
        Output:      Two possible values:
                 (0, error_info): Unsucessful disconnection, error_info contain the cause of the error
                 (1, 'Disconnection sucessful): Sucessful disconnection
        '''
        url = 'https://%s/php/session.php' % self.atdserver

        try:
            r = requests.delete(url, headers=self.sessionhdr, verify=False)
        except Exception as e:
            error_info = 'Error disconnecting from ATD:\n %s' % e
            return (0, error_info)
        if r.status_code == 200:
            server_info = json.loads(r.content)

            if server_info['success'] is True:
                return(1, 'Disconnection successful')
            else:
                error_info = 'Error disconecting from ATD - Check credentials or content type header'
                return(0, error_info)
        else:
            error_info = 'Error disconnection from ATD, Status Code: %d' % r.status_code
            return(0, error_info) 
def delete(self):
        reply = requests.delete("%s/job/%d" % (self.url, self.id))
        if reply.status_code != 200:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
def sendSignedDeleteRequest(self, uri):
        r = requests.delete(self.endpoint + uri, auth=self.auth) 
def deleteAlbum(self,gid,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        r = requests.delete(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            )
        return r.json() 
def stop(self):
        super().stop()
        if self.server_impl == 'flask':
            requests.delete('http://localhost:{port}/_shutdown'.format(port=str(self.port)))
        elif self.server_impl == 'gevent' and self.server:
            self.server.stop() 
def deleteAlbum(self,gid,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        r = requests.delete(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            )
        return r.json() 
def delete(self):
        return requests.delete(self.current_url) 
def run(self):
        r=delete("{server}/{index}".format(**self.config))
        put_dict("{server}/{index}".format(**self.config),{"mappings":{"{type}".format(**self.config):{"properties":{"location":{"type":"geo_point"}}}}})
        cmd="esbulk -z -server {server} -index {index} -type {type} -w {workers} -id id -verbose {file}.ldj.gz".format(**self.config)
        output=shellout(cmd) 
def run(self):
        #delete("{rawdata_host}/kxp-tit-{date}".format(**self.config,date=self.yesterday.strftime("%y%m%d")))
        #delete("{rawdata_host}/kxp-lok-{date}".format(**self.config,date=self.yesterday.strftime("%y%m%d")))
        cmd=". ~/git/efre-lod-elasticsearch-tools/init_environment.sh && ~/git/efre-lod-elasticsearch-tools/processing/esmarc.py  -z -server {rawdata_host}/kxp-de14/mrc -idfile ids.txt -prefix {date}-kxp".format(**self.config,date=self.yesterday.strftime("%y%m%d"))
        output=shellout(cmd)
        sleep(5) 
def run(self):
        with open("{date}-toDelete.txt".format(date=self.date),"r") as inp:
            for url in inp:
                print(url.strip())
                #delete(url.strip()) 
def delete(self, *args, **kwargs):
        """Delete this application including all containers"""
        self.log("deleting environment")
        try:
            # check if namespace exists
            self._scheduler.ns.get(self.id)

            try:
                self._scheduler.ns.delete(self.id)

                # wait 30 seconds for termination
                for _ in range(30):
                    try:
                        self._scheduler.ns.get(self.id)
                    except KubeHTTPException as e:
                        # only break out on a 404
                        if e.response.status_code == 404:
                            break
            except KubeException as e:
                raise ServiceUnavailable('Could not delete Kubernetes Namespace {} within 30 seconds'.format(self.id)) from e  # noqa
        except KubeHTTPException:
            # it's fine if the namespace does not exist - delete app from the DB
            pass

        self._clean_app_logs()
        return super(App, self).delete(*args, **kwargs) 
def _clean_app_logs(self):
        """Delete application logs stored by the logger component"""
        try:
            url = 'http://{}:{}/logs/{}'.format(settings.LOGGER_HOST,
                                                settings.LOGGER_PORT, self.id)
            requests.delete(url)
        except Exception as e:
            # Ignore errors deleting application logs.  An error here should not interfere with
            # the overall success of deleting an application, but we should log it.
            err = 'Error deleting existing application logs: {}'.format(e)
            self.log(err, logging.WARNING) 
def _update_application_service(self, namespace, app_type, port, routable=False, annotations={}):  # noqa
        """Update application service with all the various required information"""
        service = self._fetch_service_config(namespace)
        old_service = service.copy()  # in case anything fails for rollback

        try:
            # Update service information
            for key, value in annotations.items():
                if value is not None:
                    service['metadata']['annotations']['router.deis.io/%s' % key] = str(value)
                else:
                    service['metadata']['annotations'].pop('router.deis.io/%s' % key, None)
            if routable:
                service['metadata']['labels']['router.deis.io/routable'] = 'true'
            else:
                # delete the annotation
                service['metadata']['labels'].pop('router.deis.io/routable', None)

            # Set app type selector
            service['spec']['selector']['type'] = app_type

            # Find if target port exists already, update / create as required
            if routable:
                for pos, item in enumerate(service['spec']['ports']):
                    if item['port'] == 80 and port != item['targetPort']:
                        # port 80 is the only one we care about right now
                        service['spec']['ports'][pos]['targetPort'] = int(port)

            self._scheduler.svc.update(namespace, namespace, data=service)
        except Exception as e:
            # Fix service to old port and app type
            self._scheduler.svc.update(namespace, namespace, data=old_service)
            raise ServiceUnavailable(str(e)) from e 
def delete_ip(self,ip_id):
    """
    Deletes the IP associated with the supplied CRITs GUID
    Depending on the type of error, the function will either exit or return False.

    :param ip_id: The CRITs GUID for the IP that will be deleted.
    :type ip_id: str
    :returns: boolean
    """

    if ip_id == None or ip_id == "":
      print "An IP ID must be supplied to delete_ip!"
      exit(1)

    url = self.CRITs_URL + 'ips/' + ip_id + '/' + '?username=' + self.username + '&api_key=' + self.api_key 

    data = {}

    try:
      r = requests.delete(url, data=data, verify=self.verify)
    except requests.exceptions.ConnectionError as e:
      print "delete_ip error: Could not connect to " + url
      exit(1)
    except requests.exceptions.Timeout:
      print "delete_ip error: Timeout connecting to " + url
      exit(1)

    #if self.debug:
    #  print ">>>delete_ip response<<<\n"
    #  print r.text

    if r.status_code == 200:
      if self.debug:
        print "Successfully deleted "+ ip_id
      return (True)
    elif self.debug:
      print "Error with deleting IP GUID: " + ip_id + " : " + str(r.status_code)
      print r.text

    return (False) 
def delete_campaign(self,c_id):
    """
    Deletes the Campaign associated with the supplied CRITs GUID.
    Depending on the type of error, the function will either exit or return False.

    :param c_id: The CRITs campaign GUID for deletion.
    :type c_id: str
    :returns: boolean
    """

    if c_id == None or c_id == "":
      print "A campaign ID must be supplied to delete_campaign!"
      exit(1)

    url = self.CRITs_URL + 'campaigns/' + c_id + '/' + '?username=' + self.username + '&api_key=' + self.api_key 

    data = {}

    try:
      r = requests.delete(url, data=data, verify=self.verify)
    except requests.exceptions.ConnectionError as e:
      print "delete_campaign error: Could not connect to " + url
      exit(1)
    except requests.exceptions.Timeout:
      print "delete_campaign error: Timeout connecting to " + url
      exit(1)

    #if self.debug:
    #  print ">>>delete_campaign response<<<\n"
    #  print r.text

    if r.status_code == 200:
      if self.debug:
        print "Successfully deleted "+ c_id
      return (True)
    elif self.debug:
      print "Error with campaign deletion: " + c_id + " : " + str(r.status_code)
      print r.text

    return (False) 
def _delete(self, endpoint, params={}):
        """
        Private function for making DELETE requests.

        Arguments
        ---------

        endpoint : str
            WordPress endpoint.
        params : dict
            HTTP parameters when making the connection.

        Returns
        -------

        dict/list
            Returns the data from the endpoint.
        """
        url = urljoin(self.url, 'wp', self.version, endpoint)

        resp = requests.delete(url, params=params, headers=self.headers)

        if not resp.status_code == 200:
            msg = ('WordPress REST API returned the status code '
                   '{0}.'.foramt(resp.status_code))
            raise Exception(msg)

        return resp.json()

    # Post Methods 
def ensure_application_release_removed(repository_name, release_version):
    api = f'https://quay.io/cnr/api/v1/packages/' \
          f'{quay_namespace}/{repository_name}/{release_version}/helm'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': quay_access_token
    }
    res = requests.delete(api, headers=headers)
    assert res.status_code == 200 
def _delete_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.delete(request_url, headers=request_header) 
def __remove_file(self, url):
        """
        remove a file in the Selenoid node
        """
        requests.delete(url) 
def __init__(self, config):
        if not have_requests:
            raise ImportError('requests module required for RequestsTransport')
        TransportBase.__init__(self, config, self.__module__)
        self.REQ_MAP = {
            'GET': requests.get,
            'POST': requests.post,
            'DELETE': requests.delete,
            'PUT': requests.put
        }
        self._timeout = self._config.get('timeout', None)
        if isinstance(self._timeout, list) and len(self._timeout) == 2:
            self._timeout = tuple(self._timeout) 
def delete(self, api_obj, data=None, obj_id=0, url_params=''):
        if not obj_id and data:
            obj_id = data['id']
        if url_params:
            url_params = '?' + url_params.lstrip("?")
        if not obj_id:
            raise TypeError("Missing object data or id.")
        url = self.server + '/' + api_obj + '/' + str(obj_id) + url_params
        r = requests.delete(url, headers=self.tokenHeaderJson, verify=self.sslVerify)
        return self.__check_result(r) 
def rest_api_delete(self, rest_url, api_version):
        """
        DELETE request to the REST API - Not tested
        :return: JSON string of the DELETE response
        """
        response = requests.delete(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            headers=self.sf_headers
        )

        return response 
def specific_user_route(email):
    """
    Delete a particular user.

    :reqheader Content-Type: application/json
    :resheader Content-Type: application/json
    :resjson string email: The email address of the deleted user.
    :status 200: The user has been deleted.
    :status 404: There is no user with the given ``email``.
    """
    user = load_user_from_id(email)

    if user is None:
        return jsonify(
            title='The requested user does not exist.',
            detail='No user exists with the email "{email}"'.format(
                email=email),
        ), codes.NOT_FOUND

    requests.delete(
        urljoin(STORAGE_URL, '/users/{email}'.format(email=email)),
        headers={'Content-Type': 'application/json'},
    )

    return_data = jsonify(email=user.email)
    return return_data, codes.OK 
def _delete(self, endpoint, params=None):
        response = requests.delete(self.BASE_URL + endpoint, params=params, auth=(self.user, self.password))
        return self._parse(response) 
def clean_consul(port, token=''):
    # remove all data from the instance, to have a clean start
    base_uri = 'http://127.0.0.1:%s/v1/' % port
    params = {'recurse': 1}
    if token:
        params['token'] = token
    requests.delete(base_uri + 'kv/', params=params)
    services = requests.get(base_uri + 'agent/services',
                            params=params).json().keys()
    for s in services:
        requests.put(base_uri + 'agent/service/deregister/%s' % s)

    if token:
        acl_tokens = requests.get(base_uri + 'acl/list', params=params).json()
        for t in acl_tokens:
            if t['ID'] != token:
                requests.put(base_uri + 'acl/destroy/%s' % t['ID'],
                             params=params)

        acl_policys = requests.get(base_uri + 'acl/policies',
                                   params=params).json()
        for pls in acl_policys:
            if pls['ID'] != token:
                requests.delete(base_uri + 'acl/policy/%s' % pls['ID'],
                                params=params)

        acl_roles = requests.get(base_uri + 'acl/roles',
                                 params=params).json()
        for role in acl_roles:
            if role['ID'] != token:
                requests.delete(base_uri + 'acl/role/%s' % role['ID'],
                                params=params) 
def _delete(self, endpoint):
        req_url = self.BASE_URL + endpoint
        r = requests.delete(req_url, headers=self._headers)
        validate_response(r, 200, KieferClientError)
        return r.json() 
def _delete(self, request, headers=None):
        url = '{0}{1}'.format(self._url(), request)
        headers = self.headers if headers is None else headers
        response = requests.delete(url, headers=headers, verify=self.verify_cert, timeout=self.timeout)
        return self._validate(response) 
def jsond(url, *arg):
    """
    自动将 DELETE 请求转换为 JSON
    """
    if url.__class__.__name__ == 'function':
        url = url()
    try:
        return json_moudle.loads(requests.delete(url, headers=Session.headers,
                                                 verify=verify, timeout=3, *arg).text)
    except json_moudle.decoder.JSONDecodeError as e:
        log(f'JSON 解析错误,请检查知乎 API 的 URL 是否变化,当前 URL 为:{url}') 
def dns_records_delete(self, zone_id, record_id):
        """
        https://api.cloudflare.com/#dns-records-for-a-zone-delete-dns-record
        :param zone_id:
        :param record_id:
        :return:
        """
        uri = "zones/" + str(zone_id) + "/dns_records/" + str(record_id)

        return self.api_call_delete(uri, data=False)

    ##########################################################################
    # CloudFlare IPs (https://api.cloudflare.com/#cloudflare-ips-properties) #
    ########################################################################## 
def unreject_user(self, user_id):
        """ Un-decline user
            :user_id id of the user to unreject
        """

        # Create and send HTTP DELETE to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'id' :  user_id
        }
        url = 'https://api.happn.fr/api/users/me/rejected/'+str(user_id)
        try:
            r = requests.delete(url, headers=h, data = payload,verify=False)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.info('Un-declined User '+str(user_id))

        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
def runHttpRequest(self, url, headers, data, type, text):
        if type == "delete":
            res = requests.delete(url, headers=headers, verify=False)
        elif type == "post":
            res = requests.post(url, headers=headers, verify=False, data=data)
        elif type == "get":
            res = requests.get(url, headers=headers, verify=False)
        
        if (res.status_code != requests.codes.ok and res.status_code != 201):
            logger.error("Unexpected response code while %s, on url=%s, statuscode=%s reason=%s, response=\"%s\", payload=\"%s\"" % (text, url, res.status_code, res.reason, res.text, data))
            self.response.write("Error unexpected response code while %s, on url %s, statuscode %s reason %s, response \"%s\", payload=\"%s\"" % (text, url, res.status_code, res.reason, res.text, data))
            return
        
        return res 
def _request(self, verb, endpoint, data=None):
        """Request a url.

        :param endpoint: The api endpoint we want to call.
        :param verb: POST, GET, or DELETE.
        :param params: Optional build parameters.

        :type params: dict

        :raises requests.exceptions.HTTPError: When response code is not successful.

        :returns: A JSON object with the response from the API.
        """

        headers = {
            'Accept': 'application/json',
        }
        auth = HTTPBasicAuth(self.token, '')
        resp = None

        request_url = "{0}/{1}".format(self.url, endpoint)

        if verb == 'GET':
            resp = requests.get(request_url, auth=auth, headers=headers)
        elif verb == 'POST':
            resp = requests.post(request_url, auth=auth, headers=headers, json=data)
        elif verb == 'DELETE':
            resp = requests.delete(request_url, auth=auth, headers=headers)
        else:
            raise BadVerbError(verb)

        resp.raise_for_status()

        return resp.json() 
def delete(self, url=None, **kwargs):
        ''' 删除当前实例对应的数据
        '''
        url = url or self.url
        return requests.delete(url, **kwargs) 
def delete_indice(self, indice_id):
        return self.delete(self.format_url_indice(indice_id)) 
def clean(self, **kwargs):
        '''清理kibana 在 Elasticsearch dashboard 或者visualization 下的所有数据
        '''
        return requests.delete(os.path.dirname(self.url), **kwargs) 
def delete(self, url):
        return requests.delete(url, headers=self.headers()) 
def remove_branch(self):
        res = self.delete("https://api.github.com/repos/%s/git/refs/heads/%s" % (self.repo, self.branch))
        logging.debug(res) 
**************************************************


Python requests.request() Examples

def get_aws_access_key(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, turbot_user_id, api_version):
    """ Gets the federated access keys for a specified account

    :return: Returns the access key, secret key and session token for an account"""
    api_method = "POST"
    api_url = "/api/%s/accounts/%s/users/%s/awsCredentials" % (api_version, turbot_account, turbot_user_id)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    akey = responseObj['accessKeyId']
    skey = responseObj['secretAccessKey']
    token = responseObj['sessionToken']

    return (akey, skey, token) 
def send(self,method,url,params=None,data=None,headers=None):
		if headers is None: headers={}
		headers['User-Agent'] = Request.agent
		try:
			session = requests.Session()
			req = urllib3.disable_warnings(
				urllib3.exceptions.InsecureRequestWarning
				)
			req = requests.request(
				method = method.upper(),
				url = url,
				params = params,
				data = data,
				allow_redirects = True,
				verify = False  )
			return req
		except Exception as e:
			exit(warn('Failed to establish a new connection')) 
def request(method, path, params=None):
        url = api.url.rstrip("/") + path
        data = {"params" if method in ["GET", "DELETE"] else "json": params}
        resp = requests.request(method, url, auth=(api.private_key, ""), **data)

        json = resp.json()
        if resp.status_code == 200:
            return json
        error = json.get("error")
        if error is None:
            raise api.SecurionPayException("Internal error", None, json, None, None)
        raise api.SecurionPayException(
            error.get("type"),
            error.get("code"),
            error.get("message"),
            error.get("charge_id"),
            error.get("blacklist_rule_id"),
        ) 
def parse_image(image):
    """Parse the image smartly and return metadata for request.

    First check whether the image is a URL or a file path or a file-like object
    and return corresponding metadata.

    Args:
        image: A URL or a file path or a file-like object represents an image.

    Returns:
        a three-item tuple consist of HTTP headers, binary data and json data
        for POST.
    """
    if hasattr(image, 'read'):  # When image is a file-like object.
        headers = {'Content-Type': 'application/octet-stream'}
        data = image.read()
        return headers, data, None
    elif os.path.isfile(image):  # When image is a file path.
        headers = {'Content-Type': 'application/octet-stream'}
        data = open(image, 'rb').read()
        return headers, data, None
    else:  # Defailt treat it as a URL (string).
        headers = {'Content-Type': 'application/json'}
        json = {'url': image}
        return headers, None, json 
def push(self, url, method, fail_on_error, envelope, payload):  # pylint: disable=arguments-differ
        if isinstance(payload, (dict, list, tuple)):
            try:
                payload = json.dumps(payload)
            except:  # pylint: disable=bare-except
                pass
        resp = requests.request(method, url, data=str(payload))
        if fail_on_error and not 200 <= resp.status_code <= 299:
            raise PushExecutionError(
                "{method} of '{url}' failed with status code = '{status_code}'".format(
                    method=method,
                    url=url,
                    status_code=resp.status_code
                )
            )
        if not self.provide_response:
            return {'data': payload, **envelope} if envelope else payload

        try:
            return dict(status_code=resp.status_code, is_json=True, data=resp.json())
        except ValueError:
            # No valid json, try text
            return dict(status_code=resp.status_code, is_json=False, data=resp.text) 
def get_response(args, config_dir):
    """Send the request and return a `request.Response`."""

    requests_kwargs = get_requests_kwargs(args)

    if args.debug:
        sys.stderr.write('\n>>> requests.request(%s)\n\n'
                         % pformat(requests_kwargs))

    if not args.session and not args.session_read_only:
        response = requests.request(**requests_kwargs)
    else:
        response = sessions.get_response(
            args=args,
            config_dir=config_dir,
            session_name=args.session or args.session_read_only,
            requests_kwargs=requests_kwargs,
            read_only=bool(args.session_read_only),
        )

    return response 
def refresh_token(self):
        """
        Refresh the current token set in the module.

        Returns the new obtained valid token for the API.
        """
        self._set_token_header()

        response = requests.request(
            'GET', self._get_complete_url('refresh_token'),
            headers=self._headers)

        response.raise_for_status()
        jsn = response.json()
        if 'token' in jsn:
            from . import KEYS
            KEYS.API_TOKEN = jsn['token']
            return KEYS.API_TOKEN
        return '' 
def _request(self, method, path, params=None, payload=None, forceNewToken=False, cleanJson = True):
        self._set_token_header(forceNewToken)
        
        url = self._get_complete_url(path)

        response = requests.request(
            method, url, params=params, 
            data=json.dumps(payload) if payload else payload,
            headers=self._headers)
        
        if response.status_code == 200:
            response.encoding = 'utf-8'
            jsn = response.json()
            if cleanJson and 'data' in jsn:
                return jsn['data']
            return jsn
        elif not forceNewToken:
            return self._request(method=method, path=path, params=params, payload=payload, forceNewToken=True)
        try:
            raise Exception(response.json()['Error'])
        except:
            response.raise_for_status() 
def _authenticate(self):
        if self.auth_result:
            return self.auth_result

        auth_uri = self.auth_uri
        headers = {'X-Auth-User': self.auth_user,
                   'X-Auth-Key': self.auth_key,
                   'X-Auth-Project-Id': self.project_id}
        response = self.request(auth_uri,
                                headers=headers)

        http_status = response.status_code
        LOG.debug("%(auth_uri)s => code %(http_status)s",
                  {'auth_uri': auth_uri, 'http_status': http_status})

        if http_status == 401:
            raise OpenStackApiAuthenticationException(response=response)

        self.auth_result = response.headers
        return self.auth_result 
def _do_request(self, method, action_url, body, headers):
        # Connects to the server and issues a request.
        # :returns: result data
        # :raises: IOError if the request fails

        action_url = "https://%s:%s%s/%s" % (self.host, self.port,
                                             self.api_url, action_url)
        try:
            res = requests.request(method, action_url, data=body,
                                   headers=headers, cert=self.cert,
                                   verify=self.verify)
            status_code = res.status_code
            if status_code in (requests.codes.OK,
                               requests.codes.CREATED,
                               requests.codes.ACCEPTED,
                               requests.codes.NO_CONTENT):
                try:
                    return requests.codes.OK, jsonutils.loads(res.text)
                except (TypeError, ValueError):
                    return requests.codes.OK, res.text
            return status_code, None

        except requests.exceptions.RequestException:
            return IOError, None 
def token_request(self, payload):
        """Request Authorization Payload."""
        headers = {"content-type": "application/json"}
        response = requests.request(
            "POST",
            URL_OAUTH_TOKEN,
            json=payload,
            headers=headers
            )

        LOGGER.debug("Token Payload: %s", payload)
        LOGGER.debug("Token Response: %s", response.text)

        # Check for response errors.
        _response_error(
            f"Can't get token for user {self._creds['username']}",
            response
            )

        return json.loads(response.text)["data"][0] 
def get_devices(self):
        """Return all available devices from Flume API."""
        url = f"https://api.flumetech.com/users/\
        {self._flume_auth.user_id}/devices"

        querystring = {"user": "false", "location": "false"}
        response = requests.request(
            "GET",
            url,
            headers=self._flume_auth.authorization_header,
            params=querystring
            )

        LOGGER.debug("get_devices Response: %s", response.text)

        # Check for response errors.
        _response_error("Impossible to retreive devices", response)

        return json.loads(response.text)["data"] 
def get_cluster_id(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification):
    """ Gets the cluster id
    # TODO: put this in cluster.py
    """
    api_method = "GET"
    api_url = "/api/v1/cluster"

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)
    urn = responseObj['urn']

    return urn 
def get_option_list(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, urn):
    """ Gets the turbot option list

    """
    api_method = "GET"
    api_url = "/api/v1/resources/" + urn + "/options/"

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    options_obj = json.loads(response.text)

    return options_obj['items'] 
def get_set_option(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, urn, set_option):
    """ gets the set options"""

    api_method = "GET"
    api_url = "/api/v1/resources/" + urn + "/options/" + set_option


    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    options_obj = json.loads(response.text)

    for child in options_obj['children']:
        print(child) 
def create_user_ssh_keys(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_user_id):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "POST"
    api_url = "/api/v1/users/%s/sshKeys" % (turbot_user_id)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    return(responseObj['privateKey']) 
def get_guardrail_list(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account_urn, api_version):
    """ Gets the list of guardrails

    :returns: Returns a list of the guardrails"""

    api_method = "GET"
    api_url = "/api/%s/resources/%s/options" % (api_version, turbot_account_urn)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    return responseObj['items'] 
def get_account_bill(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, accountId, api_version):
    """ Gets the month to date charges for a given account

    """
    import requests
    import json
    import urllib.parse
    api_method = "GET"
    api_url = "/api/%s/accounts/%s/aws/estimatedCharges" % (api_version, accountId)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    print(responseObj['charges']['monthToDate']) 
def delete_user_access_keys(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, turbot_user_id, akey, api_version):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "DELETE"
    api_url = "/api/%s/accounts/%s/users/%s/awsAccessKeys/%s" % (api_version, turbot_account, turbot_user_id, akey)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    ) 
def create_user_access_keys(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, turbot_user_id, api_version):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "POST"
    api_url = "/api/%s/accounts/%s/users/%s/awsAccessKeys" % (api_version, turbot_account, turbot_user_id)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    akey = responseObj['accessKeyId']
    skey = responseObj['secretAccessKey']
    return (akey, skey) 
def get_account_tags(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, api_version):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "GET"
    api_url = "/api/%s/accounts/%s/" % (api_version, turbot_account)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    # If the account does not have tags, return false for an easy way to test later
    if 'tags' in responseObj:
        return responseObj['tags']
    else:
        return False 
def add_user_to_account(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host,userarn, permissions, urn, api_version):
    ''' Adds a user to account with Grant'''
    import requests
    import json
    import urllib.parse
    # Set to the required API request type and location
    api_url = "/api/%s/resources/%s/grants/%s" % (api_version, urn, permissions)
    data = {"identityUrn":  userarn, "activate": True}

    response = requests.post(
        json=data,
        url=urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key)

    )

    # Convert the response JSON into a Python object and store it if we need it
    responseObj = json.loads(response.text) 
def delete_user_grant(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host,userarn, permissions, urn, api_version):
    ''' Adds a user to account with Grant'''
    import requests
    import json
    import urllib.parse
    # Set to the required API request type and location
    api_method = "DELETE"
    api_url = "/api/%s/resources/%s/grants/%s/%s" % (api_version, urn, permissions,userarn)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    ) 
def get_guardrails_for_account(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, api_version):
    """ This returns the tick items notification stream from an account not the guardrail notifications"""
    api_method = "GET"
    api_url = "/api/%s/resources/%s/guardrails" % (api_version, turbot_account)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        },

    )

    responseObj = json.loads(response.text)

    return (responseObj['items']) 
def get_guardrail_violation(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, alarm_urn, api_version):
    """ This returns the tick items notification stream from an account not the guardrail notifications"""
    api_method = "GET"
    api_url = "/api/%s/resources/%s/guardrails/%s/notifications" % (api_version, turbot_account, alarm_urn)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        },

    )

    responseObj = json.loads(response.text)

    return (responseObj) 
def call_dbot_api(self, dbot_address: str, uri: str, method: str, **requests_kwargs) -> Response:
        """Send the API's HTTP request

        Channel will be auto created if no channel or be topuped if
        insufficient balance in channel.
        The deposit value is determined by `deposit_strategy`.
        A signature of balance will be sent to DBot server to pay the price of the API.

        :param dbot_address: address of the DBot contract
        :param uri: uri of the endpoint
        :param method: method of the endpoint
        :param requests_kwargs: the other args for http request is same with `requests`
        :return: :class:`Response <Response>` object, http response of the API
        :rtype: requests.Response
        """
        dbot_address = Web3.toChecksumAddress(dbot_address)
        price = self.get_price(dbot_address, uri, method)
        channel = self._get_suitable_channel(dbot_address, price)
        channel.create_transfer(price)
        domain = self.get_dbot_domain(dbot_address)
        dbot_url = domain if domain.lower().startswith('http') else 'http://{}'.format(domain)
        url = '{}/call/{}/{}'.format(dbot_url, dbot_address, remove_slash_prefix(uri))
        return self._request(channel, method, url, **requests_kwargs) 
def getPatients(self):
	######################################
	# Purpose: dump all patients on this
	# 	EMR. 
	#	
	##########################################
		mod = 'download_data.py:FHIR:getPatients'
		addon = 'Patient/'
		url1 = self.url + addon

		#	cmd = 'curl --request GET  --url url --header Accept: "application/json" --header apikey: api_key ' 
		#print url1

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
def getConditions(self, site, cond) :
	######################################
	# Purpose: dump Condition resources 
	# 	that match site and condition
	#	
	# https://smilecdr.com/docs/current/tutorial_and_tour/fhir_search_queries.html
	##########################################
		mod = 'download_data.py:FHIR:getCondition'
		#addon = 'Condition?_bodySite=' + site + '&_content=' + cond		# gives odd results
		addon = 'Condition?_content=' + site + '&_content=' + cond
		url1 = self.url + addon

		#print (mod, url1)
		import requests, json
		response = requests.request("GET", url1, headers=self.headers)
		return  json.loads(response.text) 
def getPatients(self):
	######################################
	# Purpose: get list of all patients in
	# 		VNA
	#	
	##########################################
		mod = 'download_data.py:DCMweb:getStudies'
		# according to this link the below should get a result
		# https://docs.google.com/spreadsheets/d/e/2PACX-1vSBEymDKGZgskFEFF6yzge5JovGHPK_FIbEnW5a6SWUbPkX06tkoObUHh6T1XQhgj-HqFd0AWSnVFOv/pubhtml?gid=1094535210&single=true

		addon = 'patients/'

		url1 = self.url + addon

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
def _request(self, method_name, **kw):
        method, endpoint, params, data, json, headers = self._prepare_req(
            method_name, **kw
        )

        http_response = requests.request(
            method,
            self.site + endpoint,
            auth=self.auth,
            params=params,
            data=data,
            json=json,
            headers=headers
        )

        if http_response.status_code not in [200, 201]:
            if 'application/json' in http_response.headers.get('Content-Type'):
                code = http_response.json().get('code')
                message = http_response.json().get('message')
            else:
                code = http_response.status_code
                message = http_response.text
            raise WordpressError(" ".join([
                str(http_response.status_code),
                str(http_response.reason),
                ":",
                '[{code}] {message}'.format(code=code, message=message)
            ]))
        elif 'application/json' in http_response.headers.get('Content-Type'):
            return http_response.json()
        else:
            raise WordpressError(" ".join([
                "Expected JSON response but got",
                http_response.headers.get('Content-Type')])) 
def _get(self, path, params=None):
        return self.request("GET", path, params) 
def _post(self, path, params=None):
        return self.request("POST", path, params) 
def _delete(self, path, params=None):
        return self.request("DELETE", path, params) 
def request(method, url, data=None, json=None, headers=None, params=None):
    # pylint: disable=too-many-arguments
    """Universal interface for request."""

    # Make it possible to call only with short name (without _BASE_URL).
    if not url.startswith('https://'):
        url = _BASE_URL + url

    # Setup the headers with default Content-Type and Subscription Key.
    headers = headers or {}
    if 'Content-Type' not in headers:
        headers['Content-Type'] = 'application/json'
    headers['Ocp-Apim-Subscription-Key'] = Key.get()

    response = requests.request(method, url, params=params, data=data,
                                json=json, headers=headers)

    # Handle result and raise custom exception when something wrong.
    result = None
    # `person_group.train` return 202 status code for success.
    if response.status_code not in (200, 202):
        print('status_code: {}'.format(response.status_code))
        print('response: {}'.format(response.text))
        error_msg = response.json()['error']
        raise CognitiveFaceException(
            response.status_code,
            error_msg.get('code'),
            error_msg.get('message'))

    # Prevent `reponse.json()` complains about empty response.
    if response.text:
        result = response.json()
    else:
        result = {}

    return result 
def get_token(self, forceNew=False):
        """
        Get the existing token or creates it if it doesn't exist.
        Returns the API token.

        If `forceNew` is true  the function will do a new login to retrieve the token.
        """
        from . import KEYS
        if not KEYS.API_TOKEN or forceNew:
            if not KEYS.API_KEY:
                raise APIKeyError

            if hasattr(self,"USER") and hasattr(self,"USER_KEY"):
                data = {"apikey": KEYS.API_KEY, "username": self.USER, "userkey": self.USER_KEY}
            else:
                data={"apikey": KEYS.API_KEY}

            response = requests.request(
                    'POST', self._get_complete_url('login'), 
                    data=json.dumps(data), 
                    headers=self._headers)
            if response.status_code == 200:
                KEYS.API_TOKEN = response.json()['token']
            else:
                error = "Unknown error while authenticating. Check your api key or your user/userkey"
                try:
                    error = response.json()['Error']
                except:
                    pass
                raise AuthenticationError(error)
        return KEYS.API_TOKEN 
def send(self, request):
        if self.__config is None:
            raise ClientException('Miss config object')
        if self.__credential is None:
            raise ClientException('Miss credential object')
        if request is None:
            raise ClientException('Miss request object')
        if request.parameters is None:
            raise ClientException('Miss parameters in request')

        region = self.__get_region_id(request)

        try:
            header = self.__merge_headers(request.header)
            token = header.get(const.JDCLOUD_SECURITY_TOKEN, '')

            param_builder = self.__builder_map[request.method]()
            url = param_builder.build_url(request, self.__config.scheme, self.__config.endpoint)
            body = param_builder.build_body(request)
            self.__logger.log(INFO, 'url=' + url)
            self.__logger.log(INFO, 'body=' + body)

            signer = Signer(self.__logger)
            signer.sign(method=request.method, region=region, uri=url,
                        headers=header, data=body, credential=self.__credential,
                        security_token=token, service=self.__service_name)
            self.__logger.log(INFO, header)

            resp = requests.request(request.method, url, data=body, headers=header,
                                    timeout=self.__config.timeout)
            self.__logger.log(INFO, resp.content)

            return self.__process_response(request.method, resp)
        except Exception as expt:
            msg = traceback.format_exc()
            self.__logger.log(ERROR, msg)
            raise expt 
def __get_region_id(self, request):
        if isinstance(request.parameters, dict):
            if 'regionId' in request.parameters and request.parameters['regionId'] is not None:
                return request.parameters['regionId']
        else:
            if hasattr(request.parameters, 'regionId') and request.parameters.regionId is not None:
                return request.parameters.regionId

        return 'jdcloud-api'  # when no region, use this value to fill field for sign 
def request(self, url, method='GET', body=None, headers=None):
        _headers = {'Content-Type': 'application/json'}
        _headers.update(headers or {})

        response = requests.request(method, url, data=body, headers=_headers)
        return response 
def api_request(self, relative_uri, check_response_status=None,
                    strip_version=False, **kwargs):
        auth_result = self._authenticate()

        # NOTE(justinsb): httplib 'helpfully' converts headers to lower case
        base_uri = auth_result['x-server-management-url']
        if strip_version:
            # NOTE(vish): cut out version number and tenant_id
            base_uri = '/'.join(base_uri.split('/', 3)[:-1])

        full_uri = '%s/%s' % (base_uri, relative_uri)

        headers = kwargs.setdefault('headers', {})
        headers['X-Auth-Token'] = auth_result['x-auth-token']
        if self.microversion:
            headers['X-OpenStack-Nova-API-Version'] = self.microversion

        response = self.request(full_uri, **kwargs)

        http_status = response.status_code
        LOG.debug("%(relative_uri)s => code %(http_status)s",
                  {'relative_uri': relative_uri, 'http_status': http_status})

        if check_response_status:
            if http_status not in check_response_status:
                if http_status == 404:
                    raise OpenStackApiNotFoundException(response=response)
                elif http_status == 401:
                    raise OpenStackApiAuthorizationException(response=response)
                else:
                    raise OpenStackApiException(
                        message="Unexpected status code",
                        response=response)

        return response 
def httpdo(url, method="GET", data=None):
    """
    thread safe http request
    """
    p = urlparse(url)
    with namedlock(p.scheme+"://"+p.netloc):
        return _unsafe_httpdo(url, method, data) 
def _unsafe_httpdo(url, method='GET', data=None):
    """
    Do HTTP Request
    """
    start = time.time()
    if DEBUG:
        body = json.dumps(data) if data else ''
        print("Shell: curl -X {method} -d '{body}' '{url}'".format(
            method=method.upper(), body=body or '', url=url))

    try:
        response = requests.request(method,
                                    url,
                                    json=data,
                                    timeout=HTTP_TIMEOUT)
    except (requests.exceptions.ConnectionError,
            requests.exceptions.ReadTimeout) as e:
        raise

    if DEBUG:
        ms = (time.time() - start) * 1000
        print('Return ({:.0f}ms): {}'.format(ms, response.text))

    try:
        retjson = response.json()
        retjson['status'] = retjson.get('status', 0)
        r = convert(retjson)
        if r.status != 0:
            raise WDARequestError(r.status, r.value)
        return r
    except JSONDecodeError:
        if response.text == "":
            raise WDAEmptyResponseError(method, url, data)
        raise WDAError(method, url, response.text) 
def api_service(route, token="", method="get", data=None, content_type="application/json",proxy=None):
    resp = requests.request(method=method, url="{0}/{1}/{2}".format(API_EP_DOUYIN, route, token), data=data,
                            headers={"Content-Type": content_type}, verify=False,proxies=proxy)
    if token != "" and resp.headers.get("x-token") != token:
        raise Exception(resp.headers.get("x-token"))
    elif resp.headers.get("x-token-times") == "0":
        raise Exception(resp.content)
    data = resp.content.decode("utf-8")
    return json.loads(data) 
def get_grants(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, namespace, api_version):
    account_list = []
    api_method = "GET"
    api_url = "/api/%s/resources/%s/grants" % (api_version, namespace)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    for obj in responseObj['items']:
        if 'user' in obj:
            common_name = obj['user']['displayName']
        else:
            # Not all accounts have user displayname, most commonly [email protected]'s
            dummy, common_name = obj['identityUrn'].split('::user:')

        if '_DELETED' in common_name:
            print('Former employee %s found in account %s' % (common_name, namespace))
        account_list.append(common_name)
    return account_list 
def delete_fingerprint(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_user_id, finger):
    api_method = "DELETE"
    api_url = "/api/v1/users/%s/sshKeys/%s" % (turbot_user_id, finger)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    ) 
def get_notifications(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, namespace, api_version):
    """ Gets the turbot notification for account
    
    :param turbot_host: turbot host
    :param turbot_api_access_key: turbot access key
    :param turbot_api_secret_key: turbot secret key
    :param turbot_host_certificate_verification: should be true
    :param namespace: the turbot namespace to look for alarms
    :param api_version: api version
    :return: Returns notification_list of all active notifications
    """
    api_method = "GET"
    api_url = "/api/%s/resources/%s/controls?filter=state:alarm,error" % (api_version, namespace)
    notification_list = []
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    for notification in responseObj['items']:
        notification_list.append(notification['alarmUrn'])
    return notification_list 
def get_guardrail(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account_urn, guardrail, api_version):
    """ Gets a guardrail

    :returns: returns a guardrail setting """

    api_method = "GET"
    api_url = "/api/%s/resources/%s/options/%s" % (api_version, turbot_account_urn, guardrail)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    print(responseObj['value'])
    return responseObj['value'] 
def get_cluster_id(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, api_version):
    """ Gets the cluster id
    # TODO: put this in cluster.py
    """
    import requests
    import json
    import urllib.parse
    api_method = "GET"
    api_url = "/api/%s/cluster" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)
    urn = responseObj['urn']

    return urn 
def get_turbot_account_ids(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, api_version):
    """ Gets the current turbot account names

    :return: Returns a dict of turbot account names as turbot_id:AWSaccount
    """
    import requests
    import json
    import urllib.parse
    # Set to the required API request type and location
    accounts = {}
    api_method = "GET"
    api_url = "/api/%s/accounts" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    if responseObj['items']:
        # A user may not have permission to list all accounts
        for obj in responseObj['items']:
            accounts[obj['id']] = obj['awsAccountId']

    return accounts 
def get_aws_account_ids(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, api_version):
    import requests
    import json
    import urllib.parse
    """ Gets the current turbot account names

    :return: Returns a list of turbot account names as accounts
    """
    # Set to the required API request type and location
    accounts = []
    api_method = "GET"
    api_url = "/api/%s/accounts" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    for obj in responseObj['items']:
        accounts.append(obj['awsAccountId'].zfill(12))

    return accounts 
def get_account_titles(turbot_api_access_key, turbot_api_secret_key,turbot_host_certificate_verification, turbot_host, api_version):
    import requests
    import json
    import urllib.parse
    accounts = {}
    api_method = "GET"
    api_url = "/api/%s/accounts" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    for obj in responseObj['items']:
        accounts[obj['id']] = obj['title']

    return accounts 
**************************************************


Python requests.ConnectionError() Examples

def sendData():
    global projectName
    global userInsightfinder
    global licenseKey
    alldata["userName"] = userInsightfinder
    alldata["operation"] = "verify"
    alldata["licenseKey"] = licenseKey
    alldata["projectName"] = projectName
    json_data = json.dumps(alldata)
    #print json_data
    url = serverUrl + "/api/v1/agentdatahelper"
    print serverUrl
    try:
        response = requests.post(url, data = json.loads(json_data))
    except requests.ConnectionError, e:
        print "Connection failure : " + str(e)
        print "Verification with InsightFinder credentials Failed"
        sys.exit(1) 
def sendData():
    global projectName
    global userInsightfinder
    global licenseKey
    alldata["userName"] = userInsightfinder
    alldata["operation"] = "verify"
    alldata["licenseKey"] = licenseKey
    alldata["projectName"] = projectName
    json_data = json.dumps(alldata)
    #print json_data
    url = serverUrl + "/api/v1/agentdatahelper"
    print serverUrl
    try:
        response = requests.post(url, data = json.loads(json_data))
    except requests.ConnectionError, e:
        print "Connection failure : " + str(e)
        print "Verification with InsightFinder credentials Failed"
        sys.exit(1) 
def verifyUser(username, licenseKey, projectName):
    alldata = {}
    alldata["userName"] = username
    alldata["operation"] = "verify"
    alldata["licenseKey"] = licenseKey
    alldata["projectName"] = projectName
    toSendDataJSON = json.dumps(alldata)

    url = parameters['serverUrl'] + "/api/v1/agentdatahelper"

    try:
        response = requests.post(url, data=json.loads(toSendDataJSON))
    except requests.ConnectionError, e:
        logger.error("Connection failure : " + str(e))
        logger.error("Verification with InsightFinder credentials Failed")
        return False 
def test_POST_nodata():
    '''The server should accept a POST and return 400 error on empty form.'''
    print("Testing POST request with empty form.")

    uri = "http://localhost:8000/"
    data = {}

    try:
        r = requests.post(uri, data=data, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a POST request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 400:
        return ("Server returned status code {} instead of 400 when I gave\n"
                "it an empty form in a POST request.".format(r.status_code))
    else:
        print("POST request with bad URI correctly got a 400.")
        return None 
def test_POST_bad():
    '''The server should accept a POST and return 404 error on bad URI.'''
    print("Testing POST request with bad URI.")

    uri = "http://localhost:8000/"
    data = {'shortname': 'bad', 'longuri': 'this is fake'}
    try:
        r = requests.post(uri, data=data, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a POST request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 404:
        return ("Server returned status code {} instead of 404 when I gave\n"
                "it a bad URI in a POST request.".format(r.status_code))
    else:
        print("POST request with bad URI correctly got a 404.")
        return None 
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        method = params.get('method', 'GET')
        json_data = params.get('json', {})
        timeout = params.pop('timeout', None) or self.timeout
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        try:
            with self.session.request(
                method, url, timeout=timeout, headers=self.headers, params=params, json=json_data
            ) as resp:
                return self._raise_for_status(resp, resp.text, method=method)
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        if self.ratelimit[1] == 0 and time() < self.ratelimit[2] / 1000:
            if not url.endswith('/auth/stats'):
                raise RatelimitErrorDetected(self.ratelimit[2] / 1000 - time())
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        timeout = params.pop('timeout', None) or self.timeout
        try:
            with self.session.get(url, timeout=timeout, headers=self.headers, params=params) as resp:
                return self._raise_for_status(resp, resp.text, method='GET')
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
def process_response(wrapped, instance, args, kwargs):
    """
    Decorator to process requests.Response

    Raises:
        Exception: Service Unavailable

    Returns:
        dict: json data
    """

    try:
        resp = wrapped(*args, **kwargs)

    except (requests.ConnectionError, requests.Timeout) as e:
        raise Exception("Service Unavailable") from e

    else:
        resp.raise_for_status()
        return resp.json() 
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
def validate_response_app_endpoint(p_client, appId):
    ingress_list = p_client.list_ingress(namespaceId=appId).data
    assert len(ingress_list) == 1
    ingress = ingress_list[0]
    if hasattr(ingress, 'publicEndpoints'):
        for public_endpoint in ingress.publicEndpoints:
            url = \
                public_endpoint["protocol"].lower() + "://" + \
                public_endpoint["hostname"]
            print(url)
            try:
                r = requests.head(url)
                assert r.status_code == 200, \
                    "Http response is not 200. Failed to launch the app"
            except requests.ConnectionError:
                print("failed to connect")
                assert False, "failed to connect to the app" 
def test_location_google_breaks(self):
        """User passed location arg but google api gave error"""
        caught_exceptions = [
            requests.ConnectionError, requests.HTTPError, requests.Timeout]
        with mock.patch('requests.get') as mock_get:
            for exception in caught_exceptions:
                mock_get.side_effect = exception
                with capture_sys_output():
                    with self.assertRaises(RipeAtlasToolsException):
                        cmd = Command()
                        cmd.init_args(["--location", "blaaaa"])
                        cmd.run()
            mock_get.side_effect = Exception()
            with self.assertRaises(Exception):
                cmd = Command()
                cmd.init_args(["--location", "blaaaa"])
                cmd.run() 
def convert(ctx: commands.Context, url: str) -> str:
        """Convert url to Intersphinx inventory URL."""
        try:
            intersphinx.fetch_inventory(SphinxConfiguration(), '', url)
        except AttributeError:
            raise commands.BadArgument(f"Failed to fetch Intersphinx inventory from URL `{url}`.")
        except ConnectionError:
            if url.startswith('https'):
                raise commands.BadArgument(
                    f"Cannot establish a connection to `{url}`. Does it support HTTPS?"
                )
            raise commands.BadArgument(f"Cannot connect to host with URL `{url}`.")
        except ValueError:
            raise commands.BadArgument(
                f"Failed to read Intersphinx inventory from URL `{url}`. "
                "Are you sure that it's a valid inventory file?"
            )
        return url 
def make_call(self, url, params=None):
        time.sleep(SLEEP_TIME)
        for i in range(10):
            if i != 0:
                self.logger.info("%s - retrying... %d" % (url,i))
                time.sleep(ERROR_SLEEP_TIME*i)
            try:
                res = requests.get(url, verify=False)
            except requests.ConnectionError, e:
                self.logger.info(e)
                continue
            
            if res.status_code == 200:
                #data = json.loads(res.text)
                data = res.json()
                if data:
                    return data
                continue

                
    #TODO: replace it with requests retry 
def make_call_v2(self, url, params=None):
        time.sleep(SLEEP_TIME)
        for i in range(10):
            if i != 0:
                self.logger.info("%s - retrying... %d" % (url,i))
                time.sleep(ERROR_SLEEP_TIME*i)
            try:
                res = requests.get(url)
            except requests.ConnectionError, e:
                self.logger.info(e)
                continue
            
            if res.status_code == 200:
                #data = json.loads(res.text)
                data = res.json()
                return data 
def fetch_info(id, type):
    """
    Returns a dictionary with information about the media(id, type).
    Currently only fetches 'members'(popularity count).
    """
    validate_media(type)

    url = media_url(id, type)

    try:
        response = requests.get(url)
        html = response.content
        return extract_info(html)
    except requests.ConnectionError:
        print(f"Timed out on fetching {type}:{id} info")
        return None
    except Exception as err:
        print(id, type, '-', response.status_code, '-', err)
        if response.status_code == 404:
            return []
        return None 
def _get_remote_projects(self):
        # import when required in order to reduce watson response time (#312)
        import requests
        if not hasattr(self, '_remote_projects'):
            dest, headers = self._get_request_info('projects')

            try:
                response = requests.get(dest, headers=headers)
                assert response.status_code == 200

                self._remote_projects = response.json()
            except requests.ConnectionError:
                raise WatsonError("Unable to reach the server.")
            except AssertionError:
                raise WatsonError(
                    u"An error occurred with the remote "
                    "server: {}".format(response.json())
                )

        return self._remote_projects['projects'] 
def get(self):

        work_list = []
        if requests.get('http://www.google.com'):
            work_list.append(build_working_response('google', 'working'))
            app.log.info('testing info log')
        else:
            work_list.append(build_working_response('google',
                                                    'error', 'another_dependency-api offline.', 'CODE02'))
            app.log.error('testing ERROR log')

        try:
            if requests.get('http://localhost:8000') == 200:
                work_list.append(build_working_response('localhost', 'working'))
                app.log.info('testing info log')
            else:
                work_list.append(build_working_response('localhost',
                                                        'error', 'another_dependency-api offline.', 'CODE02'))
                app.log.error('testing ERROR log')
        except requests.ConnectionError as e:
            work_list.append(build_working_response('localhost',
                                                    'error', str(e), 'CODE04'))
            app.log.error(e)
        return work_list, 200 
def _make_request(self, path, cni_envs, expected_status=None):
        method = 'POST'

        address = config.CONF.cni_daemon.bind_address
        url = 'http://%s/%s' % (address, path)
        try:
            LOG.debug('Making request to CNI Daemon. %(method)s %(path)s\n'
                      '%(body)s',
                      {'method': method, 'path': url, 'body': cni_envs})
            resp = requests.post(url, json=cni_envs,
                                 headers={'Connection': 'close'})
        except requests.ConnectionError:
            LOG.exception('Looks like %s cannot be reached. Is kuryr-daemon '
                          'running?', address)
            raise
        LOG.debug('CNI Daemon returned "%(status)d %(reason)s".',
                  {'status': resp.status_code, 'reason': resp.reason})
        if expected_status and resp.status_code != expected_status:
            LOG.error('CNI daemon returned error "%(status)d %(reason)s".',
                      {'status': resp.status_code, 'reason': resp.reason})
            raise k_exc.CNIError('Got invalid status code from CNI daemon.')
        return resp 
def request(self, method, url, **kwargs):
        api_error_class = kwargs.pop('api_error_class', APIError)
        handle_errors = bool(kwargs.pop('handle_errors', True))
        try:
            resp = super(APISession, self).request(method, url, **kwargs)
        except requests.ConnectionError as ce:
            host = urlparse(ce.request.url).netloc
            if 'Connection refused' in str(ce):
                six.raise_from(CLIException(
                    'Unable to connect to {host} (connection refused); try again soon.'.format(host=host)
                ), ce)
            raise

        if handle_errors and resp.status_code >= 400:
            cls = (APINotFoundError if resp.status_code == 404 else api_error_class)
            raise cls(resp)
        return resp 
def api_delete(server_name, api, session_id):
    #Header and URL for delete call
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.delete(url, headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintrRequestsiApiException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# PUT 
def api_put(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.put(url, data=json.dumps(payload),
                         headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# POST 
def api_post(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.post(url, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# Login. 
def download_file(server_name, report_url, session_id, file_name):
    headers = {'content-type': 'application/json'}

    try:
        r = requests.get(report_url, headers=headers, verify=False, stream=True)
        # if HTTP Response is not 200 then raise an exception
        if r.status_code != 200:
            message = "The HTTP response for get call to the server is not 200."
            raise TintriApiException(message, r.status_code, report_url, "No Payload", r.text)

        with open(file_name, 'w') as file_h:
            for block in r.iter_content(4096):
                file_h.write(block)

    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except Exception as e:
        raise TintriRequestsException("An unexpected error: " + e.__str__()) 
def do(self, api_name=None, pk=None, method='get', use_auth=True,
           data=None, params=None, content_type='application/json', **kwargs):

        if api_name in API_URL_MAPPING:
            path = API_URL_MAPPING.get(api_name)
            if pk and '%s' in path:
                path = path % pk
        else:
            path = api_name

        request_headers = kwargs.get('headers', {})
        default_headers = self.default_headers or {}
        headers = {k: v for k, v in default_headers.items()}
        headers.update(request_headers)
        kwargs['headers'] = headers
        url = self.endpoint.rstrip('/') + path
        req = HttpRequest(url, method=method, data=data,
                          params=params, content_type=content_type,
                          **kwargs)
        if use_auth:
            if not self.auth:
                msg = 'Authentication required, but not provide'
                logger.error(msg)
                raise RequestError(msg)
            else:
                self.auth.sign_request(req)

        try:
            resp = req.do()
        except (requests.ConnectionError, requests.ConnectTimeout) as e:
            msg = "Connect endpoint {} error: {}".format(self.endpoint, e)
            logger.error(msg)
            raise RequestError(msg)

        return self.clean_result(resp) 
def PullNews(self):
        Configuration = ConfigurationReader()
        self.__APIKey=Configuration.GetAPIKEY()
        self.__Limit=Configuration.GetLimit()
        url='https://newsapi.org/v2/top-headlines?sources='+self.Source+'&sortBy=top&apiKey='+self.__APIKey
        try:
            req=requests.get(url)
            if(req.status_code==200):
                return req
            else:
                print "There is some issue in connecting to the internet. Please check your firewall or internet"
        except ConnectionError as e:
            print "A connection Attempt failed"
            print e.message
            sys.exit() 
def _send_to_rest_api(self, suffix, data=None, content_type=None):
        '''Send a REST command to the Validator via the REST API.

           Called by count() &  _wrap_and_send().
           The latter caller is made on the behalf of bake() & eat().
        '''
        url = "{}/{}".format(self._base_url, suffix)
        print("URL to send to REST API is {}".format(url))

        headers = {}

        if content_type is not None:
            headers['Content-Type'] = content_type

        try:
            if data is not None:
                result = requests.post(url, headers=headers, data=data)
            else:
                result = requests.get(url, headers=headers)

            if not result.ok:
                raise Exception("Error {}: {}".format(
                    result.status_code, result.reason))
        except requests.ConnectionError as err:
            raise Exception(
                'Failed to connect to {}: {}'.format(url, str(err)))
        except BaseException as err:
            raise Exception(err)

        return result.text 
def get_ec2_instance_type():
    url = "http://169.254.169.254/latest/meta-data/instance-type" # TODO: fix/remove
    try:
        response = requests.post(url)
    except requests.ConnectionError, e:
        logger.error("Error finding instance-type")
        return 
def ec2InstanceType():
    url = "http://169.254.169.254/latest/meta-data/instance-type"
    try:
        response = requests.post(url)
    except requests.ConnectionError, e:
        print "Error finding instance-type"
        return 
def fetch_lyric(artist, title):
    try:
        response = requests.get('http://api.chartlyrics.com/apiv1.asmx/SearchLyricDirect\
                        ?artist={0}&song={1}'.format(artist, title))
        print(artist, ' ', title, 'response code: ', response.status_code)
        return response
    except requests.ConnectionError as e:
        print(artist, ' ', title, 'Fetching failed :', e)
        raise
    except Exception as e:
        return None 
def get_lyric(artist, title):
    result = None
    try:
        response = fetch_lyric(artist, title)
    except requests.ConnectionError as e:
        return (None, "Check your network connection.")
    if response is not None:
        result = parse_response(response)
    else:
        return (None, "Some error happend")
    if result is not None:
        result += "\n\n Lyric source: chartlyrics.com"
    return (result, None) 
def fetch_lyric(artist, title):
    try:
        response = requests.get(
            'http://api.vagalume.com.br/search.php?art={0}&mus={1}'.format(artist, title))
        print(artist, ' ', title, 'response code: ', response.status_code)
        return response
    except requests.ConnectionError as e:
        print(artist, ' ', title, 'Fetching failed :', e)
        raise
    except Exception as e:
        return None 
def get_lyric(artist, title):
    result = None
    try:
        response = fetch_lyric(artist.split(';')[0], title)
    except requests.ConnectionError as e:
        return (None, "Check your network connection.")
    if response is not None:
        result = parse_response(response)
    else:
        return (None, "Some error happend")
    if result is not None:
        result += "\n\n Lyric source: chartlyrics.com"
    return (result, None) 
def download_file(self, report_url, file_name):
        """
        Downloads the file pointed by URL.

        Args:
        
            report_url (str): URL returned from API from which file can be downloaded
            file_name (str): Name to be used for downloaded file 
        """
        headers = {'content-type': 'application/json'}
    
        try:
            r = requests.get(report_url, headers=headers, verify=False, stream=True)
            if r.status_code != 200:
                message = "The HTTP response for get call on: %s is %s" % (report_url, r.status_code)
                raise TintriServerError(r.status_code, message=message)
    
            with open(file_name, 'w') as file_h:
                for block in r.iter_content(4096):
                    file_h.write(block)

        except TintriServerError:
            raise    
        except requests.ConnectionError:
            raise TintriError("API Connection error occurred.")
        except requests.HTTPError:
            raise TintriError("HTTP error occurred.")
        except requests.Timeout:
            raise TintriError("Request timed out.")
        except Exception as e:
            raise TintriError("An unexpected error occurred: " + e.__str__()) 
def connection_refused_matcher(request):
    raise requests.ConnectionError("connection refused") 
def get_request(url, err_msg):
        try:
            req = requests.get(url)
        except requests.ConnectionError:
            abort(err_msg)

        if not req.status_code == requests.codes.ok:
            abort(err_msg)

        return req 
def test_POST_good():
    '''The server should accept a POST with a good URI and redirect to root.'''
    print("Testing POST request with good URI.")

    uri = "http://localhost:8000/"
    data = {'shortname': 'google', 'longuri': 'http://www.google.com/'}
    try:
        r = requests.post(uri, data=data, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a POST request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 303:
        return ("Server returned status code {} instead of 303 when I gave\n"
                "it a good URI in a POST request.".format(r.status_code))
    elif 'location' not in r.headers:
        return ("Server returned a 303 redirect with no Location header.")
    elif r.headers['location'] != '/':
        return ("Server returned redirect to {} instead of to /."
                .format(r.headers['location']))
    else:
        print("POST request with bad URI correctly got a 303 to /.")
        return None 
def test_GET_path():
    '''The server should redirect on a GET to a recorded URI.'''

    uri = "http://localhost:8000/google"
    orig = "http://www.google.com/"
    print("Testing GET request to {}.".format(uri))

    try:
        r = requests.get(uri, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a GET request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 303:
        return ("Server returned status code {} instead of 303 when I asked\n"
                "for it to follow a short URI.".format(r.status_code))
    elif 'location' not in r.headers:
        return ("Server returned a 303 with no Location header.")
    elif r.headers['location'] != 'http://www.google.com/':
        return ("Server returned a 303, but with a Location header of {}\n"
                "when I expected it to be http://www.google.com/."
                .format(r.headers('location')))
    else:
        print("GET request to {} returned 303 to {} successfully"
              .format(uri, orig)) 
def test_is_working_url_url_with_exception(self, req_mock):
        url_validator = UrlValidator(self.catalog, True, 1, 10)
        req_mock.head(self.test_url, exc=ConnectionError)
        self.assertEqual(
            (False, None), url_validator.is_working_url(self.test_url)) 
def run(self):
        if self.retrying:
            self.connect_with_retrying()
        else:
            try:
                self.connect()
            except requests.ConnectionError:
                self.callback(STATUS_NO_CONNECTION) 
def test_connection_error(self, error_handler):
        """Should call logging error handler when offline"""
        self.rm.post('https://some-hook.com/exception-log', exc=requests.ConnectionError)
        logger = self._build_logger('exception', 'https://some-hook.com/exception-log')
        logger.info("Testing when something fails on the wire")
        self.assertEqual(self.rm.call_count, 1)
        error_handler.assert_called_once() 
def test_timeout(self):
        self.akismet = Akismet(os.environ['AKISMET_API_KEY'], timeout=0.000001, is_test=True)

        with self.assertRaises(requests.ConnectionError):
            self.akismet.submit_ham('127.0.0.1', USER_AGENT, blog='http://127.0.0.1') 
def request_naver_endic_url(naver_endic_url):
    """
    Send a GET request to NAVER dictionary url

    """

    try:
        response = requests.get(naver_endic_url)
    except requests.ConnectionError:
        raise NdicConnectionError()
    return response 
def validate(self, badge_id):
    """Validates the badge ID with a HTTP service. Any 2xx is considered success.

    Args:
      badge_id: String containing the badge identifier to authorize.
    Returns:
      Response boolean.
    """
    try:
      r = requests.get(url = self._url, params = {self._key_param: badge_id})
      return r.status_code >= 200 and r.status_code < 300
    except requests.ConnectionError:
      return False 
def job(url, manga_name):
    def download(url, file_name, manga_name):
        if config['general']['short_title'] == 0:
            manga_name = manga_name.decode('utf-8')

        # That Unicode Stuff sucks so hard...
        if config['general']['save_path']:
            manga_path = os.path.dirname(config['general']['save_path']) + '/' + \
            manga_name + '/'
        else:
            manga_path = os.path.dirname(os.path.realpath(__file__)) + '/' + \
            manga_name + '/'
        try:
            os.makedirs(manga_path)
        except OSError:
            if not os.path.isdir(manga_path):
                raise
        #print("Download URL: ", url)
        with open(os.path.join(manga_path, file_name), "wb") as file:
            response = get(url)
            file.write(response.content)
    try:
        # Get HTTP Status Code
        # nhentai uses not only jpg.. argh
        # if 404 try some other Formats...
        # TODO: Rework this to read format out of HTML..
        formats = ["jpg", "png", "gif"]

        for i in formats:
            url_temp = url + i
            http_code  = requests.head(url_temp).status_code
            #print ("HTTP Code: ", http_code)
            if http_code == 200: # OK
                url = url_temp
                file_name = str(url.split('/')[-1])
                download(url, file_name, manga_name)

    except requests.ConnectionError:
        print("failed to connect") 
def check_for_no_access(url, verify=False):
    try:
        requests.get(url, verify=verify)
        return False
    except requests.ConnectionError:
        print("Connection Error - " + url)
        return True 
def location2degrees(self):
        """Fetches degrees based on the given location."""
        error_log = (
            "Following error occured while trying to fetch lat/lon"
            "for location <{}>:\n{}"
        )
        goole_api_url = "http://maps.googleapis.com/maps/api/geocode/json"
        try:
            result = requests.get(goole_api_url, params={
                "sensor": "false",
                "address": self.arguments.location
            })
        except (
            requests.ConnectionError,
            requests.HTTPError,
            requests.Timeout,
        ) as e:
            error_log = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error_log)

        result = result.json()

        try:
            lat = result["results"][0]["geometry"]["location"]["lat"]
            lng = result["results"][0]["geometry"]["location"]["lng"]
        except (KeyError, IndexError) as e:
            error = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error)

        return str(lat), str(lng) 
**************************************************


Python requests.exceptions() Examples

def _must_post(self, api, data=None, json=None, timeout=10, **kwargs):
        if data is not None:
            kwargs['data'] = data
        elif json is not None:
            kwargs['json'] = json
        else:
            kwargs['data'] = {}
        kwargs['timeout'] = timeout

        try:
            r = requests.post(api, **kwargs)
            return r
        except requests.exceptions.Timeout:
            logger.error("Timeout requesting Gitter")
        except KeyboardInterrupt:
            raise
        except:
            logger.exception("Unknown error requesting Gitter")
        return None 
def upload_image(self, filename=None, filedata=None, **kwargs) -> str:
        if filedata is None:
            files = {"image": open(filename, 'rb')}
        else:
            files = {"image": filedata}

        try:
            r = requests.post(self.url, files=files, timeout=5)
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to VimCN")
            return None
        except:
            logger.exception("Unknown errror uploading to VimCN")
            return None
        if not r.ok:
            return None
        return r.text.strip() 
def http_head(self, path, **kwargs):
        """
        Make a HEAD request to the k8s server.
        """
        try:

            url = urljoin(self.url, path)
            response = self.session.head(url, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem retrieving headers from " \
                "the Kubernetes API server. URL: {}".format(url)
            logger.error(message)
            raise KubeException(message) from err

        return response 
def http_post(self, path, data=None, json=None, **kwargs):
        """
        Make a POST request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.post(url, data=data, json=json, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem posting data to " \
                      "the Kubernetes API server. URL: {}, " \
                      "data: {}, json: {}".format(url, data, json)
            logger.error(message)
            raise KubeException(message) from err

        return response 
def http_put(self, path, data=None, **kwargs):
        """
        Make a PUT request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.put(url, data=data, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem putting data to " \
                      "the Kubernetes API server. URL: {}, " \
                      "data: {}".format(url, data)
            logger.error(message)
            raise KubeException(message) from err

        return response 
def _load_publisher_rules(self, rules_url):
        """
        Get the CIS integration rules
        """
        rules = None
        if not self.always_use_local_file:
            if rules_url is not None:
                try:
                    r = requests.get(rules_url)
                    rules = r.json()
                except (json.JSONDecodeError, requests.exceptions.ConnectionError) as e:
                    logger.debug("Failed to load rules data from rules_url {} ({})".format(rules_url, e))
        # Fall-back to built-in copy
        if self.always_use_local_file or rules is None:
            rules_file = "data/well-known/mozilla-iam-publisher-rules"
            if not os.path.isfile(rules_file):
                dirname = os.path.dirname(os.path.realpath(__file__))
                path = dirname + "/" + rules_file
            else:
                path = rules_file

            rules = json.load(open(path))
        return rules 
def get_sso_groups(token):
    try:
        verify_cert = True
        if is_development_environment():
            verify_cert = False

        headers = {"Authorization": "Bearer " + token}
        r = requests.get(
            current_app.config["AUTH_SERVER_ADDRESS"],
            headers=headers,
            timeout=1,
            verify=verify_cert
        )
    except requests.exceptions.ReadTimeout:
        return None
    if r.status_code != 200 or "id" not in r.json():
        return None

    result = r.json()
    if is_development_environment():
        result["groups"] = [ADH6_USER, ADH6_ADMIN]  # If we are testing, consider the user asg.admin
    return result 
def __init__(self, host, user=None, passwd=None, debug=False, use_ssl=True, verify_ssl=False, timeout=300,
                 disable_request_warnings=False, apikey=None):
        super(FortiGate, self).__init__()
        self._host = host
        self._user = user
        self._req_id = 0
        self._url = None
        self._session = None
        self._sid = None
        self._timeout = timeout
        self._debug = debug
        self._use_ssl = use_ssl
        self._verify_ssl = verify_ssl
        self._apikeyused = True if passwd is None and apikey is not None else False
        self._passwd = passwd if passwd is not None else apikey
        self._req_resp_object = RequestResponse()
        self._logger = None
        if disable_request_warnings:
            requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning) 
def _call(self, method, endpoint, payload=None):
        """
        Call the endpoint and return the response
        """
        resp = None
        shuffle(self.hosts)
        for index in xrange(len(self.hosts)):
            url = "http://%s/v1%s" % (self.hosts[index], endpoint)
            req_args = {'timeout': 10, 'headers': {'Content-Type': 'application/json'}}
            try:
                if method == _GET:
                    resp = requests.get(url, **req_args)
                elif method == _POST:
                    resp = requests.post(
                        url, data=payload, **req_args)
                elif method == _DELETE:
                    resp = requests.delete(url, **req_args)
                break
            except requests.exceptions.RequestException:
                continue
        if resp is None:
            raise DkronClientException("No valid host found")
        return resp 
def __exit__(self, exc, value, traceback):
        if self._is_reported:
            # if the user has already manually marked this response as failure or success
            # we can ignore the default haviour of letting the response code determine the outcome
            return exc is None
        
        if exc:
            if isinstance(value, ResponseError):
                self.failure(value)
            else:
                return False
        else:
            try:
                self.raise_for_status()
            except requests.exceptions.RequestException as e:
                self.failure(e)
            else:
                self.success()
        return True 
def execute(self):
		timeout = self.timeout_seconds
		if timeout is None: timeout = GLOBAL_TIMEOUT_SECONDS
		try:
			if timeout is None:
				r = urllib.request.urlopen(self.rq, **_get_tls_parms())
			else:
				r = urllib.request.urlopen(self.rq, None, timeout, **_get_tls_parms())
		except urllib.error.HTTPError as e:
			self.status_code = e.code
			self.text = e.msg
			return self
		except (http.client.HTTPException, urllib.error.URLError, socket.timeout) as e:
			e2 = exceptions.RequestException("{}.{!r}".format(type(e).__module__, e))
			raise e2
		self._rdata = r.read()
		if DEBUG: print("Response._rdata set to:", repr(self._rdata), file=sys.stderr)
		self.map_request(r)
		r.close()
		return self 
def request(session, method, url, **kwargs):
    """
    :desc: Custom wrapper method to add a timeout message
           when there is a `requests.exceptions.ConnectionError`
           or `requests.ReadTimeout` exception.
    :param: `session` requests.Session object
            `method` HTTP method to use
            `url` name of the URL
    :return: requests.Response object.
    """

    try:
        return session.request(method=method, url=url, timeout=(5, 5), **kwargs)
    except (ConnectionError, ReadTimeout):
        print(INTERNET_DOWN_MSG)
        sys.exit(1) 
def __init__(self, endpoint, resource_uri, optimization=True,
                 max_elems=100, filter_query=None, filter_dialect=None):
        self.endpoint = endpoint
        self.resource_uri = resource_uri
        self.filter_dialect = None
        self.filter_query = None
        self.optimization = optimization
        self.max_elems = max_elems

        if filter_query is not None:
            try:
                self.filter_dialect = FILTER_DIALECT_MAP[filter_dialect]
            except KeyError:
                valid_opts = ', '.join(FILTER_DIALECT_MAP)
                raise exceptions.WSManInvalidFilterDialect(
                    invalid_filter=filter_dialect, supported=valid_opts)

            self.filter_query = filter_query 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def down(text):
    """<url> - checks if <url> is online or offline
    :type text: str
    """

    if "://" not in text:
        text = 'http://' + text

    text = 'http://' + urllib.parse.urlparse(text).netloc

    try:
        requests.get(text)
    except requests.exceptions.ConnectionError:
        return '{} seems to be down'.format(text)
    else:
        return '{} seems to be up'.format(text) 
def register_operation_failure(self, v):
        self.incr_counter('operation.failure')
        return v

    #
    # The raw HTTP requests
    #

    # def _http_req(self, endpoint, **kwargs):
    #     url = 'http://%s:%d/%s' % (self.http_service_host, self.http_service_port, endpoint)
    #
    #     # self.log.msg("[HTTP] %s %r" % (url, kwargs), level=logger.INFO)
    #
    #     try:
    #         r = requests.post(url, **kwargs)
    #     except requests.exceptions.RequestException:
    #         self.log.msg("ERROR in HTTP request: %s" % get_traceback(), level=logger.INFO)
    #     else:
    #         if r.status_code != 200:
    #             self.log.msg("Bad status code in HTTP request: %d" % r.status_code, level=logger.INFO)
    #             return None
    #         else:
    #             return r 
def _set_response_ins_(self, pageurl):
        """
        Sets the response for the GET request of pageurl and stores it in self.resp

        :param pageurl: url for which we store the response.
        """
        try:
            s = requests.Session()
            a = requests.adapters.HTTPAdapter(max_retries=5)
            s.mount('http://', a)
            resp = s.get(pageurl, timeout=30)
            self.__resp_obj__ = resp
            resp.close()
        except requests.exceptions.Timeout:
            logging.error("\tVery Slow Internet Connection.")
        except requests.exceptions.ConnectionError:
            logging.error("\tNetwork Unavailable. Check your connection.")
        except requests.exceptions.MissingSchema:
            logging.error("\t503 Service Unavailable. Retrying download ... ") 
def wan_available(retry: int = 0):
    """

    Returns: True if connected to WAN

    """
    try:
        response = requests.get('http://google.com', timeout=2)
        commands.DCS.unblock_start('no WAN connection available')
        commands.DISCORD.can_start()
        return bool(response.ok)
    except requests.exceptions.RequestException:
        if retry < 5:
            LOGGER.debug('Internet connection loss detected, retry %s', retry)
            await asyncio.sleep(2)
            result = await wan_available(retry + 1)
            return result
        LOGGER.debug(f'Internet connection loss detected, no more retry')
        commands.DISCORD.cannot_start()
        commands.DCS.block_start('no WAN connection available')
        return False 
def get_cdas_url(starttime, endtime, vars, dataset, timeout=10):
    dataview = 'sp_phys'
    if vars is None:
        try:
            var_info = get_variables(dataset, timeout=timeout)
        except requests.exceptions.ReadTimeout:
            raise util.NoDataError(
                'Connection to CDAweb timed out when getting CDAS URL for '
                f'{dataset} data for interval {starttime} - {endtime}.')

        if not len(var_info):
            raise util.NoDataError(
                f'No {dataset} data available for date {date}')

        vars = [v['Name'] for v in var_info['VariableDescription']]

    uri = '/'.join(['dataviews', dataview,
                    'datasets', dataset,
                    'data',
                    ','.join([starttime.strftime('%Y%m%dT%H%M%SZ'),
                              endtime.strftime('%Y%m%dT%H%M%SZ')]),
                    ','.join(vars)
                    ])
    url = '/'.join([CDAS_BASEURL, uri])
    return url 
def test_full_internal_error_text(self, full_bot_setup):
        """Tests that unhandled exceptions in commands with error text are handled safely"""

        bot = full_bot_setup["bot"]
        aux_api = full_bot_setup["aux_api"]
        emulator = full_bot_setup["emulator"]

        @bot.command("exception")
        def cause_exception():
            raise ValueError("Whoops", "Hey, an exception")

        self.start_receiver(full_bot_setup["receiver_process"], full_bot_setup["receiver_webhook_url"])

        bot_reply = self.invoke_bot(aux_api, emulator.bot_id, emulator.bot_displayname, "exception", room_name="test1")

        assert bot_reply.text == "⚠️ Error: Hey, an exception" 
def test_full_internal_error(self, full_bot_setup):
        """Tests that unhandled exceptions in commands without error text are handled safely"""

        bot = full_bot_setup["bot"]
        aux_api = full_bot_setup["aux_api"]
        emulator = full_bot_setup["emulator"]

        @bot.command("exception")
        def cause_exception():
            raise ValueError("Whoops")

        self.start_receiver(full_bot_setup["receiver_process"], full_bot_setup["receiver_webhook_url"])

        bot_reply = self.invoke_bot(aux_api, emulator.bot_id, emulator.bot_displayname, "exception", room_name="test1")

        assert bot_reply.text == "⚠️ Error: Something happened internally. For more information, contact the bot author." 
def download(url, timeout=5):
    try:
        response = requests.get(url, timeout=timeout)
    except requests.exceptions.RequestException as ex:
        error(f"Exception caught while fetching {url}\n{ex}")
        return None

    if response.status_code != 200:
        error(f"Unexpected status code {response.status_code} while fetching {url}")
        return None

    return response 
def new_paste(self, text, sender, **kwargs) -> str:

        ts = kwargs["date"] + kwargs["time"] \
            if "date" in kwargs and "time" in kwargs \
            else get_now().strftime("%Y%m%d%H%M")

        filename = "{sender}.{ts}.txt".format(
            sender=sender,
            ts=ts
        )
        data = {
            'api_option': "paste",
            'api_dev_key': self.api_dev_key,
            'api_paste_code': text,
            'api_paste_name': filename,
        }
        try:
            r = requests.post(self.api_url, data=data, timeout=5)
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to Pastebin")
            return None

        if r.text.startswith("http"):
            return r.text.strip()

        return None 
def new_paste(self, text, sender, **kwargs) -> str:
        data = {
            'vimcn': text,
        }
        try:
            r = requests.post(self.api_url, data=data, timeout=5)
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to Vinergy")
            return None

        if r.text.startswith("http"):
            return r.text.strip()

        return None 
def upload_image(self, filename=None, filedata=None, **kwargs):
        if filedata is None:
            with open(filename, 'rb') as f:
                b64img = b64encode(f.read())
        else:
            b64img = b64encode(filedata)

        headers = {"Authorization": "Client-ID %s" % self.client_id}
        try:
            r = requests.post(
                self.url,
                headers=headers,
                data={
                    'image': b64img,
                    'type': 'base64',
                },
                timeout=5,
            )
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to Imgur")
            return None
        except:
            logger.exception("Unknown errror uploading to Imgur")
            return None

        try:
            ret = json.loads(r.text)
        except:
            return None
        if ret.get('status', None) != 200 or ret.get('success', False) != True:
            logger.error(
                "Error: Imgur returned error, {}".format(ret.get('data', ''))
            )
            return None

        link = ret.get('data', {}).get('link', None)
        return link if link is None else re.sub(r'^http:', 'https:', link) 
def __call__(self, url, method='GET', body=None, headers=None,
                 timeout=None, **kwargs):
        """Make an HTTP request using requests.

        Args:
            url (str): The URI to be requested.
            method (str): The HTTP method to use for the request. Defaults
                to 'GET'.
            body (bytes): The payload / body in HTTP request.
            headers (Mapping[str, str]): Request headers.
            timeout (Optional[int]): The number of seconds to wait for a
                response from the server. If not specified or if None, the
                requests default timeout will be used.
            kwargs: Additional arguments passed through to the underlying
                requests :meth:`~requests.Session.request` method.

        Returns:
            google.auth.transport.Response: The HTTP response.

        Raises:
            google.auth.exceptions.TransportError: If any exception occurred.
        """
        try:
            _LOGGER.debug('Making request: %s %s', method, url)
            response = self.session.request(
                method, url, data=body, headers=headers, timeout=timeout,
                **kwargs)
            return _Response(response)
        except requests.exceptions.RequestException as caught_exc:
            new_exc = exceptions.TransportError(caught_exc)
            six.raise_from(new_exc, caught_exc) 
def http_get(self, path, params=None, **kwargs):
        """
        Make a GET request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.get(url, params=params, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem retrieving data from " \
                      "the Kubernetes API server. URL: {}, params: {}".format(url, params)
            logger.error(message)
            raise KubeException(message) from err

        return response 
def http_delete(self, path, **kwargs):
        """
        Make a DELETE request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.delete(url, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem deleting data from " \
                      "the Kubernetes API server. URL: {}".format(url)
            logger.error(message)
            raise KubeException(message) from err

        return response 
def full_get(self, url, params=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))
        try:
            return self.session().get(url, params=params, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            # Only log the message to avoid logging any sensitive info.
            self.module.fail_json(msg=inst.message) 
def full_post(self, url, data=None, json=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().post(url, data=data, json=json, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
def full_put(self, url, data=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().put(url, data=data, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
def full_patch(self, url, data=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().patch(url, data=data, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
def full_delete(self, url, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().delete(url, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
def _load_well_known(self):
        """
        Gets the discovery url's data ("well-known")
        Return dict,None the well-known JSON data copy
        """
        # Memory cache
        if self._well_known_json is not None:
            return self._well_known_json

        if not self.always_use_local_file:
            try:
                r = requests.get(self.discovery_url)
                self._well_known_json = r.json()
            except (json.JSONDecodeError, requests.exceptions.ConnectionError) as e:
                logger.debug("Failed to fetch schema url from discovery {} ({})".format(self.discovery_url, e))
                logger.debug("Using builtin copy")

        if self._well_known_json is None or self.always_use_local_file:
            well_known_file = "data/well-known/mozilla-iam"  # Local fall-back
            if not os.path.isfile(well_known_file):
                dirname = os.path.dirname(os.path.realpath(__file__))
                path = dirname + "/" + well_known_file
            else:
                path = well_known_file
            self._well_known_json = json.load(open(path))

        return self._well_known_json 
def _load_schema(self, schema_url, stype="data/profile.schema"):
        """
        Loads JSON Schema from an URL
        @schema_url: str,None the schema URL
        @stype: str, type of schema to load. This is also the name of the library builtin, local copy.
        Return dict JSON object which is the CIS Profile Schema
        """
        schema = None
        if not self.always_use_local_file:
            if schema_url is not None:
                try:
                    r = requests.get(schema_url)
                    schema = r.json()
                except (json.JSONDecodeError, requests.exceptions.ConnectionError) as e:
                    logger.debug("Failed to load schema from schema_url {} ({})".format(schema_url, e))

        # That did not work, fall-back to local, built-in copy
        if schema is None or self.always_use_local_file:
            # Builtin, hardcoded schema from library
            schema_file = stype
            if not os.path.isfile(schema_file):
                dirname = os.path.dirname(os.path.realpath(__file__))
                path = dirname + "/" + schema_file
            else:
                path = schema_file

            schema = json.load(open(path))
        return schema 
def __init__(self):
        self.sess = CacheControl(requests.session(), heuristic=CustomHeuristic(days=30), cache=FileCache('.web_cache'))
        self.exceptions = requests.exceptions 
def has_permissions(self):
        try:
            self.check_bulk_quota_usage()
        except requests.exceptions.HTTPError as err:
            if err.response is not None:
                for error_response_item in err.response.json():
                    if error_response_item.get('errorCode') == 'API_DISABLED_FOR_ORG':
                        return False
        return True 
def _raise_for_status(self, response, explanation=None):
        """Raises stored :class:`APIError`, if one occurred."""
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                raise errors.NotFound(e, response, explanation=explanation)
            raise errors.APIError(e, response, explanation=explanation) 
def _do_request(self, payload):
        payload = payload.build()
        LOG.debug('Sending request to %(endpoint)s: %(payload)s',
                  {'endpoint': self.endpoint, 'payload': payload})
        try:
            resp = requests.post(
                self.endpoint,
                auth=requests.auth.HTTPBasicAuth(self.username, self.password),
                data=payload,
                # TODO(ifarkas): enable cert verification
                verify=False)

        except Exception as e:
            # This is a hack for handling 'No route to host' ConnectionError,
            # so that the Traceback would not be shown
            if e.__class__ == 'requests.exceptions.ConnectionError':
                LOG.exception('Request failed (ConnectionError)')
                raise exceptions.WSManRequestFailure()
            if e.__class__ == 'requests.exceptions.RequestException':
                LOG.exception('Request failed')
                raise exceptions.WSManRequestFailure()
            else:
                raise

        LOG.debug('Received response from %(endpoint)s: %(payload)s',
                  {'endpoint': self.endpoint, 'payload': resp.content})
        if not resp.ok:
            raise exceptions.WSManInvalidResponse(
                status_code=resp.status_code,
                reason=resp.reason)
        else:
            return resp 
def invoke(self, resource_uri, method, selectors=None, properties=None,
               expected_return_value=None):
        """Invokes a remote WS-Man method

        :param resource_uri: URI of the resource
        :param method: name of the method to invoke
        :param selectors: dictionary of selectors
        :param properties: dictionary of properties
        :param expected_return_value: expected return value reported back by
            the DRAC card. For return value codes check the profile
            documentation of the resource used in the method call. If not set,
            return value checking is skipped.
        :returns: an lxml.etree.Element object of the response received
        :raises: WSManRequestFailure on request failures
        :raises: WSManInvalidResponse when receiving invalid response
        :raises: DRACOperationFailed on error reported back by the DRAC
                 interface
        :raises: DRACUnexpectedReturnValue on return value mismatch
        """
        if selectors is None:
            selectors = {}

        if properties is None:
            properties = {}

        resp = super(WSManClient, self).invoke(resource_uri, method, selectors,
                                               properties)

        return_value = utils.find_xml(resp, 'ReturnValue', resource_uri).text
        if return_value == utils.RET_ERROR:
            message_elems = utils.find_xml(resp, 'Message', resource_uri, True)
            messages = [message_elem.text for message_elem in message_elems]
            raise exceptions.DRACOperationFailed(drac_messages=messages)

        if (expected_return_value is not None and
                return_value != expected_return_value):
            raise exceptions.DRACUnexpectedReturnValue(
                expected_return_value=expected_return_value,
                actual_return_value=return_value)

        return resp 
def block_until_number_of_known_nodes_is(self,
                                             number_of_nodes_to_know: int,
                                             timeout: int = 10,
                                             learn_on_this_thread: bool = False):
        start = maya.now()
        starting_round = self._learning_round

        while True:
            rounds_undertaken = self._learning_round - starting_round
            if len(self.__known_nodes) >= number_of_nodes_to_know:
                if rounds_undertaken:
                    self.log.info("Learned about enough nodes after {} rounds.".format(rounds_undertaken))
                return True

            if not self._learning_task.running:
                self.log.warn("Blocking to learn about nodes, but learning loop isn't running.")
            if learn_on_this_thread:
                try:
                    self.learn_from_teacher_node(eager=True)
                except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectTimeout):
                    # TODO: Even this "same thread" logic can be done off the main thread.
                    self.log.warn("Teacher was unreachable.  No good way to handle this on the main thread.")

            # The rest of the fucking owl
            if (maya.now() - start).seconds > timeout:
                if not self._learning_task.running:
                    raise RuntimeError("Learning loop is not running.  Start it with start_learning().")
                else:
                    raise self.NotEnoughNodes("After {} seconds and {} rounds, didn't find {} nodes".format(
                        timeout, rounds_undertaken, number_of_nodes_to_know))
            else:
                time.sleep(.1) 
def _node_request_handler(self, request):
        """The callback function for processing service request.

        It never raises. If anything unexpected happens, it will return a PollyResponse with details of the exception.

        :param request: an instance of PollyRequest
        :return: a PollyResponse
        """
        rospy.loginfo('Amazon Polly Request: {}'.format(request))

        try:
            response = self._dispatch(request)
            rospy.loginfo('will return {}'.format(response))
            return PollyResponse(result=response)
        except Exception as e:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            exc_type = sys.exc_info()[0]

            # not using `issubclass(exc_type, ConnectionError)` for the condition below because some versions
            # of urllib3 raises exception when doing `from requests.exceptions import ConnectionError`
            error_ogg_filename = 'connerror.ogg' if 'ConnectionError' in exc_type.__name__ else 'error.ogg'

            error_details = {
                'Audio File': os.path.join(current_dir, 'data', error_ogg_filename),
                'Audio Type': 'ogg',
                'Exception': {
                    'Type': str(exc_type),
                    'Module': exc_type.__module__,
                    'Name': exc_type.__name__,
                    'Value': str(e),
                },
                'Traceback': traceback.format_exc()
            }

            error_str = json.dumps(error_details)
            rospy.logerr(error_str)
            return PollyResponse(result=error_str) 
def _raise_for_status(self, response, explanation=None):
        """Raises stored :class:`APIError`, if one occurred."""
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                raise errors.NotFound(e, response, explanation=explanation)
            raise errors.APIError(e, response, explanation=explanation) 
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP GET function to send REST APIs.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
           ignoreError: True or False.  If False, the response will be returned.
        """
        if silentMode is False:
            print('\nGET:', restApi)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.get(restApi, headers=self.jsonHeader)

            if silentMode is False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http GET error:{0}\n'.format(response.text))
            return response

        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http GET error: {0}\n'.format(errMsg)) 
def post(self, restApi, data={}, headers=None, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP POST function to mainly used to create or start operations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The special header to use for the URL.
           silentMode: True or False.  To display URL, data and header info.
           noDataJsonDumps: True or False. If True, use json dumps. Else, accept the data as-is. 
           ignoreError: True or False.  If False, the response will be returned. No exception will be raised.
        """

        if headers != None:
            originalJsonHeader = self.jsonHeader
            self.jsonHeader = headers

        data = json.dumps(data)

        print('\nPOST:', restApi)
        if silentMode == False:
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.post(restApi, data=data, headers=self.jsonHeader)
            # 200 or 201
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http POST error: {0}\n'.format(response.text))

            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http POST error: {0}\n'.format(errMsg)) 
def delete(self, restApi, data={}, headers=None):
        """
        Description
           A HTTP DELETE function to delete the session.
           For Linux API server only.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The header to use for the URL.
        """

        if headers != None:
            self.jsonHeader = headers

        print('\nDELETE:', restApi)
        print('DATA:', data)
        print('HEADERS:', self.jsonHeader)
        try:
            response = requests.delete(restApi, data=json.dumps(data), headers=self.jsonHeader)
            print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                raise IxNetRestApiException('http DELETE error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http DELETE error: {0}\n'.format(errMsg)) 
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP GET function to send REST APIs.

        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
           ignoreError: True or False.  If False, the response will be returned.
        """
        if silentMode is False or self.generateRestLogFile is True:
            #print('\nGET:', restApi)
            #print('HEADERS:', self.jsonHeader)
            self.logInfo('\nGET: {0}'.format(restApi))
            self.logInfo('HEADERS: {0}'.format(self.jsonHeader))

        try:
            # For binary file
            if stream:
                response = requests.get(restApi, stream=True, headers=self.jsonHeader, verify=self.verifySslCert)
            if stream == False:
                response = requests.get(restApi, headers=self.jsonHeader, verify=self.verifySslCert)

            if silentMode is False:
                self.logInfo('STATUS CODE: {0}'.format(response.status_code))
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    if 'message' in response.json() and response.json()['messsage'] != None:
                        self.logWarning('\n%s' % response.json()['message'])
                    raise IxNetRestApiException('GET error:{0}\n'.format(response.text))
            return response

        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('GET error: {0}\n'.format(errMsg)) 
**************************************************


Python requests.Response() Examples

def get(self, route, query=None, timeout=None):
        """
        Send a GET request to Promenade.

        :param string route: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v pairs to add to the query string
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        while True:
            url = self.base_url + route
            self.logger.debug('GET ' + url)
            self.logger.debug('Query Params: ' + str(query))
            resp = self.__session.get(
                url, params=query, timeout=self._timeout(timeout))

            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
def get(self, endpoint, query=None, timeout=None):
        """
        Send a GET request to Drydock.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v pairs to add to the query string
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        while True:
            url = self.base_url + endpoint
            self.logger.debug('GET ' + url)
            self.logger.debug('Query Params: ' + str(query))
            resp = self.__session.get(
                url, params=query, timeout=self._timeout(timeout))

            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
def process_protein_info_to_model(response: Response):
    """Process description.

    :param response: response from KEGG API
    :type: dict
    :return: protein model attributes
    """
    # Get protein description from KEGG API
    description = parse_description(response)
    # Filters out db link columns
    protein_as_dict = get_description_properties(
        description=description,
        description_property=DBLINKS,
        columns=PROTEIN_RESOURCES
    )
    # Adapt the dict keys to match protein model columns
    return kegg_properties_to_models(protein_as_dict) 
def transmit(self, transport, data, content_type):
        """Transmit the resource to be uploaded.

        Args:
            transport (~requests.Session): A ``requests`` object which can
                make authenticated requests.
            data (bytes): The resource content to be uploaded.
            content_type (str): The content type of the resource, e.g. a JPEG
                image has content type ``image/jpeg``.

        Returns:
            ~requests.Response: The HTTP response returned by ``transport``.
        """
        method, url, payload, headers = self._prepare_request(data, content_type)
        response = _helpers.http_request(
            transport,
            method,
            url,
            data=payload,
            headers=headers,
            retry_strategy=self._retry_strategy,
        )
        self._process_response(response)
        return response 
def send_message(self, text: str, retry_count: int = 3) -> Response:
        """Send raw text to bot framework using direct line api"""

        url = "/".join(
            [self._base_url, "conversations", self._conversation_id, "activities"]
        )
        json_payload = {
            "conversationId": self._conversation_id,
            "type": "message",
            "from": {"id": "user1"},
            "text": text,
        }

        success = False
        current_retry = 0
        bot_response = None
        while not success and current_retry < retry_count:
            bot_response = requests.post(url, headers=self._headers, json=json_payload)
            current_retry += 1
            if bot_response.status_code == 200:
                success = True

        return bot_response 
def validar_reposta(resposta: requests.Response) -> dict:
    """
    Valida a resposta da API do Lomadee e retorna os dados

    :param resposta: Reposta a ser validada
    :type resposta: requests.Response

    :raises Exception: Falha na requisição

    :return: Dados da Resposta
    :rtype: dict
    """
    if resposta.status_code == 200:
        return resposta.json()
    else:
        return erro(resposta) 
def erro(resposta: requests.Response):
    """
    Gera uma exceção padronizada

    :param resposta: Resposta
    :type resposta: requests.Response

    :raises Exception: Falha na requisição
    """
    dados = {
        "codigo": resposta.status_code,
        "motivo": resposta.reason,
        "resposta": None
    }
    try:
        dados["resposta"] = resposta.json()
    except JSONDecodeError:
        pass

    if dados["codigo"] == 404:
        raise RespostaVaziaException()
    else:
        raise Exception(dados) 
def process_response(wrapped, instance, args, kwargs):
    """
    Decorator to process requests.Response

    Raises:
        Exception: Service Unavailable

    Returns:
        dict: json data
    """

    try:
        resp = wrapped(*args, **kwargs)

    except (requests.ConnectionError, requests.Timeout) as e:
        raise Exception("Service Unavailable") from e

    else:
        resp.raise_for_status()
        return resp.json() 
def call_dbot_api(self, dbot_address: str, uri: str, method: str, **requests_kwargs) -> Response:
        """Send the API's HTTP request

        Channel will be auto created if no channel or be topuped if
        insufficient balance in channel.
        The deposit value is determined by `deposit_strategy`.
        A signature of balance will be sent to DBot server to pay the price of the API.

        :param dbot_address: address of the DBot contract
        :param uri: uri of the endpoint
        :param method: method of the endpoint
        :param requests_kwargs: the other args for http request is same with `requests`
        :return: :class:`Response <Response>` object, http response of the API
        :rtype: requests.Response
        """
        dbot_address = Web3.toChecksumAddress(dbot_address)
        price = self.get_price(dbot_address, uri, method)
        channel = self._get_suitable_channel(dbot_address, price)
        channel.create_transfer(price)
        domain = self.get_dbot_domain(dbot_address)
        dbot_url = domain if domain.lower().startswith('http') else 'http://{}'.format(domain)
        url = '{}/call/{}/{}'.format(dbot_url, dbot_address, remove_slash_prefix(uri))
        return self._request(channel, method, url, **requests_kwargs) 
def setup(mocker):
    class Setup:
        resp = mocker.patch.object(requests.Response, '__init__')
        resp.status_code = 200
        resp.json = lambda: {'meta': {'error_type': 'CustomError',
                                      'error_detail': 'custom error detail'}}
        req_get = mocker.patch('requests.get')
        req_get.return_value = resp

        req_post = mocker.patch('requests.post')
        req_post.return_value = resp

        req_delete = mocker.patch('requests.delete')
        req_delete.return_value = resp

        client = KieferClient('access_token')
        headers = {'Authorization': 'Bearer access_token'}
    return Setup 
def __init__(self, status_code, content=None, headers=None):
        """A requests.Response that can be used as a mock return_value.

        A key feature is that the instance will evaluate to True or False like
        a real Response, based on the status_code.

        Properties like ok, status_code, text, and content, and methods like
        json(), work as expected based on the inputs.

        :param status_code: Integer HTTP response code (200, 404, etc.)
        :param content: String supplying the payload content of the response.
                        Using a json-encoded string will make the json() method
                        behave as expected.
        :param headers: Dict of HTTP header values to set.
        """
        super(FakeResponse, self).__init__()
        self.status_code = status_code
        if content:
            self._content = content.encode('utf-8')
            self.encoding = 'utf-8'
        if headers:
            self.headers = headers 
def post_stats(request: WSGIRequest, response: HttpResponse, data: dict) -> Response:
    es_url_template = get_request_es_url_template(request)
    if not es_url_template:
        return None
    payload = build_payload(data, request, response)
    es_url = es_url_template.format_map(
        dict(payload, ymd=datetime.utcnow().strftime('%Y-%m-%d')),
    )
    body = force_bytes(json.dumps(payload, cls=PayloadJSONEncoder))
    try:
        resp = sess.post(
            es_url, data=body, headers={'Content-Type': 'application/json'}, timeout=0.5
        )
        if resp.status_code != 201:
            log.warning(
                'Unable to post data to %s (error %s): %s',
                es_url,
                resp.status_code,
                resp.text,
            )
        return resp
    except Exception as e:
        log.warning('Unable to post data to %s: %s', es_url, e) 
def get_raw(self, url: str, _attempt=1) -> requests.Response:
        """Downloads a file anonymously.

        :raises QueryReturnedNotFoundException: When the server responds with a 404.
        :raises QueryReturnedForbiddenException: When the server responds with a 403.
        :raises ConnectionException: When download failed.

        .. versionadded:: 4.2.1"""
        with self.get_anonymous_session() as anonymous_session:
            resp = anonymous_session.get(url, stream=True)
        if resp.status_code == 200:
            resp.raw.decode_content = True
            return resp
        else:
            if resp.status_code == 403:
                # suspected invalid URL signature
                raise QueryReturnedForbiddenException("403 when accessing {}.".format(url))
            if resp.status_code == 404:
                # 404 not worth retrying.
                raise QueryReturnedNotFoundException("404 when accessing {}.".format(url))
            raise ConnectionException("HTTP error code {}.".format(resp.status_code)) 
def test_get_document_types(self, mock_requests):
        mock_response_json = {
            "DE": [
                "DrivingLicence",
                "IdentityCard",
                "Passport",
                "ResidencePermit"
            ]
        }
        response_obj = Response()
        response_obj.__setattr__("status_code", 200)
        response_obj.__setattr__("_content", json.dumps(
            mock_response_json).encode("utf-8"))
        mock_requests.return_value = response_obj

        country_code = "DE"

        reponse = VerificationService().get_document_types(country_code)

        assert(reponse == {
               "DE": ["DrivingLicence", "IdentityCard", "Passport", "ResidencePermit"]
               }) 
def test_that_next_value_is_returned_on_no_error(self, request):
        """
        Test that a value from request is returned when no error is
        raised.
        """
        result = None

        def on_next(value):
            nonlocal result
            result = value

        response = requests.Response()
        response.status_code = 200
        request.return_value = response
        r = rx_request('get', 'url')

        r.subscribe(on_next=on_next)

        self.assertEqual(response, result) 
def test_that_completed_is_invoked_on_no_error(self, request):
        """
        Test that completed callback is invoked on no error.
        """
        completed = False

        def on_completed():
            nonlocal completed
            completed = True

        response = requests.Response()
        response.status_code = 200
        request.return_value = response
        r = rx_request('get', 'url')

        r.subscribe(on_completed=on_completed)

        self.assertTrue(completed) 
def test_that_error_callback_is_not_invoked_on_no_error(self, request):
        """
        Test that error callback is not invoked on no error.
        """
        error = False

        def on_error(_):
            nonlocal error
            error = True

        response = requests.Response()
        response.status_code = 200
        request.return_value = response
        r = rx_request('get', 'url')

        r.subscribe(on_error=on_error)

        self.assertFalse(error) 
def request(session, method, url, **kwargs):
    """
    :desc: Custom wrapper method to add a timeout message
           when there is a `requests.exceptions.ConnectionError`
           or `requests.ReadTimeout` exception.
    :param: `session` requests.Session object
            `method` HTTP method to use
            `url` name of the URL
    :return: requests.Response object.
    """

    try:
        return session.request(method=method, url=url, timeout=(5, 5), **kwargs)
    except (ConnectionError, ReadTimeout):
        print(INTERNET_DOWN_MSG)
        sys.exit(1) 
def print_response(data_type='text', code=200, data=None, extra=None, pager=False, inverse=False):
    """
    :desc: Prints response to user.
    :param: `data_type` Type of data
            `data` Data to print
            `extra` Extra messages to print
            `code` Response code
    """

    color = None

    if code == 503:
        data = SERVER_DOWN_MSG
        color = 'FAIL'
    elif code == 404 or code == 400:
        color = 'WARNING'
    elif code == 401:
        color = 'FAIL'
        data = UNAUTHORIZED_MSG

    print_response_util(data, extra, data_type, color, is_pager=pager, inverse=inverse) 
def put(self, endpoint, query=None, body=None, data=None, timeout=None):
        """
        Send a PUT request to Promenade. If both body and data are specified,
        body will be used.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v parameters to add to the query string
        :param string body: A string to use as the request body. Will be treated as raw
        :param data: Something json.dumps(s) can serialize. Result will be used as the request body
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        url = self.base_url + endpoint
        while True:
            self.logger.debug('PUT ' + url)
            self.logger.debug('Query Params: ' + str(query))
            if body is not None:
                self.logger.debug(
                    "Sending PUT with explicit body: \n%s" % body)
                resp = self.__session.put(
                    self.base_url + endpoint,
                    params=query,
                    data=body,
                    timeout=self._timeout(timeout))
            else:
                self.logger.debug(
                    "Sending PUT with JSON body: \n%s" % str(data))
                resp = self.__session.put(
                    self.base_url + endpoint,
                    params=query,
                    json=data,
                    timeout=self._timeout(timeout))
            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
def post(self, endpoint, query=None, body=None, data=None, timeout=None):
        """
        Send a POST request to Drydock. If both body and data are specified,
        body will be used.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v parameters to add to the query string
        :param string body: A string to use as the request body. Will be treated as raw
        :param data: Something json.dumps(s) can serialize. Result will be used as the request body
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        url = self.base_url + endpoint
        while True:
            self.logger.debug('POST ' + url)
            self.logger.debug('Query Params: ' + str(query))
            if body is not None:
                self.logger.debug(
                    "Sending POST with explicit body: \n%s" % body)
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    data=body,
                    timeout=self._timeout(timeout))
            else:
                self.logger.debug(
                    "Sending POST with JSON body: \n%s" % str(data))
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    json=data,
                    timeout=self._timeout(timeout))
            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
def post(self, endpoint, query=None, body=None, data=None, timeout=None):
        """
        Send a POST request to Drydock. If both body and data are specified,
        body will will be used.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v parameters to add to the query string
        :param string body: A string to use as the request body. Will be treated as raw
        :param data: Something json.dumps(s) can serialize. Result will be used as the request body
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        url = self.base_url + endpoint
        while True:
            self.logger.debug('POST ' + url)
            self.logger.debug('Query Params: ' + str(query))
            if body is not None:
                self.logger.debug(
                    "Sending POST with explicit body: \n%s" % body)
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    data=body,
                    timeout=self._timeout(timeout))
            else:
                self.logger.debug(
                    "Sending POST with JSON body: \n%s" % str(data))
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    json=data,
                    timeout=self._timeout(timeout))
            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
def remote_response(self):
        """
        远程服务器的响应, 对象, requests.Response
        :rtype: requests.Response
        """
        return self.__getattribute__("_remote_response") 
def remote_response(self, value):
        """:type value: requests.Response"""
        self.__setattr__("_remote_response", value) 
def test_homepage(self):
        """https://httpbin.org/"""

        self.rv = self.client.get(
            self.url("/"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertIn(b'httpbin', self.rv.data, msg=self.dump()) 
def test__enable_keep_alive_per_domain(self):
        """https://httpbin.org/"""
        self.reload_zmirror({"enable_keep_alive_per_domain": True})

        self.rv = self.client.get(
            self.url("/"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertIn(b'httpbin', self.rv.data, msg=self.dump()) 
def test_main_domain_as_external(self):
        self.rv = self.client.get(
            self.url("/extdomains//" + self.C.target_domain),
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertEqual(307, self.rv.status_code, self.dump()) 
def test_user_agent(self):
        """https://httpbin.org/user-agent"""

        self.rv = self.client.get(
            self.url("/user-agent"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response

        self.assertEqual(load_rv_json(self.rv)['user-agent'], DEFAULT_USER_AGENT, msg=self.dump()) 
def test_remote_set_cookie(self):
        """https://httpbin.org/cookies/set?name=value"""
        self.rv = self.client.get(
            self.url("/cookies/set?k1=value1&k2=value2"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response

        self.assertEqual(2, len(self.rv.headers.get_all("Set-Cookie")), msg=self.dump())
        for set_cookie_header in self.rv.headers.get_all("Set-Cookie"):
            if not ("k1=value1" in set_cookie_header
                    or "k2=value2" in set_cookie_header):
                raise ValueError("cookie set error" + self.dump())
        self.assertEqual(302, self.rv.status_code, msg=self.dump()) 
def test_relative_redirect_to(self):
        """https://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F"""
        self.rv = self.client.get(
            self.url("/redirect-to"),
            query_string="url=http%3A%2F%2Fexample.com%2F",
            environ_base=env(),
            headers=headers(),
        )  # type: Response

        self.assertIn("example.com", self.rv.location, msg=self.dump()) 
def test_relative_redirect_to_2(self):
        """https://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F"""
        self.rv = self.client.get(
            self.url("/redirect-to"),
            query_string="url=http%3A%2F%2Feu.httpbin.org%2F",
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertEqual(self.url("/extdomains/eu.httpbin.org/"), self.rv.location, msg=self.dump()) 
def get(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='GET'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('GET', endpoint=endpoint, data=data, headers=headers) 
def post(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='POST'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('POST', endpoint=endpoint, data=data, headers=headers) 
def put(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='PUT'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('PUT', endpoint=endpoint, data=data, headers=headers) 
def delete(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='DELETE'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('DELETE', endpoint=endpoint, data=data, headers=headers) 
def parse_description(response: Response):
    """Parse the several properties in the description file given an KEGG identifier using the KEGG API.

    :rtype: dict
    :return: description dictionary
    """
    description = {}

    for line in response.iter_lines():
        line = line.decode('utf-8')

        if not line.startswith(' '):
            keyword = get_first_word(line)

        if keyword == 'ENTRY':
            description['ENTRY'] = parse_entry_line(line)

        elif keyword == 'NAME':
            entry_name = parse_entry_line(line)
            if entry_name:
                # If there is a name, take the first element of the tuple and strip semi colon
                # in case there are multiple names
                description['ENTRY_NAME'] = entry_name[0].strip(';')

        elif keyword == 'PATHWAY':

            if 'PATHWAY' not in description:
                description['PATHWAY'] = [parse_pathway_line(line)]
            else:
                description['PATHWAY'].append(parse_pathway_line(line))

        elif keyword == 'DBLINKS':

            if 'DBLINKS' not in description:
                description['DBLINKS'] = [parse_link_line(line)]
            else:
                description['DBLINKS'].append(parse_link_line(line))

    return description 
def get(self, url, **kwargs):
        """
        :rtype: requests.Response
        """
        if 'timeout' in kwargs:
            kwargs.pop('timeout')
        return self.session.get(url, timeout=(2, 30), **kwargs) 
def __call__(self, url, method='GET', body=None, headers=None,
                 timeout=None, **kwargs):
        """Make an HTTP request using requests.

        Args:
            url (str): The URI to be requested.
            method (str): The HTTP method to use for the request. Defaults
                to 'GET'.
            body (bytes): The payload / body in HTTP request.
            headers (Mapping[str, str]): Request headers.
            timeout (Optional[int]): The number of seconds to wait for a
                response from the server. If not specified or if None, the
                requests default timeout will be used.
            kwargs: Additional arguments passed through to the underlying
                requests :meth:`~requests.Session.request` method.

        Returns:
            google.auth.transport.Response: The HTTP response.

        Raises:
            google.auth.exceptions.TransportError: If any exception occurred.
        """
        try:
            _LOGGER.debug('Making request: %s %s', method, url)
            response = self.session.request(
                method, url, data=body, headers=headers, timeout=timeout,
                **kwargs)
            return _Response(response)
        except requests.exceptions.RequestException as caught_exc:
            new_exc = exceptions.TransportError(caught_exc)
            six.raise_from(new_exc, caught_exc) 
def transmit(self, transport, data, metadata, content_type):
        """Transmit the resource to be uploaded.

        Args:
            transport (~requests.Session): A ``requests`` object which can
                make authenticated requests.
            data (bytes): The resource content to be uploaded.
            metadata (Mapping[str, str]): The resource metadata, such as an
                ACL list.
            content_type (str): The content type of the resource, e.g. a JPEG
                image has content type ``image/jpeg``.

        Returns:
            ~requests.Response: The HTTP response returned by ``transport``.
        """
        method, url, payload, headers = self._prepare_request(
            data, metadata, content_type
        )
        response = _helpers.http_request(
            transport,
            method,
            url,
            data=payload,
            headers=headers,
            retry_strategy=self._retry_strategy,
        )
        self._process_response(response)
        return response 
def recover(self, transport):
        """Recover from a failure.

        This method should be used when a :class:`ResumableUpload` is in an
        :attr:`~ResumableUpload.invalid` state due to a request failure.

        This will verify the progress with the server and make sure the
        current upload is in a valid state before :meth:`transmit_next_chunk`
        can be used again.

        Args:
            transport (~requests.Session): A ``requests`` object which can
                make authenticated requests.

        Returns:
            ~requests.Response: The HTTP response returned by ``transport``.
        """
        method, url, payload, headers = self._prepare_recover_request()
        # NOTE: We assume "payload is None" but pass it along anyway.
        response = _helpers.http_request(
            transport,
            method,
            url,
            data=payload,
            headers=headers,
            retry_strategy=self._retry_strategy,
        )
        self._process_recover_response(response)
        return response 
def req(self, url, method='get', params=None, data=None, auth=False):
        """
        请求API

        :type url: str
        :param url: API
        
        :type method: str
        :param method: HTTP METHOD
        
        :type params: dict
        :param params: query
        
        :type data: dict
        :param data: body
        
        :type auth: bool
        :param auth: if True and session expired will raise exception
        
        :rtype: requests.Response
        :return: Response
        """
        self.logger.debug('fetch api<%s:%s>' % (method, url))
        if auth and self.user_alias is None:
            raise Exception('cannot fetch api<%s> without session' % url)
        s = requests.Session()
        r = s.request(method, url, params=params, data=data, cookies=self.cookies, headers=self.headers,
                      timeout=self.timeout)
        s.close()
        if r.url is not url and RE_SESSION_EXPIRE.search(r.url) is not None:
            self.expire()
            if auth:
                raise Exception('auth expired, could not fetch with<%s>' % url)
        return r 
def print_json(j):
    try:
        if isinstance(j, requests.Response):
            j = j.json()
        s = json.dumps(j, sort_keys=True, indent=4)
        print(s)
    except Exception as e:
        print("could not decode json:", e)
        print(j) 
def _format_code_request(
        self, formatter: str, code: t.List[str], options: t.Dict[str, t.Any]
    ) -> requests.Response:
        return self.request(
            verb="POST",
            path="/jupyterlab_code_formatter/format",
            data=json.dumps(
                {"code": code, "options": options, "formatter": formatter,}
            ),
        ) 
def get_message(self, retry_count: int = 3) -> Tuple[Response, str]:
        """Get a response message back from the bot framework using direct line api"""

        url = "/".join(
            [self._base_url, "conversations", self._conversation_id, "activities"]
        )
        url = url + "?watermark=" + self._watermark

        success = False
        current_retry = 0
        bot_response = None
        while not success and current_retry < retry_count:
            bot_response = requests.get(
                url,
                headers=self._headers,
                json={"conversationId": self._conversation_id},
            )
            current_retry += 1
            if bot_response.status_code == 200:
                success = True
                json_response = bot_response.json()

                if "watermark" in json_response:
                    self._watermark = json_response["watermark"]

                if "activities" in json_response:
                    activities_count = len(json_response["activities"])
                    if activities_count > 0:
                        return (
                            bot_response,
                            json_response["activities"][activities_count - 1]["text"],
                        )
                    return bot_response, "No new messages"
        return bot_response, "error contacting bot for response" 
def __init__(self, message: str, response: Response, payload=None):
        self.message = message
        self.response = response
        self.payload = payload 
def _get_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        if requests_data:
            request_url = f"{request_url}&{urlencode(requests_data)}"

        return requests.get(request_url, headers=request_header) 
def _post_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.post(request_url, json=requests_data, headers=request_header) 
def _put_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.put(request_url, json=requests_data, headers=request_header) 
def _delete_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.delete(request_url, headers=request_header) 
def test_get_response(self):
        """This test will test out:
        - BaseAttrDict.response
        """
        tag = '2P0LYQ'
        chests = self.cr.get_player_chests(tag)
        self.assertTrue(isinstance(chests.response, requests.Response)) 
**************************************************


Python requests.auth() Examples

def login(self):
        HEADERS = {
            'Ubi-AppId': UBI_APP_ID,
            'Content-Type': 'application/json; charset=UTF-8',
            'User-Agent': 'Mozilla/5.0',
            'Ubi-LocaleCode': 'en-US',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        payload = {'rememberMe': 'true'}
        r = requests.post(LOGIN_URL, headers=HEADERS, auth=HTTPBasicAuth(self.SECRET_USERNAME, self.SECRET_PASSWORD), json=payload)
        if r.status_code == 200:
            self.session = json.loads(r.text)
            f = open('info.txt', 'w')
            json.dump(r.json(), f)
            f.close()
            print('INFO: Created a new session successfully.')
            self.connected = True
            return True
        else:
            #raise Exception('ERROR: Login request failed:')
            print(r)
            print(type(r))
            pprint.pprint(r.text)
            self.connected = False
            return False 
def __init__(self):

        self.buyorder = None
        self.sellorder = None

        self.endpoint = "https://api.exchange.coinbase.com"
        #self.endpoint = "http://demo-api.hitbtc.com"

        # Live Keys
        self.api_key = ""
        self.secret = ""
        self.passphrase = ""

        self.auth = CoinbaseExchangeAuth(self.api_key, self.secret, self.passphrase)

        self.logger = FileLogger("coinbase-orderbook") 
def import_project(project, opts):
    u = opts.scheme + '://' + opts.host + _api + opts.project_id
    r = requests.patch(
            url=u,
            auth=HTTPBasicAuth(opts.username, opts.password),
            data=json.dumps(project),
            headers={'Content-Type': 'application/json'},
            verify=not (opts.insecure_skip_verify and opts.insecure_skip_verify))

    rjson = r.json()
    ret = dict(lair_response)
    ret['status'] = rjson['Status']
    ret['message'] = rjson['Message']

    return ret

# Function that performs project export. Returns a json string 
def __init__(self, base_url, *args, **kwargs):
        requests.Session.__init__(self, *args, **kwargs)

        self.base_url = base_url
        
        # Check for basic authentication
        parsed_url = urlparse(self.base_url)
        if parsed_url.username and parsed_url.password:
            netloc = parsed_url.hostname
            if parsed_url.port:
                netloc += ":%d" % parsed_url.port
            
            # remove username and password from the base_url
            self.base_url = urlunparse((parsed_url.scheme, netloc, parsed_url.path, parsed_url.params, parsed_url.query, parsed_url.fragment))
            # configure requests to use basic auth
            self.auth = HTTPBasicAuth(parsed_url.username, parsed_url.password) 
def _request_data(self, url):
        try:
            if set(["COUCHBASE_USERNAME","COUCHBASE_PASSWORD"]).issubset(os.environ):
                response = requests.get(url, auth=HTTPBasicAuth(os.environ["COUCHBASE_USERNAME"], os.environ["COUCHBASE_PASSWORD"]))
            else:
                response = requests.get(url)
        except Exception as e:
            print('Failed to establish a new connection. Is {0} correct?'.format(self.BASE_URL))
            sys.exit(1)

        if response.status_code != requests.codes.ok:
            print('Response Status ({0}): {1}'.format(response.status_code, response.text))
            sys.exit(1)

        result = response.json()
        return result 
def setAuthMethod(self, auth_method):
        "Set the authentication method to use for the requests."
        self.auth_method = auth_method
        if len(self.auth_credentials) == 2:
            username, password = self.auth_credentials
            if self.auth_method == "basic":
                from requests.auth import HTTPBasicAuth
                self.h.auth = HTTPBasicAuth(username, password)
            elif self.auth_method == "digest":
                from requests.auth import HTTPDigestAuth
                self.h.auth = HTTPDigestAuth(username, password)
            elif self.auth_method == "ntlm":
                from requests_ntlm import HttpNtlmAuth
                self.h.auth = HttpNtlmAuth(username, password)
        elif self.auth_method == "kerberos":
            from requests_kerberos import HTTPKerberosAuth
            self.h.auth = HTTPKerberosAuth() 
def setAuthMethod(self, auth_method):
        "Set the authentication method to use for the requests."
        self.auth_method = auth_method
        if len(self.auth_credentials) == 2:
            username, password = self.auth_credentials
            if self.auth_method == "basic":
                from requests.auth import HTTPBasicAuth
                self.h.auth = HTTPBasicAuth(username, password)
            elif self.auth_method == "digest":
                from requests.auth import HTTPDigestAuth
                self.h.auth = HTTPDigestAuth(username, password)
            elif self.auth_method == "ntlm":
                from requests_ntlm import HttpNtlmAuth
                self.h.auth = HttpNtlmAuth(username, password)
        elif self.auth_method == "kerberos":
            from requests_kerberos import HTTPKerberosAuth
            self.h.auth = HTTPKerberosAuth() 
def send_request(self, commands, method='cli', timeout=30):
        """
        Send a HTTP/HTTPS request containing the JSON-RPC payload, headers, and username/password.

        method = cli for structured data response
        method = cli_ascii for a string response (still in JSON-RPC dict, but in 'msg' key)
        """
        timeout = int(timeout)
        payload_list = self._build_payload(commands, method)
        response = requests.post(self.url,
                                 timeout=timeout,
                                 data=json.dumps(payload_list),
                                 headers=self.headers,
                                 auth=HTTPBasicAuth(self.username, self.password),
                                 verify=self.verify)
        response_list = json.loads(response.text)

        if isinstance(response_list, dict):
            response_list = [response_list]

        # Add the 'command' that was executed to the response dictionary
        for i, response_dict in enumerate(response_list):
            response_dict['command'] = commands[i]
        return response_list 
def __find_rows(self, find_url, **attributes):
        """
            :param find_url: URL of the find api
            :type find_url: string
            :return: The Response returned by requests including the list of documents based on find_url
            :rtype: Response object
        """
        req = self.url + find_url

        # Add range and sort parameters
        params = {
            "range": attributes.get("range", "all"),
            "sort": attributes.get("sort", [])
        }

        # Add body
        data = {
            "query": attributes.get("query", {})
        }

        try:
            return requests.post(req, params=params, json=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
def create_case_task(self, case_id, case_task):

        """
        :param case_id: Case identifier
        :param case_task: TheHive task
        :type case_task: CaseTask defined in models.py
        :return: TheHive task
        :rtype: json

        """

        req = self.url + "/api/case/{}/task".format(case_id)
        data = case_task.jsonify()

        try:
            return requests.post(req, headers={'Content-Type': 'application/json'}, data=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
def create_task_log(self, task_id, case_task_log):

        """
        :param task_id: Task identifier
        :param case_task_log: TheHive log
        :type case_task_log: CaseTaskLog defined in models.py
        :return: TheHive log
        :rtype: json
        """

        req = self.url + "/api/case/task/{}/log".format(task_id)
        data = {'_json': json.dumps({"message":case_task_log.message})}

        if case_task_log.file:
            f = {'attachment': (os.path.basename(case_task_log.file), open(case_task_log.file, 'rb'))}
            try:
                return requests.post(req, data=data,files=f, proxies=self.proxies, auth=self.auth, verify=self.cert)
            except requests.exceptions.RequestException as e:
                sys.exit("Error: {}".format(e))

        else:
            try:
                return requests.post(req, headers={'Content-Type': 'application/json'}, data=json.dumps({'message':case_task_log.message}), proxies=self.proxies, auth=self.auth, verify=self.cert)
            except requests.exceptions.RequestException as e:
                sys.exit("Error: {}".format(e)) 
def runSearchJob(self, url, appname, headers, auth, username, earliest_time):
        url = url + "/servicesNS/-/%s/search/jobs" % (appname)
        query = "savedsearch \"Splunk Version Control Audit Query POST\" username=\"%s\" | stats count | where count>0" % (username)
        logger.debug("Running requests.post() on url=%s query=\"%s\"" % (url, query))
        data = { "search" : query, "output_mode" : "json", "exec_mode" : "oneshot", "earliest_time" : earliest_time }
         
        res = requests.post(url, auth=auth, headers=headers, verify=False, data=data)
        if (res.status_code != requests.codes.ok):
            logger.error("url=%s status_code=%s reason=%s, response=\"%s\"" % (url, res.status_code, res.reason, res.text))
            return { "error": "url=%s status_code=%s reason=%s, response=\"%s\"" % (url, res.status_code, res.reason, res.text) } 
        res = json.loads(res.text)
        
        #Log return messages from Splunk, often these advise of an issue but not always...
        if len(res["messages"]) > 0:
            firstMessage = res["messages"][0]
            if 'type' in firstMessage and firstMessage['type'] == "INFO":
                #This is a harmless info message ,most other messages are likely an issue
                logger.info("messages from query=\"%s\" were messages=\"%s\"" % (query, res["messages"]))
            else:
                logger.warn("messages from query=\"%s\" were messages=\"%s\"" % (query, res["messages"]))
        return res 
def __build_auth_kwargs(self, **kwargs):
        """Setup authentication for requests

        If `access_token` is given, it is used in Authentication header.
        Otherwise basic auth is used with the client credentials.
        """

        if "access_token" in kwargs:
            headers = self.get_auth_headers(kwargs["access_token"])

            if "headers" in kwargs:
                headers.update(kwargs["headers"])

            kwargs["headers"] = headers
            del kwargs["access_token"]
        elif "auth" not in kwargs:
            kwargs["auth"] = HTTPBasicAuth(self.client_id, self.client_secret)

        return kwargs 
def _execute(self, results: TestResultSet) -> Generator[events.ExecutionEvent, None, None]:
        auth = get_requests_auth(self.auth, self.auth_type)
        with get_session(auth, self.headers) as session:
            for endpoint, test in self.schema.get_all_tests(network_test, self.hypothesis_settings, self.seed):
                for event in run_test(
                    self.schema,
                    endpoint,
                    test,
                    self.checks,
                    results,
                    session=session,
                    request_timeout=self.request_timeout,
                ):
                    yield event
                    if isinstance(event, events.Interrupted):
                        return 
def thread_task(
    tasks_queue: Queue,
    events_queue: Queue,
    schema: BaseSchema,
    checks: Iterable[Callable],
    settings: hypothesis.settings,
    auth: Optional[RawAuth],
    auth_type: Optional[str],
    headers: Optional[Dict[str, Any]],
    seed: Optional[int],
    results: TestResultSet,
    kwargs: Any,
) -> None:
    """A single task, that threads do.

    Pretty similar to the default one-thread flow, but includes communication with the main thread via the events queue.
    """
    # pylint: disable=too-many-arguments
    prepared_auth = get_requests_auth(auth, auth_type)
    with get_session(prepared_auth, headers) as session:
        _run_task(
            network_test, tasks_queue, events_queue, schema, checks, settings, seed, results, session=session, **kwargs
        ) 
def do_post(self, urlpath: str, data: Union[bytes, MutableMapping[str, str], IO[Any], None] = None,
                params: Optional[Dict[str, str]] = None,
                files: Union[
                    Dict[str, IO],
                    Dict[str, Tuple[str, Union[IO, BinaryIO], Optional[str], Optional[Dict[str, str]]]],
                    Dict[str, Tuple[str, str]],
                    Sequence[Tuple[str, Union[IO, BinaryIO]]],
                    Sequence[Tuple[str, Union[IO, BinaryIO], Optional[str], Optional[Dict[str, str]]]],
                    None
                ] = None,
                json: Optional[MutableMapping[Any, Any]] = None) -> requests.Response:
        resp = requests.post(self._make_url(urlpath), data=data, params=params, files=files, json=json,
                             verify=self.ssl_verify, cert=self.ssl_cert, auth=self.http_auth,
                             timeout=self.timeout)

        if resp.status_code < 200 or resp.status_code >= 300:
            raise AptlyAPIException(self._error_from_response(resp), status_code=resp.status_code)

        return resp 
def do_put(self, urlpath: str, data: Union[bytes, MutableMapping[str, str], IO[Any]] = None,
               files: Union[
                   Dict[str, IO],
                   Dict[str, Tuple[str, IO, Optional[str], Optional[Dict[str, str]]]],
                   Dict[str, Tuple[str, str]],
                   Sequence[Tuple[str, IO]],
                   Sequence[Tuple[str, IO, Optional[str], Optional[Dict[str, str]]]],
                   None
               ] = None,
               json: Optional[MutableMapping[Any, Any]] = None) -> requests.Response:
        resp = requests.put(self._make_url(urlpath), data=data, files=files, json=json,
                            verify=self.ssl_verify, cert=self.ssl_cert, auth=self.http_auth,
                            timeout=self.timeout)

        if resp.status_code < 200 or resp.status_code >= 300:
            raise AptlyAPIException(self._error_from_response(resp), status_code=resp.status_code)

        return resp 
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
def api_submit(request, user=None, password=None):

    # Fetch the list of deploys for the application
    # This becomes the api call
    api_url = (api_protocol
               + '://'
               + api_host
               + request)

    if user:
        logging.info('Submitting data to API: %s' % api_url)
        r = requests.put(api_url, verify=verify_ssl, auth=HTTPBasicAuth(user, password))
    else:
        logging.info('Requesting data from API: %s' % api_url)
        r = requests.get(api_url, verify=verify_ssl)

    if r.status_code == requests.codes.ok:

        logging.debug('Response data: %s' % r.json())
        return r.json()

    elif r.status_code == requests.codes.conflict:

        logging.info('Artifact location/revision combination '
                     'is not unique. Nothing to do.')

        logging.info('twoni-plete')
        print ""
        sys.exit(0)

    else:

        logging.error('There was an error querying the API: '
                      'http_status_code=%s,reason=%s,request=%s'
                      % (r.status_code, r.reason, api_url))
        logging.info('twoni-plete')
        print ""
        sys.exit(2) 
def jenkins_post(url, config_xml):

    try:

        log.info('Posting data to jenkins: %s' % url)
        headers = {'Content-Type': 'text/xml'}
        auth = HTTPBasicAuth(jenkins_user, jenkins_pass)
        r = requests.post(url, verify=False, headers=headers, auth=auth, data=config_xml)
    
        if r.status_code == requests.codes.ok:
            log.info('Success: %s' % r.status_code)
            return r
        else:
            msg = 'There was an error posting to Jenkins: http_status_code={0}s,reason={1},request={2}'.format(r.status_code, r.reason, url)
            log.error(msg)
            raise Exception(msg)

    except Exception, e:
        msg = 'Failed to create jenkins conf job: {0}'.format(e)
        log.error(msg)
        raise Exception(msg) 
def sendSignedGetRequest(self, uri, raw=False):
        r = requests.get(self.endpoint + uri, auth=self.auth)

        if raw:
            return r.json(), r
        else:
            return r.json() 
def sendSignedDeleteRequest(self, uri):
        r = requests.delete(self.endpoint + uri, auth=self.auth) 
def sendSignedPostRequest(self, uri, data):
        r = requests.post(self.endpoint + uri, json=data, auth=self.auth)
        return r.json() 
def poll(self):
        self.logger.debug("Polling url '%s'", self.url)
        reply = requests.get(self.url, auth=HTTPBasicAuth(self.user, self.password))
        if reply.status_code != requests.codes.ok:  # pylint: disable=no-member
            raise PollingError(
                "Code {code}: {error}".format(code=reply.status_code, error=reply.text)
            )

        try:
            return reply.json()
        except ValueError:
            # No valid json, try text
            return reply.text 
def get_auth(self, username, password):
        return requests.auth.HTTPBasicAuth(username, password) 
def get_auth(self, username, password):
        return requests.auth.HTTPDigestAuth(username, password) 
def __init__(self, key, b64secret, passphrase,
                 api_url="https://api.pro.coinbase.com"):
        """ Create an instance of the AuthenticatedClient class.

        Args:
            key (str): Your API key.
            b64secret (str): The secret key matching your API key.
            passphrase (str): Passphrase chosen when setting up key.
            api_url (Optional[str]): API URL. Defaults to cbpro API.
        """
        super(AuthenticatedClient, self).__init__(api_url)
        self.auth = CBProAuth(key, b64secret, passphrase)
        self.session = requests.Session() 
def get_access_token(consumer_key, consumer_secret):
    # Validate the app 
    api_URL = "https://sandbox.safaricom.co.ke/oauth/v1/generate?grant_type=client_credentials"
    get_token = requests.get(api_URL, auth=HTTPBasicAuth(consumer_key, consumer_secret))
    token = get_token.json()['access_token']
    return token 
def export_project(opts):
    u = opts.scheme + '://' + opts.host + _api + opts.project_id
    r = requests.get(
            url=u,
            auth=HTTPBasicAuth(opts.username, opts.password),
            headers={'Content-Type': 'application/json'},
            verify=not (opts.insecure_skip_verify and opts.insecure_skip_verify))

    return r.json()

# Dictionary used to represent the response from the Lair API server 
def validate(cls, username, password):
        HEADERS = {
            'Ubi-AppId': UBI_APP_ID,
            'Content-Type': 'application/json; charset=UTF-8',
            'User-Agent': 'Mozilla/5.0',
            'Ubi-LocaleCode': 'en-US',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        payload = {'rememberMe': 'true'}
        r = requests.post(LOGIN_URL, headers=HEADERS, auth=HTTPBasicAuth(username, password), json=payload)
        if r.status_code == 200:
            return True
        else:
            return False 
def send_request(self, commands, method='cli_show', timeout=30):
        timeout = int(timeout)
        payload = self._build_payload(commands, method)
        response = requests.post(self.url,
                                 timeout=timeout,
                                 data=payload,
                                 headers=self.headers,
                                 auth=HTTPBasicAuth(self.username, self.password),
                                 verify=self.verify)
        response = response.text
        return response 
def __init__(self, url, principal, password=None, proxies={}, cert=False):

        self.url = url
        self.principal = principal
        self.password = password
        self.proxies = proxies

        if self.password is not None:
            self.auth = requests.auth.HTTPBasicAuth(principal=self.principal,
                                                    password=self.password)
        else:
            self.auth = BearerAuth(self.principal)

        self.cert = cert 
def create_case(self, case):

        """
        :param case: The case details
        :type case: Case defined in models.py
        :return: TheHive case
        :rtype: json
        """

        req = self.url + "/api/case"
        data = case.jsonify()
        try:
            return requests.post(req, headers={'Content-Type': 'application/json'}, data=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
def get_case(self, case_id):
        """
            :param case_id: Case identifier
            :return: TheHive case
            :rtype: json
        """
        req = self.url + "/api/case/{}".format(case_id)

        try:
            return requests.get(req, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
def get_case_tasks(self, case_id, **attributes):
        req = self.url + "/api/case/task/_search"

        # Add range and sort parameters
        params = {
            "range": attributes.get("range", "all"),
            "sort": attributes.get("sort", [])
        }

        # Add body
        parent_criteria = {
            '_parent': {
                '_type': 'case',
                '_query': {
                    '_id': case_id
                }
            }
        }

        # Append the custom query if specified
        if "query" in attributes:
            criteria = {
                "_and": [
                    parent_criteria,
                    attributes["query"]
                ]
            }
        else:
            criteria = parent_criteria

        data = {
            "query": criteria
        }

        try:
            return requests.post(req, params=params, json=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
def get_case_template(self, name):

        """
        :param name: Case template name
        :return: TheHive case template
        :rtype: json

        """

        req = self.url + "/api/case/template/_search"
        data = {
            "query": {
                "_and": [{
                    "_field": "name",
                    "_value": name
                }, {
                    "status": "Ok"
                }]
            }
        }

        try:
            response = requests.post(req, json=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
            json_response = response.json()

            if response.status_code == 200 and len(json_response) > 0:
                return response.json()[0]
            else:
                sys.exit("Error: {}".format("Unable to find case templates"))
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
def create_alert(self, alert):

        """
        :param alert: TheHive alert
        :type alert: Alert defined in models.py
        :return: TheHive alert
        :rtype: json
        """

        req = self.url + "/api/alert"
        data = alert.jsonify()
        try:
            return requests.post(req, headers={'Content-Type': 'application/json'}, data=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
def getAllAppsList(self):
        appList = []
        url = self.splunk_rest + "/services/apps/local?search=disabled%3D0&count=0&f=title"

        logger.debug("i=\"%s\" Running requests.get() on url=%s with user=%s to obtain a list of all applications" % (self.stanzaName, url, self.srcUsername))
        #no srcUsername, use the session_key method    
        headers = {}
        auth = None
        
        if not self.srcUsername:
            headers={'Authorization': 'Splunk %s' % self.session_key}
        else:
            auth = HTTPBasicAuth(self.srcUsername, self.srcPassword)
        
        #Verify=false is hardcoded to workaround local SSL issues
        res = requests.get(url, auth=auth, headers=headers, verify=False)
        if (res.status_code != requests.codes.ok):
            logger.fatal("i=\"%s\" Could not obtain a list of all apps, URL=%s statuscode=%s reason=%s, response=\"%s\"" % (self.stanzaName, url, res.status_code, res.reason, res.text))
            sys.exit(-1)

        #Splunk returns data in XML format, use the element tree to work through it
        root = ET.fromstring(res.text)
        
        for child in root:
            #Working per entry in the results
            if child.tag.endswith("entry"):
                #Down to each entry level
                for innerChild in child:
                    #name attribute
                    if innerChild.tag.endswith("title"):
                        name = innerChild.text
                        appList.append(name)
                        logger.debug("i=\"%s\" name=\"%s\" is the app added to the list" % (self.stanzaName, name))
        return appList
        
    #As per https://stackoverflow.com/questions/1101508/how-to-parse-dates-with-0400-timezone-string-in-python/23122493#23122493 
def runSearchJob(self, query):
        url = self.splunk_rest + "/servicesNS/-/%s/search/jobs" % (self.appName)
        logger.debug("i=\"%s\" Running requests.post() on url=%s with user=%s query=\"%s\"" % (self.stanzaName, url, self.srcUsername, query))
        data = { "search" : query, "output_mode" : "json", "exec_mode" : "oneshot" }
        
        #no srcUsername, use the session_key method    
        headers = {}
        auth = None
        if not self.srcUsername:
            headers = {'Authorization': 'Splunk %s' % self.session_key }
        else:
            auth = HTTPBasicAuth(self.srcUsername, self.srcPassword)
        res = requests.post(url, auth=auth, headers=headers, verify=False, data=data)
        if (res.status_code != requests.codes.ok):
            logger.error("i=\"%s\" URL=%s statuscode=%s reason=%s response=\"%s\"" % (self.stanzaName, url, res.status_code, res.reason, res.text))
        res = json.loads(res.text)
        
        #Log return messages from Splunk, often these advise of an issue but not always...
        if len(res["messages"]) > 0:
            firstMessage = res["messages"][0]
            if 'type' in firstMessage and firstMessage['type'] == "INFO":
                #This is a harmless info message ,most other messages are likely an issue
                logger.info("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
            else:
                logger.warn("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
        return res
    
    #We keep a remote excluded app list so we don't backup anything that we are requested not to backup... 
def runSearchJob(self, query, earliest_time="-1h"):
        url = self.splunk_rest + "/servicesNS/-/%s/search/jobs" % (self.appName)
        logger.debug("i=\"%s\" Running requests.post() on url=%s with user=%s query=\"%s\"" % (self.stanzaName, url, self.destUsername, query))
        data = { "search" : query, "output_mode" : "json", "exec_mode" : "oneshot", "earliest_time" : earliest_time }
        
        #no destUsername, use the session_key method
        headers = {}
        auth = None
        if not self.destUsername:
            headers = {'Authorization': 'Splunk %s' % self.session_key }
        else:
            auth = HTTPBasicAuth(self.destUsername, self.destPassword)
        
        res = requests.post(url, auth=auth, headers=headers, verify=False, data=data)
        if (res.status_code != requests.codes.ok):
            logger.error("i=\"%s\" URL=%s statuscode=%s reason=%s, response=\"%s\"" % (self.stanzaName, url, res.status_code, res.reason, res.text))
        res = json.loads(res.text)
        
        #Log return messages from Splunk, often these advise of an issue but not always...
        if len(res["messages"]) > 0:
            firstMessage = res["messages"][0]
            if 'type' in firstMessage and firstMessage['type'] == "INFO":
                #This is a harmless info message ,most other messages are likely an issue
                logger.info("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
            else:
                logger.warn("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
        return res

    ###########################
    #
    # Main logic section
    #
    ##########################
    #restlist_override is when we are passed a dictionary with info on the restore requirements rather than obtaining this via a lookup commmand
    #config_override is for when we are passed a configuration dictionary and we do not need to read our config from stdin (i.e. we were not called by Splunk in the normal fashion) 
def _request(self, verb, endpoint, data=None):
        """Request a url.

        :param endpoint: The api endpoint we want to call.
        :param verb: POST, GET, or DELETE.
        :param params: Optional build parameters.

        :type params: dict

        :raises requests.exceptions.HTTPError: When response code is not successful.

        :returns: A JSON object with the response from the API.
        """

        headers = {
            'Accept': 'application/json',
        }
        auth = HTTPBasicAuth(self.token, '')
        resp = None

        request_url = "{0}/{1}".format(self.url, endpoint)

        if verb == 'GET':
            resp = requests.get(request_url, auth=auth, headers=headers)
        elif verb == 'POST':
            resp = requests.post(request_url, auth=auth, headers=headers, json=data)
        elif verb == 'DELETE':
            resp = requests.delete(request_url, auth=auth, headers=headers)
        else:
            raise BadVerbError(verb)

        resp.raise_for_status()

        return resp.json() 
def main():
    data_dir, docs = get_documents()

    with requests.session() as session:
        token = get_token(session)
        session.auth = BearerAuth(token)

        notebook_id = create_notebook(session)

        for location, docs in docs.items():
            section_name = location.strip('/').replace('/', '-')
            section_id = create_section(session, notebook_id, section_name)

            for doc in docs:
                upload_doc(session, section_id, data_dir, doc) 
def http_get(self,ip,port,user,password,path,payload,auth_mode=0):
        url = "http://{}:{}/{}".format(ip,port,path)
        
        self.logger.debug("http_get: Sending: %s %s auth_mode=%d" % (url, payload, auth_mode) )
        if auth_mode == 0:
            auth = HTTPBasicAuth(user,password)
        elif auth_mode == 1:
            auth = HTTPDigestAuth(user,password)
        else:
            self.send_error("Unknown auth_mode '%s' for request '%s'.  Must be 0 for 'digest' or 1 for 'basic'." % (auth_mode, url) )
            return False
            
        try:
            response = requests.get(
                url,
                auth=auth,
                params=payload,
                timeout=5
            )
        # This is supposed to catch all request excpetions.
        except requests.exceptions.RequestException as e:
            self.send_error("Connection error for %s: %s" % (url, e))
            return False
        self.logger.debug("http_get: Got: code=%s", response.status_code)
        if response.status_code == 200:
            #self.logger.debug("http_get: Got: text=%s", response.text)
            return response.text
        elif response.status_code == 400:
            self.send_error("Bad request: %s" % (url) )
        elif response.status_code == 404:
            self.send_error("Not Found: %s" % (url) )
        elif response.status_code == 401:
            # Authentication error
            self.send_error(
                "Failed to authenticate, please check your username and password")
        else:
            self.send_error("Unknown response %s: %s" % (response.status_code, url) )
        return False 
def get(self, url, params=None):
        r = requests.get(self.base_url + url,
                         params=params,
                         headers=self.headers,
                         auth=self.__get_auth())
        r.raise_for_status()
        return r.json() 
def exists(self):
        basic_auth = HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD'))
        res = requests.get('https://gemma.msl.ubc.ca/rest/v2/datasets/{}/platforms'.format(self.dataset_short_name), auth=basic_auth)
        res.raise_for_status()
        return any(platform['shortName'] == self.platform
                   for platform in res.json()['data']) 
def exists(self):
        basic_auth = HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD'))
        res = requests.get('https://gemma.msl.ubc.ca/rest/v2/datasets/{}/samples'.format(self.dataset_short_name), auth=basic_auth)
        res.raise_for_status()
        # all samples must have a batch factor
        return all('batch' in sample['sample']['factors'].values() for sample in res.json()['data']) 
def get_dataset_info(self):
        basic_auth = HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD'))
        res = requests.get('https://gemma.msl.ubc.ca/rest/v2/datasets/{}'.format(self.experiment_id), auth=basic_auth)
        res.raise_for_status()
        return res.json()['data'][0] 
def requires(self):
        res = requests.get('http://gemma.msl.ubc.ca/rest/v2/datasets/{}/samples'.format(self.experiment_id), auth=HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD')))
        res.raise_for_status()
        return [DownloadGeoSample(sample['accession']['accession'])
                for sample in res.json()['data'] if sample['accession']['externalDatabase']['name'] == 'GEO'] 
def _execute(self, results: TestResultSet) -> Generator[events.ExecutionEvent, None, None]:
        for endpoint, test in self.schema.get_all_tests(wsgi_test, self.hypothesis_settings, self.seed):
            for event in run_test(
                self.schema,
                endpoint,
                test,
                self.checks,
                results,
                auth=self.auth,
                auth_type=self.auth_type,
                headers=self.headers,
            ):
                yield event
                if isinstance(event, events.Interrupted):
                    return 
**************************************************


Python requests.HTTPError() Examples

def get_yahoo_data(self):
        """
        Cycles through "yahoo_series"ids" to get data from the Yahoo Finance.
        """        
        import time
        
        print('\nGetting data from Yahoo Finance...')
        for series_name in list(self.yahoo_series_ids.keys()):
            series_data = DataSeries()
            series_id = self.yahoo_series_ids[series_name]
            print('\t|--Getting data for {}({}).'.format(series_name, series_id))
            success = False
            while success == False:
                try:
                    series_data.yahoo_response(series_id)
                except req.HTTPError:
                    delay = 5
                    print('\t --CONNECTION ERROR--',
                          '\n\t Sleeping for {} seconds.'.format(delay))
                    time.sleep(delay)
                else:
                    success = True
            self.primary_dictionary_output[series_name] = series_data
        print('Finished getting data from Yahoo Finance!') 
def get_tc_queue_base(task_id):
    if task_id not in tc_base_cache:
        cache = True
        try:
            resp = requests.get(QUEUE_BASE + "task/%s" % task_id)
            resp.raise_for_status()
        except requests.HTTPError:
            try:
                resp = requests.get(OLD_QUEUE_BASE + "task/%s" % task_id)
                resp.raise_for_status()
            except requests.HTTPError:
                # In this case we didn't find it on either system, so make a guess
                cache = False
                value = QUEUE_BASE
            else:
                value = OLD_QUEUE_BASE
        else:
            value = QUEUE_BASE
        if cache:
            tc_base_cache[task_id] = value
    else:
        value = tc_base_cache[task_id]
    return value 
def request(self, url, method, data=None):
        """
        The requester shortcut to submit a http request to CloutFlare
        :param url:
        :param method:
        :param data:
        :return:
        """
        method = getattr(requests, method)
        response = method(
            url,
            headers=self.headers,
            json=data
        )
        content = response.json()
        if response.status_code != 200:
            print(content)
            raise requests.HTTPError(content['message'])
        return content 
def convert_to_mp4(url):
    cached = check_pony_cache(url)
    if cached is not None:
        return cached
    print("Converting {} to mp4...".format(url))
    result = requests.post("https://api.imgur.com/3/image", {
        "image": url,
        "type": "URL"
    }, headers={
        'Authorization': 'Client-ID {}'.format(settings.IMGUR_TOKEN),
        'Content-Type': 'application/x-www-form-urlencoded',
    })
    try:
        result.raise_for_status()
    except requests.HTTPError as e:
        print(e.response.content)
        return None
    mp4_url = result.json()['data'].get('mp4', None)
    if mp4_url is not None:
        cache_pony(url, mp4_url)
    return mp4_url 
def post(self, resource_type, media_type, data,
             path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.post(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            data=data,
            params=params)
        try:
            response.raise_for_status()
            if response.status_code == 204:
                return True
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
def put(self, resource_type, media_type, data,
            path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.put(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            data=data,
            params=params)
        try:
            response.raise_for_status()
            if response.status_code == 204:
                return True
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
def delete(self, resource_type, media_type, data,
               path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.delete(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            data=data,
            params=params)
        try:
            response.raise_for_status()
            if response.status_code == 204:
                return True
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
def get_last_measurement(self):
        """Get latest measurement timestamp and value.

        Returns:
            Dictionary of latest measurement timestamp and value

        Raises:
            requests.HTTPError if request failed
        """
        call_rate_limiter()
        response = requests.get(API_ENDPOINTS["time series pattern"]
                                .format(time_series_id=self.sensor_id))
        response.raise_for_status()
        time_series_data = response.json()
        last_measurement = time_series_data["lastValue"]
        return last_measurement 
def test_extract_link(self):
        success_response = {'success': True, 'data': 'link'}
        responses.add(responses.POST, constants.ENDPOINTS['extract_link'],
                      json=success_response,
                      status=200)
        responses.add(responses.POST, constants.ENDPOINTS['extract_link'],
                      status=401)
        # success call
        result = utils.extract_link(self.session, 'https://www.ojbk.com')
        self.assertEqual(result, 'link')
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['extract_link'])
        self.assertEqual(responses.calls[0].response.json(), success_response)
        # failed call
        with self.assertRaises(requests.HTTPError) as cm:
            utils.extract_link(self.session, 'https://www.ojbk.com')
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(cm.exception.response.status_code, 401) 
def test_create_my_post(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True, 'data': {}}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.create_my_post('jike')
        self.assertIsInstance(result, tuple)
        # failed by post no string content
        with self.assertRaises(AssertionError):
            self.jike_client.create_my_post(123)
        # failed call by post both link and picture at one time
        with self.assertRaises(ValueError):
            self.jike_client.create_my_post('jike', link='a', pictures='b')
        mock_response.reset_mock()
        # failed call by post failed
        mock_response.json.return_value = {'success': False}
        with self.assertRaises(RuntimeError):
            self.jike_client.create_my_post('jike')
        # failed call by server error
        mock_response.status_code = 401
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.create_my_post('jike') 
def test_delete_my_post(self):
        mock_message = Mock()
        mock_message.type = 'ORIGINAL_POST'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.delete_my_post(mock_message)
        self.assertTrue(result)
        # failed call by no post id provided
        with self.assertRaises(AssertionError):
            self.jike_client.delete_my_post(None)
        # failed call by server error
        mock_response.status_code = 403
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.delete_my_post(mock_message) 
def test__collect_action(self):
        mock_message = Mock()
        mock_message.type = 'OFFICIAL_MESSAGE'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client._collect_action(mock_message, 'collect_it')
        self.assertTrue(result)
        # failed call by assertion
        mock_message.type = ''
        with self.assertRaises(AssertionError):
            self.jike_client._collect_action(mock_message, 'uncollect_it')
        # failed by server error
        mock_message.type = 'ORIGINAL_POST'
        mock_response.status_code = 403
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client._collect_action(mock_message, 'collect_it') 
def _update_case_description(self, attributes: JsonDict, case_id: str, name: str,
                                 references: Optional[str]) -> None:
        """ Update test case description in TestRail

        *Args:* \n
            _attributes_ - attributes of test case in Robot Framework;\n
            _case_id_ - case id;\n
            _name_ - test case name;\n
            _references_ - test references.
        """
        logger.info(f"[TestRailListener] update of test {case_id} in TestRail")
        description = f"{attributes['doc']}\nPath to test: {attributes['longname']}"
        request_fields: Dict[str, Union[str, int, None]] = {
            'title': name, 'type_id': self.TESTRAIL_CASE_TYPE_ID_AUTOMATED,
            'custom_case_description': description, 'refs': references}
        try:
            json_result = self.tr_client.update_case(case_id, request_fields)
            result = json.dumps(json_result, sort_keys=True, indent=4)
            logger.info(f"[TestRailListener] result for method update_case: {result}")
        except requests.HTTPError as error:
            logger.error(f"[TestRailListener] http error, while execute request:\n{error}") 
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
def test_location_google_breaks(self):
        """User passed location arg but google api gave error"""
        caught_exceptions = [
            requests.ConnectionError, requests.HTTPError, requests.Timeout]
        with mock.patch('requests.get') as mock_get:
            for exception in caught_exceptions:
                mock_get.side_effect = exception
                with capture_sys_output():
                    with self.assertRaises(RipeAtlasToolsException):
                        cmd = Command()
                        cmd.init_args(["--location", "blaaaa"])
                        cmd.run()
            mock_get.side_effect = Exception()
            with self.assertRaises(Exception):
                cmd = Command()
                cmd.init_args(["--location", "blaaaa"])
                cmd.run() 
def lookup_index(index_name):
    if index_name is None:
        return None

    error = None
    for base in [INDEX_BASE, OLD_INDEX_BASE]:
        idx_url = INDEX_BASE + "task/" + index_name
        resp = requests.get(idx_url)
        try:
            resp.raise_for_status()
        except requests.HTTPError as e:
            error = e
            continue
        error = None
        idx = resp.json()
        task_id = idx.get("taskId")
        break

    if error:
        raise error
    if task_id:
        return task_id
    logger.warning("Task not found from index: %s\n%s" % (index_name, idx.get("message", "")))
    return task_id 
def add_wpt_fyi_data(sync, results):
    head_sha1 = sync.wpt_commits.head.sha1

    logs = []
    for target, run_has_changes in [("base", False),
                                    ("head", True)]:
        target_results = defaultdict(dict)
        try:
            runs = wptfyi.get_runs(sha=head_sha1, labels=["pr_%s" % target])
            for run in runs:
                if run["browser_name"] in browsers:
                    browser = run["browser_name"]
                    target_results[browser]["GitHub"] = [requests.get(run["raw_results_url"])]
        except requests.HTTPError as e:
            logger.error("Unable to fetch results from wpt.fyi: %s" % e)
            return False

        logs.append(target_results)
    results.add_jobs_from_log_files(*logs)
    results.wpt_sha = head_sha1
    return True 
def from_uri(
    uri: str,
    base_url: Optional[str] = None,
    method: Optional[Filter] = None,
    endpoint: Optional[Filter] = None,
    tag: Optional[Filter] = None,
    *,
    app: Any = None,
    **kwargs: Any,
) -> BaseSchema:
    """Load a remote resource and parse to schema instance."""
    kwargs.setdefault("headers", {}).setdefault("User-Agent", USER_AGENT)
    response = requests.get(uri, **kwargs)
    try:
        response.raise_for_status()
    except requests.HTTPError:
        raise HTTPError(response=response, url=uri)
    if base_url is None:
        base_url = get_base_url(uri)
    return from_file(response.text, location=uri, base_url=base_url, method=method, endpoint=endpoint, tag=tag, app=app) 
def from_wsgi(
    schema_path: str,
    app: Any,
    base_url: Optional[str] = None,
    method: Optional[Filter] = None,
    endpoint: Optional[Filter] = None,
    tag: Optional[Filter] = None,
) -> BaseSchema:
    client = Client(app, WSGIResponse)
    response = client.get(schema_path, headers={"User-Agent": USER_AGENT})  # type: ignore
    # Raising exception to provide unified behavior
    # E.g. it will be handled in CLI - a proper error message will be shown
    if 400 <= response.status_code < 600:
        raise HTTPError(response=response, url=schema_path)
    return from_file(
        response.data, location=schema_path, base_url=base_url, method=method, endpoint=endpoint, tag=tag, app=app
    ) 
def resolve_short_url(url):
    if url=='':
        return graph_nodes['tweetWithoutURL']
        
    try:
        #Follow the redirections of a URL
        r = requests.head(url, allow_redirects='HEAD', timeout=url_timeout)
        if r.status_code != 403:            
            r.raise_for_status()

        #Avoid blacklisted and flat URLs
        domain, path = analyze_url(r.url)
        if domain in blacklistURLs or path in ['', '/']:
            r.url = ''

        return re.sub('\?.*', '', re.sub('^http://', 'https://', r.url))

    #Catch the different errors       
    except requests.HTTPError as e:
        return graph_nodes['HTTPError']
    except:
        return graph_nodes['TimeoutError']

#Get outgoing links from article 
def test_acl_forbidden(self):
        """
        Testing Consul Integration
        """

        config = {
            "instances": [{
                'url': 'http://localhost:8500',
                'catalog_checks': True,
                'network_latency_checks': True,
                'new_leader_checks': True,
                'catalog_checks': True,
                'self_leader_check': True,
                'acl_token': 'wrong_token'
            }]
        }
        got_error_403 = False
        try:
            self.run_check(config)
        except HTTPError as e:
            if e.response.status_code == 403:
                got_error_403 = True

        self.assertTrue(got_error_403) 
def user_data(self, access_token, *args, **kwargs):
        data = self._user_data(access_token)
        try:
            emails = self._user_data(access_token, '/emails')
        except (HTTPError, ValueError, TypeError):
            emails = []

        emails = [(e.get('email'), e.get('primary'), 0) for e in emails if isinstance(e, dict) and e.get('verified')]
        emails.sort(key=itemgetter(1), reverse=True)
        emails = map(itemgetter(0), emails)

        if emails:
            data['email'] = emails[0]
        else:
            data['email'] = None

        return data 
def show_manifest(self, client, repository, ref):
        try:
            repo = client.repository(repository)
        except requests.HTTPError as e:
            if e.response.status_code == requests.codes.not_found:
                print("Repository {0} not found".format(repository))
            else:
                raise
        else:
            assert client.api_version in [1, 2]
            if client.api_version == 2:
                manifest, digest = repo.manifest(ref)
                print("Digest: {0}".format(digest))
                print("Manifest:")
                print(json.dumps(manifest, indent=2, sort_keys=True))
            else:
                image = repo.image(ref)
                image_json = image.get_json()
                print("Image ID: {0}".format(image.image_id))
                print("Image JSON:")
                print(json.dumps(image_json, indent=2, sort_keys=True)) 
def _reportable_http_errors(location):
    try:
        yield
    except requests.exceptions.HTTPError as ex:
        # E.g. we can see 404 errors if packages were deleted
        # without updating the repodata.
        #
        # Future: If we see lots of transient error status codes
        # in practice, we could retry automatically before
        # waiting for the next snapshot, but the complexity is
        # not worth it for now.
        raise HTTPError(
            location=location,
            http_status=ex.response.status_code,
        ) 
def _get_data(self):
        try:
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        res.raise_for_status()
        root = ET.fromstring(res.text)
        citybikewien_data = []

        # extract only wanted stations and parse to citybikewien dict
        conf = get_config()
        stations = conf['api']['citybikewien']['stations']
        for station_xml in root.findall('station'):
            if station_xml.find('id').text in list(map(lambda s: str(s['id']), stations)):
                citybikewien_data.append({
                    'id': station_xml.find('id').text,
                    'name': station_xml.find('name').text,
                    'bikes': station_xml.find('free_bikes').text,
                    'status': station_xml.find('status').text
                })

        # rename stations to names from config, so they can be mapped with other api data by name
        for conf_station in stations:
            if 'rename' in conf_station:
                for station in citybikewien_data:
                    if station['id'] == str(conf_station['id']):
                        station['name'] = conf_station['rename']
                        break

        logger.info("updated data: %s" % citybikewien_data)
        self.data = citybikewien_data 
def _new_session(self):
        self.header = {'Channel': 'inet'}
        try:
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        except RequestException or HTTPError:  # retry on error
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        res.raise_for_status()
        auth = res.json()
        logger.debug('autenticated: %s' % auth)
        self.header.update(
            {'AccessToken': auth['accessToken'], 'SessionId': auth['sessionId'], 'x-ts-supportid': auth['supportId']})
        self.session_end = time.time() + auth['sessionTimeout'] 
def test_get_error(self):
        self.adapter.register_uri('GET', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.get(ResourceType.API, MediaType.API) 
def test_get_error_plain(self):
        self.adapter.register_uri('GET', '/api/api', json={'test': 'a'}, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.get(ResourceType.API, MediaType.API) 
def test_get_plain_error(self):
        self.adapter.register_uri('GET', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.get_plain(ResourceType.API, MediaType.API) 
def test_put_error(self):
        self.adapter.register_uri('PUT', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.put(ResourceType.API, MediaType.API, data={'test': 'data'}) 
def test_delete_error(self):
        self.adapter.register_uri('DELETE', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.delete(ResourceType.API, MediaType.API, data={'test': 'data'}) 
def get(self, resource_type, media_type, path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.get(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            params=params)
        try:
            response.raise_for_status()
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            message = _format_error_message(response)
            logger.error(message)
            raise 
def get_plain(self, resource_type, media_type, path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.get(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            params=params)
        try:
            response.raise_for_status()
            return response.text
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
def get_session(self, session_id: int) -> Optional[Session]:
        """Get information about a session.

        :param session_id: The ID of the session.
        """
        try:
            data = self._client.get(f"/sessions/{session_id}")
        except requests.HTTPError as e:
            if e.response.status_code == 404:
                return None
            else:
                raise
        return Session.from_json(data) 
def download_file(self, report_url, file_name):
        """
        Downloads the file pointed by URL.

        Args:
        
            report_url (str): URL returned from API from which file can be downloaded
            file_name (str): Name to be used for downloaded file 
        """
        headers = {'content-type': 'application/json'}
    
        try:
            r = requests.get(report_url, headers=headers, verify=False, stream=True)
            if r.status_code != 200:
                message = "The HTTP response for get call on: %s is %s" % (report_url, r.status_code)
                raise TintriServerError(r.status_code, message=message)
    
            with open(file_name, 'w') as file_h:
                for block in r.iter_content(4096):
                    file_h.write(block)

        except TintriServerError:
            raise    
        except requests.ConnectionError:
            raise TintriError("API Connection error occurred.")
        except requests.HTTPError:
            raise TintriError("HTTP error occurred.")
        except requests.Timeout:
            raise TintriError("Request timed out.")
        except Exception as e:
            raise TintriError("An unexpected error occurred: " + e.__str__()) 
def test_get_cities_bad_response(mock_responses):
        mock_responses.add(
            responses.RequestsMock.POST,
            mealpy.CITIES_URL,
            status=400,
        )

        with pytest.raises(requests.exceptions.HTTPError):
            mealpy.MealPal.get_cities() 
def test_login_fail(mock_responses):
        mock_responses.add(
            method=responses.RequestsMock.POST,
            url=mealpy.LOGIN_URL,
            status=404,
            json={
                'code': 101,
                'error': 'An error occurred while blah blah, try agian.',
            },
        )

        mealpal = mealpy.MealPal()

        with pytest.raises(requests.HTTPError):
            mealpal.login('username', 'password') 
def test_get_schedules_fail(mock_responses, mock_city):
        mock_responses.add(
            method=responses.RequestsMock.GET,
            url=mealpy.MENU_URL.format(mock_city.objectId),
            status=400,
        )

        with pytest.raises(requests.HTTPError):
            mealpy.MealPal.get_schedules(mock_city.name) 
def test_fetch_more(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'more': 'items'}
        mock_response.raise_for_status.return_value = None
        self.mock_session.post.return_value = mock_response
        self.assertEqual(self.fetcher.fetch_more(None, None), {'more': 'items'})
        mock_response.status_code = 404
        mock_response.raise_for_status.side_effect = requests.HTTPError
        with self.assertRaises(requests.HTTPError):
            self.fetcher.fetch_more(None, None) 
def test_wait_login(self):
        success_response = {'logged_in': True}
        responses.add(responses.GET, constants.ENDPOINTS['wait_login'],
                      json=success_response, status=200)
        failed_response = {'logged_in': False}
        responses.add(responses.GET, constants.ENDPOINTS['wait_login'],
                      json=failed_response, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['wait_login'],
                      status=500)
        uuid = {'uuid': '123'}
        # success call
        result = utils.wait_login(uuid)
        self.assertTrue(result)
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['wait_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[0].response.json(), success_response)
        # failed call
        result = utils.wait_login(uuid)
        self.assertFalse(result)
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(responses.calls[1].request.url, constants.ENDPOINTS['wait_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[1].response.json(), failed_response)
        # failed again call
        with self.assertRaises(requests.HTTPError) as cm:
            utils.wait_login(uuid)
        self.assertEqual(len(responses.calls), 3)
        self.assertEqual(cm.exception.response.status_code, 500) 
def test_confirm_login(self):
        success_response = {'confirmed': True, 'token': 'token'}
        responses.add(responses.GET, constants.ENDPOINTS['confirm_login'],
                      json=success_response, status=200)
        failed_response = {'confirmed': False, 'token': 'token'}
        responses.add(responses.GET, constants.ENDPOINTS['confirm_login'],
                      json=failed_response, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['confirm_login'],
                      status=502)
        uuid = {'uuid': '123'}
        # success call
        result = utils.confirm_login(uuid)
        self.assertEqual(result, 'token')
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['confirm_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[0].response.json(), success_response)
        # failed call
        with self.assertRaises(SystemExit):
            utils.confirm_login(uuid)
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(responses.calls[1].request.url, constants.ENDPOINTS['confirm_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[1].response.json(), failed_response)
        # failed again call
        with self.assertRaises(requests.HTTPError) as cm:
            utils.confirm_login(uuid)
        self.assertEqual(len(responses.calls), 3)
        self.assertEqual(cm.exception.response.status_code, 502) 
def test_login(self):
        uuid = {'uuid': '123'}
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      json=uuid, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      status=400)
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      json=uuid, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      json=uuid, status=200)
        # success call
        with patch('jike.utils.wait_login', return_value=True), \
             patch('jike.utils.confirm_login', return_value='token'), \
             patch('jike.utils.make_qrcode'):
            result = utils.login()
        self.assertEqual(result, 'token')
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['create_session'])
        self.assertEqual(responses.calls[0].response.json(), uuid)
        # failed call
        with patch('jike.utils.wait_login', return_value=True), \
             patch('jike.utils.confirm_login', return_value='token'), \
             patch('jike.utils.make_qrcode'), \
             self.assertRaises(requests.HTTPError) as cm:
            utils.login()
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(cm.exception.response.status_code, 400)
        # failed call by `wait_login`
        with patch('jike.utils.wait_login', return_value=False), \
             patch('jike.utils.confirm_login', return_value='token'), \
             patch('jike.utils.make_qrcode'), \
             self.assertRaises(SystemExit):
            utils.login()
        self.assertEqual(len(responses.calls), 3)
        # failed call by `confirm_login`
        with patch('jike.utils.wait_login', return_value=True), \
             patch('jike.utils.confirm_login', return_value=None), \
             patch('jike.utils.make_qrcode'), \
             self.assertRaises(SystemExit):
            utils.login()
        self.assertEqual(len(responses.calls), 4) 
def test_get_news_feed_unread_count(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'newMessageCount': 0}
        self.mock_jike_session.get.return_value = mock_response
        result = self.jike_client.get_news_feed_unread_count()
        self.assertEqual(result, 0)
        self.assertEqual(self.jike_client.unread_count, 0)
        # failed call
        mock_response.status_code = 404
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.get_news_feed_unread_count() 
def test_get_user_profile(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'user': {'name': 'jike'}, 'statsCount': {'count': 1}}
        self.mock_jike_session.get.return_value = mock_response
        result = self.jike_client.get_user_profile('jike')
        self.assertEqual(result, self.mock_user)
        # failed call
        mock_response.status_code = 401
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.get_user_profile('jike') 
def test_repost_it(self):
        mock_message = Mock()
        mock_message.type = 'OFFICIAL_MESSAGE'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True, 'data': {}}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.repost_it('jike', mock_message)
        self.assertIsInstance(result, tuple)
        # failed by post no string content
        with self.assertRaises(AssertionError):
            self.jike_client.repost_it(123, mock_message)
        # failed call by assertion
        mock_message.type = ''
        with self.assertRaises(AssertionError):
            self.jike_client.repost_it('jike', mock_message)
        # failed call by post failed
        mock_message.type = 'ORIGINAL_POST'
        mock_response.json.return_value = {'success': False}
        with self.assertRaises(RuntimeError):
            self.jike_client.repost_it('jike', mock_message)
        # failed by server error
        mock_response.status_code = 403
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.repost_it('jike', mock_message) 
def test_comment_it(self):
        mock_message = Mock()
        mock_message.type = 'OFFICIAL_MESSAGE'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True, 'data': {}}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.comment_it('jike', mock_message)
        self.assertIsInstance(result, tuple)
        # failed by post no string content
        with self.assertRaises(AssertionError):
            self.jike_client.comment_it(123, mock_message)
        # failed call by assertion
        mock_message.type = ''
        with self.assertRaises(AssertionError):
            self.jike_client.comment_it('jike', mock_message)
        # failed call by post failed
        mock_message.type = 'ORIGINAL_POST'
        mock_response.json.return_value = {'success': False}
        with self.assertRaises(RuntimeError):
            self.jike_client.comment_it('jike', mock_message)
        # failed by server error
        mock_response.status_code = 404
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.comment_it('jike', mock_message) 
**************************************************


Python requests.head() Examples

def _check_bad_blob(self, bad_blob):
        with self.repo_server_thread({'bad_blob': bad_blob}) as (host, port):
            # Drive-by test of HEAD requests -- note that this doesn't
            # detect the error yet, so the next GET "succeeds".
            req_head = requests.head(f'http://{host}:{port}/bad_blob')
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(req_head.status_code, req.status_code)
            self.assertEqual(_no_date(req_head.headers), _no_date(req.headers))
            # You'd think that `requests` would error on this, but, no...
            # https://blog.petrzemek.net/2018/04/22/
            #   on-incomplete-http-reads-and-the-requests-library-in-python/
            self.assertEqual(200, req.status_code)
            self.assertLess(
                req.raw.tell(),  # Number of bytes that were read
                int(req.headers['content-length']),
            )
            # Ok, so we didn't get enough bytes, let's retry. This verifies
            # that the server memoizes integrity errors correctly.
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(500, req.status_code)
            self.assertIn(b'file_integrity', req.content)
            return req.content.decode() 
def complete(self):
        r=head(str(self.config.get("url")+self.config.get("file")+".zip"))
        remote=None
        if r.headers.get("Last-Modified"):
            datetime_object=parser.parse(r.headers["Last-Modified"])
            remote=float(datetime_object.timestamp())
        if os.path.isfile(self.config.get("file")+".zip"):
            statbuf=os.stat(self.config.get("file")+".zip")
            here=float(statbuf.st_mtime)
        else:
            return False
        if here<remote:
            return False
        if self.txt>0:
            return True
        else:
            return False 
def complete(self):
        for url in self.config["urls"]:
            fd=url.split("/")[-1]
            r=head(url,auth=(self.config["username"],self.config["username"]))
            remote=None
            if r.headers.get("Last-Modified"):
                datetime_object=parser.parse(r.headers["Last-Modified"])
                remote=float(datetime_object.timestamp())
            if os.path.isfile(fd):
                statbuf=os.stat(fd)
                here=float(statbuf.st_mtime)
            else:
                return False
            if here<=remote:
                return False
        return True 
def _get_wp_api_url(self, url):
        """
        Private function for finding the WP-API URL.

        Arguments
        ---------

        url : str
            WordPress instance URL.
        """
        resp = requests.head(url)

        # Search the Links for rel="https://api.w.org/".
        wp_api_rel = resp.links.get('https://api.w.org/')

        if wp_api_rel:
            return wp_api_rel['url']
        else:
            # TODO: Rasie a better exception to the rel doesn't exist.
            raise Exception 
def get_server_time(self):
        """
        Gets remote server time using HTTP
        """
        headers = {
            'User-Agent': self.user_agent
        }
        # Sometimes HEAD requests fail so we try multiple times
        for attempt in range(10):
            try:
                r = requests.head(self.url, headers=headers)
            except requests.exceptions.ConnectionError:
                time.sleep(3)
            else:
                break
        if r.status_code == 200:
            t = parsedate(r.headers['Date'])
            return datetime.fromtimestamp(time.mktime(t))
        else:
            raise Exception('Remote server did not respond. Is it down?') 
def test_head(self):
        '''test_head
        *description*
            Test Case 1: Send HEAD request to Google.  (Should get 302)
            Test Case 2: Send HEAD request to twitter. (Should get 200)
        '''
        s = Session()
        s.cUrl.setopt(pycurl.VERBOSE, True)
        # r0   = s.head('https://www.google.com')
        # req0 = requests.head('https://www.google.com')
        r1   = s.head('https://twitter.com/?lang=en')
        req1 = requests.head('https://twitter.com/?lang=en')
        s.proxy.terminate()

        r2 = s.head('https://twitterneverexist.com/?lang=en')

        # self.assertEqual(r0.status, req0.status_code)
        # self.assertEqual(r0.body  , req0.text)
        self.assertEqual(r1.status, req1.status_code)
        self.assertEqual(r1.body  , req1.text)
        self.assertEqual(r2, None) 
def validate_response_app_endpoint(p_client, appId):
    ingress_list = p_client.list_ingress(namespaceId=appId).data
    assert len(ingress_list) == 1
    ingress = ingress_list[0]
    if hasattr(ingress, 'publicEndpoints'):
        for public_endpoint in ingress.publicEndpoints:
            url = \
                public_endpoint["protocol"].lower() + "://" + \
                public_endpoint["hostname"]
            print(url)
            try:
                r = requests.head(url)
                assert r.status_code == 200, \
                    "Http response is not 200. Failed to launch the app"
            except requests.ConnectionError:
                print("failed to connect")
                assert False, "failed to connect to the app" 
def to_torrent(magnet_link):
    """turn a magnet link to a link to a torrent file"""
    infoHash = parse_magnet(magnet_link)['infoHash']
    torcache = 'http://torcache.net/torrent/' + infoHash + '.torrent'
    torrage = 'https://torrage.com/torrent/' + infoHash + '.torrent'
    reflektor = 'http://reflektor.karmorra.info/torrent/' + \
        infoHash + '.torrent'
    thetorrent = 'http://TheTorrent.org/'+infoHash
    btcache = 'http://www.btcache.me/torrent/'+infoHash
    for link in [torcache, torrage, reflektor, btcache, thetorrent]:
        try:
            print "Checking "+link
            response = requests.head(link, headers=HEADERS)
            if response.headers['content-type'] in ['application/x-bittorrent',
                                                    'application/octet-stream']:
                return link
        except requests.exceptions.ConnectionError:
            pass
    return 
def get_remote_source_length():
    url = os.environ.get('SP_REMOTE_SOURCE')
    try:
        response = requests.head(url, allow_redirects=True, timeout=10)
    except requests.exceptions.RequestException as e:
        puts(colored.red('[HEAD] %s' % url))
        puts(colored.red('Failed to get remote installation size: %s' % e))
        sys.exit(1)
    size = response.headers.get('content-length')
    if not size:
        size = response.headers.get('Content-Length')
    if not size or not size.isdigit():
        puts(colored.red('Could not fetch the remote Content-Length.'))
        sys.exit(1)
    try:
        size = int(size)
    except ValueError:
        pass
    return size 
def main():
    print('hello world')
    print('contacting google.com...')
    r = requests.head("https://www.google.com")
    print("status code:", r.status_code)
    print("PATH:", os.getenv("PATH"))
    result = helper.add(1, 1)
    print(f"1 + 1 = {result}")
    try:
        with open(Path(BASE_DIR, "input.txt")) as f:
            content = f.read().strip()
        print(content)
    except IOError:
        print("Warning: input.txt was not found")
    #
    fname = Path(BASE_DIR, "output.txt")
    print("writing to the following file:", fname)
    with open(fname, "w") as g:
        print("writing to a file", file=g)

############################################################################## 
def validate_href(image_href):
        """Validate HTTP image reference.

        :param image_href: Image reference.
        :raises: exception.ImageRefValidationFailed if HEAD request failed or
            returned response code not equal to 200.
        :returns: Response to HEAD request.
        """
        try:
            response = requests.head(image_href)
            if response.status_code != http_client.OK:
                raise exception.ImageRefValidationFailed(
                    image_href=image_href,
                    reason=("Got HTTP code %s instead of 200 in response to "
                            "HEAD request." % response.status_code))
        except requests.RequestException as e:
            raise exception.ImageRefValidationFailed(image_href=image_href,
                                                     reason=e)
        return response 
def is_downloadable(major: int, minor: int, patch: int) -> bool:
    """Test whether is a downloadable nuke version.

    Args:
        major (int): Major version
        minor (int): Minor version
        patch (int): Patch version

    Returns:
        bool: Test result
    """

    version = f'{major}.{minor}v{patch}'
    url = ('https://thefoundry.s3.amazonaws.com/'
           f'products/nuke/releases/{version}/Nuke{version}-linux-x86-release-64.tgz')
    LOGGER.debug('testing download: %s', version)
    resp = requests.head(url, timeout=3)

    return resp.status_code == 200 
def resolve_short_url(url):
    if url=='':
        return graph_nodes['tweetWithoutURL']
        
    try:
        #Follow the redirections of a URL
        r = requests.head(url, allow_redirects='HEAD', timeout=url_timeout)
        if r.status_code != 403:            
            r.raise_for_status()

        #Avoid blacklisted and flat URLs
        domain, path = analyze_url(r.url)
        if domain in blacklistURLs or path in ['', '/']:
            r.url = ''

        return re.sub('\?.*', '', re.sub('^http://', 'https://', r.url))

    #Catch the different errors       
    except requests.HTTPError as e:
        return graph_nodes['HTTPError']
    except:
        return graph_nodes['TimeoutError']

#Get outgoing links from article 
def move_head_to_tail(self, head_proxy, log_level=logging.INFO, mesg=None, *arg, **kwargs):
        if self._proxy_count <= 1:
            return False
        # with self.rlock:
        if head_proxy and head_proxy.hostname != self.head_proxy.hostname:
            logger.debug("move_head(%s)_to_TAIL() fail cause it's not the head", head_proxy)
            return False
        if not head_proxy:
            head_proxy = self.head_proxy
        if mesg:
            logger.log(logging.INFO, "move_head(%s)_to_TAIL() cause " + mesg, head_proxy, *arg, **kwargs)
        self.fix_top = False
        head_proxy.error_time = time.time()
        self._move_head_to_tail()
        for i in range(1, self._proxy_count-1):
            if not self.head_proxy.pause:
                break
            self._move_head_to_tail()
        self.try_select_head_proxy(force_to_head=True)
        return True 
def _download_report(source_url, destination_file, chunk_size):
        response = requests.head(source_url)
        content_length = int(response.headers['Content-Length'])

        start_byte = 0
        while start_byte < content_length:
            end_byte = start_byte + chunk_size - 1
            if end_byte >= content_length:
                end_byte = content_length - 1

            headers = {'Range': 'bytes=%s-%s' % (start_byte, end_byte)}
            response = requests.get(source_url, stream=True, headers=headers)
            chunk = response.raw.read()
            destination_file.write(chunk)
            start_byte = end_byte + 1
        destination_file.close() 
def httpd():
    """Start a new detached httpd container, yield to the test, then stop the container."""
    client = docker.from_env()
    container = client.containers.run("httpd_alpine", detach=True, ports={'80/tcp': 8080})

    # Wait up to 10 seconds for httpd to finish starting.
    start_time = time.time()
    while time.time() - start_time <= 10:
        try:
            assert requests.head('http://localhost:8080').status_code == 200
        except (AssertionError, requests.exceptions.ConnectionError):
            time.sleep(0.1)
        else:
            break

    # Yield to caller, then stop.
    yield container
    container.stop() 
def get_picture_url(cls, id, topic_id=None):
        if topic_id is not None:
            person = cls.by_id(id, topic_id)
        else:
            person = cls.collection.find_one({'id': str(id)})
        if not person:
            return None

        url = f"{environ.get('PERSON_PICTURE_URL_BASE')}/l/{person['id']}.jpg"

        # Make sure the URL is valid to prevent facebook errors
        r = requests.head(url)
        if r.status_code == 404:
            return None

        return url 
def process_image(image):
    medium_size = 'https:' + image['representations']['medium']
    thumb_size = 'https:' + image['representations']['thumb']
    result = requests.head(medium_size)
    size = int(result.headers['Content-Length'])
    if size >= 10000000: # 10 MB max size.
        return None
    mp4_url = convert_to_mp4(medium_size)
    if mp4_url is not None:
        return mp4_url, thumb_size, image['id'], (image['width'], image['height'])
    else:
        return None 
def _parse(self, html):
        doc = BeautifulSoup(html, 'lxml')
        ogs = doc.html.head.findAll(property=re.compile(r'^og'))

        for og in ogs:
            if og.has_attr('content'):
                self.__data__[og['property'][3:]] = og['content'] 
def complete(self):
        r=head(self.config["url"],auth=(self.config["username"],self.config["username"]))
        remote=None
        if r.headers["Last-Modified"]:
            datetime_object=parser.parse(r.headers["Last-Modified"])
            remote=float(datetime_object.timestamp())
        if os.path.isfile(self.config["file"]):
            statbuf=os.stat(self.config["file"])
            here=float(statbuf.st_mtime)
        else:
            return False
        if here>remote:
            return True
        else:
            return False 
def process_gravatar(content):
    gravatar = getattr(content, 'gravatar', None)
    if gravatar:
        params = {}

        if content.twitter:
            url = 'https://twitter.com/{}/profile_image?size=original'
            url = url.format(content.twitter)
            try:
                resp = requests.head(url)
                resp.raise_for_status()
                params['d'] = resp.headers['location']
            except Exception:
                pass

        if not params.get('d') and 'DEFAULT_GRAVATAR' in content.settings:
            default_gravatar_url = os.path.join(
                content.settings['SITEURL'],
                content.settings['DEFAULT_GRAVATAR']
            )
            params['d'] = default_gravatar_url

        params['s'] = str(content.settings.get('GRAVATAR_SIZE', GRAVATAR_SIZE))
        gravatar_url = (
            'http://www.gravatar.com/avatar/' +
            hashlib.md5(gravatar.lower().encode('utf-8')).hexdigest()
        )
        gravatar_url += '?' + urllib.parse.urlencode(params)
        content.gravatar = gravatar_url
    else:
        content.gravatar = None 
def rest_api_head(self, rest_url, api_version):
        """
        HEAD request to the REST API
        :return: Request response
        """
        response = requests.head(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            headers=self.sf_headers
        )

        return response 
def is_working_url(self, url):
        try:
            response = requests.head(url,
                                     timeout=self.url_check_timeout,
                                     verify=self.verify_ssl)
            matches = []
            if response.status_code not in EXCEPTION_STATUS_CODES:
                matches = \
                    [re.match(pattern, str(response.status_code)) is not None
                     for pattern in INVALID_STATUS_CODES_REGEX]
            return True not in matches, response.status_code
        except Timeout:
            return False, 408
        except (RequestException, Exception):
            return False, None 
def test_head_onion(self):
        '''test_head
        *description*
            Test the HEAD method is workable on hidden services or not.
            Test Case 1:  
            HEAD the [Green World](http://greenroxwc5po3ab.onion/).  

            Test Case 2:  
            HEAD the [Lambda](http://ze2djl7sv6m7eqzi.onion/)  

            Test Case 3:  
            Send HEAD to google 

        '''
        s = Session()
        s.cUrl.setopt(pycurl.VERBOSE, True)
        proxies = {
            'http' : 'socks5h://127.0.0.1:9050',
            'https': 'socks5h://127.0.0.1:9500'
        }
        r0   = s.head_onion('http://greenroxwc5po3ab.onion/')
        req0 = requests.head('http://greenroxwc5po3ab.onion/', proxies=proxies)
        self.assertEqual(r0.status, req0.status_code)
        self.assertEqual(r0.body,   req0.text)

        r1   = s.head_onion('http://ze2djl7sv6m7eqzi.onion/')
        req1 = requests.head('http://ze2djl7sv6m7eqzi.onion/', proxies=proxies)
        self.assertEqual(r1.status, req1.status_code)
        self.assertEqual(r1.body,   req1.text)

        r2 = s.head_onion('https://www.google.com')
        self.assertEqual(None, r2)

        r3 = s.head_onion('http://ze2djl7sv6m7eqzineverexist.onion/')
        self.assertEqual(None, r3)

        s.proxy.terminate() 
def exists(site):
    """Summary
    
    Parameters
    ----------
    site : TYPE
        Description
    
    Returns
    -------
    TYPE
        Description
    """
    res = requests.head(site)
    return res.ok 
def job(url, manga_name):
    def download(url, file_name, manga_name):
        if config['general']['short_title'] == 0:
            manga_name = manga_name.decode('utf-8')

        # That Unicode Stuff sucks so hard...
        if config['general']['save_path']:
            manga_path = os.path.dirname(config['general']['save_path']) + '/' + \
            manga_name + '/'
        else:
            manga_path = os.path.dirname(os.path.realpath(__file__)) + '/' + \
            manga_name + '/'
        try:
            os.makedirs(manga_path)
        except OSError:
            if not os.path.isdir(manga_path):
                raise
        #print("Download URL: ", url)
        with open(os.path.join(manga_path, file_name), "wb") as file:
            response = get(url)
            file.write(response.content)
    try:
        # Get HTTP Status Code
        # nhentai uses not only jpg.. argh
        # if 404 try some other Formats...
        # TODO: Rework this to read format out of HTML..
        formats = ["jpg", "png", "gif"]

        for i in formats:
            url_temp = url + i
            http_code  = requests.head(url_temp).status_code
            #print ("HTTP Code: ", http_code)
            if http_code == 200: # OK
                url = url_temp
                file_name = str(url.split('/')[-1])
                download(url, file_name, manga_name)

    except requests.ConnectionError:
        print("failed to connect") 
def test_report(self, report: dict):
        for link in parse_links_from_statuses(report['statuses']):
            response = requests.head(link, allow_redirects=True, headers=HEADERS)
            resolved_url = response.url
            for regex in self.blocked:
                if re.search(regex, resolved_url):
                    return True
        return False 
def get_download_size(url):
    try:
        # We don't want to download the package just yet
        response = requests.head(url, timeout=10)
    except requests.exceptions.RequestException as e:
        print('GET: %s' % url)
        raise SiphonCommandException(str(e))
    size = response.headers.get('content-length')
    if not size:
        size = response.headers.get('Content-Length')
    if not response.ok or not size or not size.isdigit():
        raise SiphonCommandException('Bad response from server. ' \
                'Please try again later.')
    return int(size) 
def check_exists(url):
    with contextlib.closing(requests.head(url, allow_redirects=True)) as r:
        return r.status_code == requests.codes.ok 
def search(self, params, cache_discovery=True):
        """Search for images and returns
        them using generator object
        :param params: search params
        :param cache_discovery whether or not to cache the discovery doc
        :return: yields url to searched image
        """

        search_params = self._search_params(params)

        res = self._query_google_api(search_params, cache_discovery)

        for image in res.get('items', []):
            try:
                response = requests.head(image['link'], timeout=5)
                content_length = response.headers.get('Content-Length')

                # check if the url is valid
                if response.status_code == 200 and \
                        'image' in response.headers['Content-Type'] and \
                        content_length:

                    # calculate download chunk size based on image size
                    self._fethch_resize_save.set_chunk_size(
                        image['link'], content_length
                    )

                    # if everything is ok, yield image url back
                    yield image['link']

                else:
                    # validation failed, go with another image
                    continue

            except requests.exceptions.ConnectTimeout:
                pass
            except requests.exceptions.SSLError:
                pass 
def _get_url(links: Dict[str, str]) -> Optional[str]:
        # try to find githab or gitlub url and use it as a bug tracker
        for url in links.values():
            if not url.startswith('http'):
                url = 'https://' + url
            parsed = urlparse(url)
            if parsed.hostname not in ('github.com', 'gitlab.com', 'bitbucket.org'):
                continue

            # build URL
            parts = parsed.path.strip('/').split('/')
            if len(parts) < 2:
                continue
            url = 'https://{}/{}/{}/issues/new'.format(parsed.hostname, *parts)

            # check that issues aren't disabled for the project
            response = requests.head(url)
            if response.status_code == 404:
                continue

            return url

        # try to find custom bug tracker by name
        for name, url in links.items():
            if 'tracker' not in name.lower():
                continue
            if not url.startswith('http'):
                url = 'https://' + url
            return url

        return None 
def _has_api(url: str) -> bool:
    if urlparse(url).hostname in ('pypi.org', 'python.org', 'test.pypi.org'):
        return True
    full_url = urljoin(url, 'dephell/json/')
    try:
        response = requests.head(full_url)
    except (SSLError, ConnectionError):
        return False
    return response.status_code < 400 
def _test_proxy(self, proxy_name=None, test_url='http://www.google.com.hk/', reason=''):
        res = None
        try:
            if proxy_name:
                self.checking_proxy.add(proxy_name)

            def async_request():
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) '
                                  'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.41 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Cache-Control': 'no-cache',
                    'Pragma': 'no-cache',
                    'Connection': 'close',
                    'Accept-Language': 'zh-CN,zh;q=0.8'
                    # 'Proxy-Name': '%s' % proxy_name
                }
                if proxy_name:
                    headers['Proxy-Name'] = proxy_name
                return requests.head(test_url, headers=headers, timeout=common.default_timeout+1, proxies={
                    "http": "http://127.0.0.1:%d" % (self._proxy_port-1),
                    "https": "http://127.0.0.1:%d" % (self._proxy_port-1)
                })
            res = yield from self._loop.run_in_executor(self.executor, async_request)
            logger.debug('_test_proxy(%s, %s) status_code: %d', proxy_name, reason, res.status_code)
            local_ip = res.headers.get('Proxy-LocalIP', None)
            return res.status_code, local_ip
        except BaseException as ex:
            logger.info('_test_proxy(%s, %s) %s: %s', proxy_name, reason, common.clazz_fullname(ex), ex)
        finally:
            if proxy_name:
                self.checking_proxy.remove(proxy_name)
            if res:
                res.close()
        return 500, None 
def run(self, saved_state):
        # Read saved state and set HTTP headers.
        headers = {}
        if saved_state:
            # If both last modified and etag, set both.
            # Otherwise just interpret the whole field as last modified.
            last_modified = saved_state

            if len(saved_state.split(';')) == 2:
                last_modified, etag = saved_state.split(';')
                headers['If-None-Match'] = etag

            headers['If-Modified-Since'] = last_modified

        # Send head first to check 304.
        response = requests.head(self.url, headers=headers)

        # If not modified, return immediately.
        if response.status_code == 304:
            return saved_state, []

        # Otherwise, do the full request.
        response = requests.get(self.url, headers=headers)

        # Form saved state.
        last_modified = response.headers.get('Last-Modified')
        etag = response.headers.get('Etag')

        if etag:
            saved_state = ';'.join([str(last_modified), etag])
        else:
            saved_state = last_modified

        # Process text.
        artifact_list = self.process_element(response.text, self.url, include_nonobfuscated=True)

        return saved_state, artifact_list 
def get_thoth_version(self) -> str:
        """Get version of Thoth backend."""
        _LOGGER.debug("Contacting Thoth at %r to receive version information", self.api_url)
        response = requests.head(self.api_url, verify=self.tls_verify)
        response.raise_for_status()
        return response.headers.get("X-Thoth-Version", "Not Available") 
def exists(path):
    r = requests.head(path)
    return r.status_code == requests.codes.ok 
def test_galaxy10(self):
        # make sure galaxy10 exists on Bovy's server

        r = requests.head(_G10_ORIGIN, allow_redirects=True)
        self.assertEqual(r.status_code, 200)
        r.close()

        galaxy10cls_lookup(0)
        self.assertRaises(ValueError, galaxy10cls_lookup, 11)
        galaxy10_confusion(np.ones((10,10))) 
def authenticate_withings(username, password):
    """Authenticate based on username and md5 hashed password."""
    global pem
    if args.warning:
        try:
            requests.packages.urllib3.disable_warnings()
        except Exception:
            pass
    if args.insecure:
        pem = False
    else:
        try:
            import certifi
            pem = certifi.old_where()
        except Exception:
            pem = True
    requests.head(URL_USAGE, timeout=3, headers=HEADER, allow_redirects=True, verify=pem)
    payload = {'email': username, 'hash': hashlib.md5(password.encode('utf-8')).hexdigest(), 'duration': '900'}
    print("[-] Authenticating at scalews.withings.net")
    response = requests.post(URL_AUTH, data=payload)
    iddata = response.json()
    sessionkey = iddata['body']['sessionid']
    response = requests.get(URL_ASSO + sessionkey)
    iddata = response.json()
    deviceid = iddata['body']['associations'][0]['deviceid']
    return deviceid, sessionkey 
def head_url(url):
    '''Returns a request HEAD object given a URL as a string'''
    return requests.head(add_schema(url)) 
def connect(self, params={}):
        self.logger.info("Connect: Connecting..")
        url = params.get('url')
        try:
            r = requests.head(url)
            if r.status_code != 200:
                self.logger.error('Logstash: Connect: error %s', params)
        except requests.ConnectionError:
            self.logger.error('Logstash: Connect: error %s', params)
            raise Exception('Logstash: Connect: connection failed')

        self.url = url 
def head(self, url):
    """head request, typically used for status code retrieval, etc.
    """
    bot.debug("HEAD %s" % url)
    return self._call(url, func=requests.head) 
def download(self, url, file_name, headers=None, show_progress=True):

    """stream to a temporary file, rename on successful completion

        Parameters
        ==========
        file_name: the file name to stream to
        url: the url to stream from
        headers: additional headers to add
        force: If the final image exists, don't overwrite

    """

    fd, tmp_file = tempfile.mkstemp(prefix=("%s.tmp." % file_name))
    os.close(fd)

    # Should we verify the request?
    verify = self._verify()

    # Check here if exists
    if requests.head(url, verify=verify).status_code in [200, 401]:
        response = self.stream(url, headers=headers, stream_to=tmp_file)

        if isinstance(response, HTTPError):
            bot.error("Error downloading %s, exiting." % url)
            sys.exit(1)
        shutil.move(tmp_file, file_name)
    else:
        bot.error("Invalid url or permissions %s" % url)
    return file_name 
def download(url, file_name, headers=None, show_progress=True):
    """stream to a temporary file, rename on successful completion

        Parameters
        ==========
        file_name: the file name to stream to
        url: the url to stream from
        headers: additional headers to add
    """

    fd, tmp_file = tempfile.mkstemp(prefix=("%s.tmp." % file_name))
    os.close(fd)

    if DISABLE_SSL_CHECK is True:
        bot.warning("Verify of certificates disabled! ::TESTING USE ONLY::")

    verify = not DISABLE_SSL_CHECK

    # Does the url being requested exist?
    if requests.head(url, verify=verify).status_code in [200, 401]:
        response = stream(url, headers=headers, stream_to=tmp_file)

        if isinstance(response, HTTPError):
            bot.error("Error downloading %s, exiting." % url)
            sys.exit(1)
        shutil.move(tmp_file, file_name)
    else:
        bot.error("Invalid url or permissions %s" % url)
    return file_name 
def is_downloadable(url):
    """
    Does the url contain a downloadable resource
    """
    h = requests.head(url, allow_redirects=True)
    header = h.headers
    content_type = header.get('content-type')
    # content_length = header.get('content-length', 1e10)
    if 'text' in content_type.lower():
        return False
    if 'html' in content_type.lower():
        return False
    return True 
def parse_xml(result, link):
    """ Parse XML results """
    # TO-DO: add unicode support
    try:
        root = ET.fromstring(result)
        for _ in root.iter('{http://s3.amazonaws.com/doc/2006-03-01/}Key'):
            target = link + "/" + _.text
            _ = requests.head(target)
            if _.status_code == 200:
                print target

    # TO-DO: add better parse error handling
    # If there is a known exception it would be better to catch that exception
    except:
        pass 
def s3_scan(silent, bucket):
    """ Checks for open S3 buckets and returns content """
    if not silent:
        print "scanning bucket: " + bucket
    link = "https://" + bucket + ".s3.amazonaws.com"
    try:
        _ = requests.head(link)
        if _.status_code != 404:
            _ = requests.get(link)
            parse_xml(_.text, link)
    except requests.exceptions.RequestException as _:
        print _ 
def get_from_cache(url, cache_dir=None):
    """
    Given a URL, look for the corresponding dataset in the local cache.
    If it's not there, download it. Then return the path to the cached file.
    """
    response = requests.head(url, allow_redirects=True)
    if response.status_code != 200:
        raise IOError("HEAD request failed for url {} with status code {}"
                      .format(url, response.status_code))
    etag = response.headers.get("ETag")
    filename = url_to_filename(url, etag)

    # get cache path to put the file
    cache_path = os.path.join(cache_dir, filename)

    if not os.path.exists(cache_path):
        # Download to temporary file, then copy to cache dir once finished.
        # Otherwise you get corrupt cache entries if the download gets interrupted.
        with tempfile.NamedTemporaryFile() as temp_file:
            print("%s not found in cache, downloading to %s", url, temp_file.name)

            http_get(url, temp_file)

            # we are copying the file before closing it, so flush to avoid truncation
            temp_file.flush()
            # shutil.copyfileobj() starts at the current position, so go to the start
            temp_file.seek(0)

            print("copying %s to cache at %s", temp_file.name, cache_path)
            with open(cache_path, 'wb') as cache_file:
                shutil.copyfileobj(temp_file, cache_file)

            print("creating metadata file for %s", cache_path)
            meta = {'url': url, 'etag': etag}
            meta_path = cache_path + '.json'
            with open(meta_path, 'w', encoding="utf-8") as meta_file:
                json.dump(meta, meta_file)

            print("removing temp file %s", temp_file.name)

    return cache_path 
def check_if_page_exists(url):
    try:
        response = requests.head(url, timeout=5)
        status_code = response.status_code
        reason = response.reason
    except requests.exceptions.ConnectionError:
        status_code = 999
        reason = 'ConnectionError'
    if status_code == 200:
        return status_code
    else:
        print("Skipping Url (not found): " + str(url)) 
def unwrap_30x(self, uri, timeout=10):

        domain = urlsplit(uri).netloc
        self._timeout = timeout

        loop_counter = 0
        try:

            if loop_counter > 5:
                raise ValueError("Infinitely looping redirect from URL: '%s'" % (uri,))

            # headers stop t.co from working so omit headers if this is a t.co link
            if domain == 't.co':
                r = requests.get(uri, timeout=self._timeout)
                return r.url, r.status_code
            # p.ost.im uses meta http refresh to redirect.
            if domain == 'p.ost.im':
                r = requests.get(uri, headers=HTTP_HEADER, timeout=self._timeout)
                uri = re.findall(r'.*url\=(.*?)\"\.*', r.text)[0]
                return uri, r.status_code
            else:

                while True:
                    try:
                        r = requests.head(uri, headers=HTTP_HEADER, timeout=self._timeout)
                    except (requests.exceptions.InvalidSchema, requests.exceptions.InvalidURL):
                        return uri, -1

                    retries = 0
                    if 'location' in r.headers and retries < self._maxretries:
                        r = requests.head(r.headers['location'])
                        uri = r.url
                        loop_counter += 1
                        retries = retries + 1
                    else:
                        return r.url, r.status_code


        except Exception as e:
            return uri, str(e) 
def _unshorten_hrefli(self, uri):
        try:
            # Extract url from query
            parsed_uri = urlparse(uri)
            extracted_uri = parsed_uri.query
            if not extracted_uri:
                return uri, 200
            # Get url status code
            r = requests.head(extracted_uri, headers=HTTP_HEADER, timeout=self._timeout)
            return r.url, r.status_code
        except Exception as e:
            return uri, str(e) 
**************************************************


Python requests.Request() Examples

def extract_url_path_and_query(full_url=None, no_query=False):
    """
    Convert http://foo.bar.com/aaa/p.html?x=y to /aaa/p.html?x=y

    :param no_query:
    :type full_url: str
    :param full_url: full url
    :return: str
    """
    if full_url is None:
        full_url = request.url
    split = urlsplit(full_url)
    result = split.path or "/"
    if not no_query and split.query:
        result += '?' + split.query
    return result


# ################# End Client Request Handler #################


# ################# Begin Middle Functions ################# 
def compose_request_for_kannel(msg = {}, server = DEFAULT_KANNEL_SERVER):
    '''composes a proper Request using the given msg and kannel server details'''

    params = {  #the data to be sent as query string with the URL
            'username' : server['username'],
            'password' : server['password'],
            'from'     : msg['from'],
            'to'       : msg['to'],
            'text'     : msg['text'],
            'smsc'     : server['smsc'],
    }

    #also ask for delivery reports
    #ref: http://www.kannel.org/download/1.4.0/userguide-1.4.0/userguide.html#DELIVERY-REPORTS
    if server['smsc'] is not None: #since SMSC IDs are *required* for getting delivery reports,
        params['dlr-mask'] = 31 #31 means we get ALL Kind of delivery reports.
        params['dlr-url'] = ROOT_URL + "/deliveredsms/?msgid=%s&dlr-report-code=%%d&dlr-report-value=%%A" % msg['id']


    url = "http://%s:%s/%s" % (server['host'],server['port'],server['path']);

    #return a prepared Request
    r = Request('GET', url, params = params)
    return r 
def _fetch_certs(request, certs_url):
    """Fetches certificates.

    Google-style cerificate endpoints return JSON in the format of
    ``{'key id': 'x509 certificate'}``.

    Args:
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        certs_url (str): The certificate endpoint URL.

    Returns:
        Mapping[str, str]: A mapping of public key ID to x.509 certificate
            data.
    """
    response = request(certs_url, method='GET')

    if response.status != http_client.OK:
        raise exceptions.TransportError(
            'Could not fetch certificates at {}'.format(certs_url))

    return json.loads(response.data.decode('utf-8')) 
def verify_token(id_token, request, audience=None,
                 certs_url=_GOOGLE_OAUTH2_CERTS_URL):
    """Verifies an ID token and returns the decoded token.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. If None
            then the audience is not verified.
        certs_url (str): The URL that specifies the certificates to use to
            verify the token. This URL should return JSON in the format of
            ``{'key id': 'x509 certificate'}``.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    certs = _fetch_certs(request, certs_url)

    return jwt.decode(id_token, certs=certs, audience=audience) 
def verify_oauth2_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Google's OAuth 2.0 authorization server.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your application's OAuth 2.0 client ID. If None then the
            audience is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience,
        certs_url=_GOOGLE_OAUTH2_CERTS_URL) 
def verify_firebase_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Firebase Authentication.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your Firebase application ID. If None then the audience
            is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience, certs_url=_GOOGLE_APIS_CERTS_URL) 
def send_router_login(request_url, username, password, session):
    url_parts = urlparse(request_url)

    auth_url = "{}://{}/api/v1/auth/local".format(url_parts.scheme, url_parts.netloc)
    data = {
        'username': username,
        'password': password
    }
    request = requests.Request('POST', auth_url, json=data)
    prepped = session.prepare_request(request)
    res = session.send(prepped)
    print("Server responded: {} {}".format(res.status_code, res.reason))

    if res.ok:
        data = res.json()
        token = data['token']

        return (res.status_code, token)

    else:
        return (res.status_code, None) 
def _send_request_safe_mode(self, method, url, **kwargs):
        """
        Send an HTTP request, and catch any exception that might occur due to connection problems.
        
        Safe mode has been removed from requests 1.x.
        """
        try:
            return requests.Session.request(self, method, url, **kwargs)
        except (MissingSchema, InvalidSchema, InvalidURL):
            raise
        except RequestException as e:
            r = LocustResponse()
            r.error = e
            r.status_code = 0  # with this status_code, content returns None
            r.request = Request(method, url).prepare() 
            return r 
def __init__(self, requestmocker):
        """
        Args:
            requestmocker: A requests Mocker object.
        """
        self.mock = requestmocker
        self.expected_auth_header = (
            requests.Request(
                "GET",
                "http://example.com",
                auth=(
                    os.getenv("TRANSPLANT_USERNAME"),
                    os.getenv("TRANSPLANT_PASSWORD"),
                ),
            )
            .prepare()
            .headers["Authorization"]
        ) 
def push_url(resource, proxy=None):

    def wrapper(interface):

        @functools.wraps(interface)
        def connection(*args, **kwargs):
            session = get_session(proxy=proxy)

            params  = interface(*args, **kwargs)

            if resource not in params['url']:
                params['url'] = urljoin(resource, params['url'])

            request = Request(method='GET',
                              headers={'Content-Type': 'application/json'},
                              **params
                              )
            response = session.send(request.prepare(), verify=False)
            return response.json()

        return connection

    return wrapper 
def authedRequest(*args, **kwargs):
    if len(args) >= 2:
        if not args[1].startswith(ILX_SERVER):
            raise ValueError(f'Server does not match {ILX_SERVER} sess cookie will fail.')
    elif 'url' in kwargs:
        if not kwargs['url'].startswith(ILX_SERVER):
            raise ValueError(f'Server does not match {ILX_SERVER} sess cookie will fail.')
    else:
        pass  # let requests take care of the error

    session = requests.Session()
    req = requests.Request(*args, **kwargs)
    req.headers.update(SESS_COOKIE)
    req.headers['Connection'] = 'keep-alive'
    prep = req.prepare()
    resp = session.send(prep)
    return resp 
def get_idle_ci_hosts(self):
        """Query Jenkins for idle servers.

        Send GET request to Jenkins server, querying for idle servers labeled
        for nGraph-ONNX CI job.

            :return:     Number of idle hosts delegated to nGraph-ONNX CI
            :rtype:      int
        """
        jenkins_request_url = self.jenkins_server + 'label/ci&&onnx/api/json?pretty=true'
        try:
            log.info('Sending request to Jenkins: %s', jenkins_request_url)
            r = requests.Request(method='GET', url=jenkins_request_url, verify=False)
            response = self.jenkins.jenkins_request(r).json()
            return int(response['totalExecutors']) - int(response['busyExecutors'])
        except Exception as e:
            log.exception('Failed to send request to Jenkins!\nException message: %s', str(e))
            raise 
def _request(cls, method, path, params=None, payload=None, auth=False, headers=None, url=None):
        cookie = None

        if auth:
            cookie = dict(username=request.cookies.get('username'))

        data = json.dumps(payload) if payload is not None else None

        if payload:
            req = requests.Request(method, url, params=params, data=data, cookies=cookie, headers=headers).prepare()
            req.headers['Content-Type'] = 'application/json'

        else:
            req = requests.Request(method, url, params=params, cookies=cookie, headers=headers).prepare()

        s = requests.Session()
        res = s.send(req)

        return res 
def _fetch_certs(request, certs_url):
    """Fetches certificates.

    Google-style cerificate endpoints return JSON in the format of
    ``{'key id': 'x509 certificate'}``.

    Args:
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        certs_url (str): The certificate endpoint URL.

    Returns:
        Mapping[str, str]: A mapping of public key ID to x.509 certificate
            data.
    """
    response = request(certs_url, method='GET')

    if response.status != http_client.OK:
        raise exceptions.TransportError(
            'Could not fetch certificates at {}'.format(certs_url))

    return json.loads(response.data.decode('utf-8')) 
def verify_token(id_token, request, audience=None,
                 certs_url=_GOOGLE_OAUTH2_CERTS_URL):
    """Verifies an ID token and returns the decoded token.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. If None
            then the audience is not verified.
        certs_url (str): The URL that specifies the certificates to use to
            verify the token. This URL should return JSON in the format of
            ``{'key id': 'x509 certificate'}``.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    certs = _fetch_certs(request, certs_url)

    return jwt.decode(id_token, certs=certs, audience=audience) 
def verify_oauth2_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Google's OAuth 2.0 authorization server.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your application's OAuth 2.0 client ID. If None then the
            audience is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience,
        certs_url=_GOOGLE_OAUTH2_CERTS_URL) 
def verify_firebase_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Firebase Authentication.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your Firebase application ID. If None then the audience
            is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience, certs_url=_GOOGLE_APIS_CERTS_URL) 
def query_elsa(user, apikey, ip, query):
    packages.urllib3.disable_warnings()
    url = 'https://' + ip + '/elsa-query/API/query'
    epoch = int(time.time())
    hash_it = hashlib.sha512()
    hash_it.update(str(epoch) + apikey)
    header = {}
    header['Authorization'] = 'ApiKey ' + user + ':' + str(epoch) + ':' + hash_it.hexdigest()
    s = Session()
    payload = '{"class_id":{"0": 1},"program_id":{"0": 1},"node_id":{"0": 1},"host_id":{"0": 1}}'
    elsa_post = Request('POST',
                        url,
                        data=[('permissions', payload), ('query_string', query)],
                        headers=header)
    postData = elsa_post.prepare()
    results = s.send(postData, verify=False)
    return results 
def get_strike_prices(self,symbol=""):
        """return list of float strike prices for specific symbol"""
        
        # Safety first!
        if not utils.check(symbol):
            return []
        
        # Format
        symbol = symbol.upper()
        
        # Assemble URL
        url =   self.endpoints['base']    + 'market/options/strikes.json'
        data = { 'symbol':symbol }
        
        # Create HTTP Request objects
        auth               = self.create_auth()
        results            = requests.get(url,params=data,auth=auth).json()
        
        # Convert to floats
        return [float(x) for x in results['response']['prices']['price']]
    ############################################################################ 
def get_exp_dates(self,symbol=""):
        """return list of float strike prices for specific symbol"""
        
        # Safety first!
        if not utils.check(symbol):
            return []
        
        # Format
        symbol = symbol.upper()
        
        # Assemble URL
        url =   self.endpoints['base']    + 'market/options/expirations.json'
        data = { 'symbol':symbol }
        
        # Create HTTP Request objects
        auth               = self.create_auth()
        results            = requests.get(url,params=data,auth=auth).json()
        
        return results['response']['expirationdates']['date']
        
    ############################################################################ 
def __api_query(self, authorization=False, path=None, method='get', query_params=None):
        with requests.Session() as s:
            headers = {'User-Agent': platform.platform()}
            url = '{0:s}{1:s}'.format(self.host_url, path)
            if authorization:
                payload = {
                        'access_key': self.access_key,
                        'nonce': str(int(time.time() * 1000))
                }
                if query_params is not None:
                    payload['query'] = query_params
                    url = '{0:s}?{1:s}'.format(url, query_params)
                token = jwt.encode(payload, self.secret_key, algorithm='HS256')
                headers['Authorization'] = 'Bearer {0:s}'.format(token.decode('utf-8'))
                req = requests.Request(method, url, headers=headers)
            else:
                req = requests.Request(method, url, headers=headers, params=query_params)
            prepped = s.prepare_request(req)
            response = s.send(prepped)
        return response.json() if response.status_code is 200 or response.status_code is 201 else None 
def response_cookie_rewrite(cookie_string):
    """
    rewrite response cookie string's domain to `my_host_name`
    :type cookie_string: str
    """
    cookie_string = regex_cookie_rewriter.sub('domain=' + my_host_name_no_port, cookie_string)
    return cookie_string


# ################# End Server Response Handler #################


# ################# Begin Client Request Handler ################# 
def filter_client_request():
    """过滤用户请求, 视情况拒绝用户的访问
    :rtype: Union[Response, None]
    """
    dbgprint('Client Request Url: ', request.url)

    # crossdomain.xml
    if os.path.basename(request.path) == 'crossdomain.xml':
        dbgprint('crossdomain.xml hit from', request.url)
        return crossdomain_xml()

    # Global whitelist ua
    if check_global_ua_pass(str(request.user_agent)):
        return None

    if is_deny_spiders_by_403 and is_denied_because_of_spider(str(request.user_agent)):
        return generate_simple_resp_page(b'Spiders Are Not Allowed To This Site', 403)

    if human_ip_verification_enabled and (
                ((human_ip_verification_whitelist_from_cookies or enable_custom_access_cookie_generate_and_verify)
                 and must_verify_cookies)
            or is_ip_not_in_allow_range(request.remote_addr)
    ):
        dbgprint('ip', request.remote_addr, 'is verifying cookies')
        if 'zmirror_verify' in request.cookies and \
                ((human_ip_verification_whitelist_from_cookies and verify_ip_hash_cookie(request.cookies.get('zmirror_verify')))
                 or (enable_custom_access_cookie_generate_and_verify and custom_verify_access_cookie(
                        request.cookies.get('zmirror_verify'), request))):
            ip_whitelist_add(request.remote_addr, info_record_dict=request.cookies.get('zmirror_verify'))
            dbgprint('add to ip_whitelist because cookies:', request.remote_addr)
        else:
            return redirect(
                "/ip_ban_verify_page?origin=" + base64.urlsafe_b64encode(str(request.url).encode(encoding='utf-8')).decode(
                    encoding='utf-8'),
                code=302)

    return None 
def get_map_url(self):
        """Get map URL for this instantiation."""
        return requests.Request(HTTP_GET, DASHBOARD_URL).prepare().url 
def call_model_runtime(
        configuration: Dict[str, object], text: str
    ) -> requests.Request:
        """ Makes a call to the model runtime api

        The model runtime api signature is:
          http://<model_runtime_host>:<port>/v1.0/model?q=<text>

        where:

          model_runtime_host - The host running the model runtime api.  To resolve
            the host running the model runtime api (in the following order):
            - MODEL_RUNTIME_API environment variable.  Used in docker.
            - config.py (which contains the DefaultConfig class).  Used running
                locally.

          port - http port number (ie, 8880)

          q - A query string to process (ie, the text utterance from user)

        For more details: (See TBD swagger file)
        """
        port = os.environ.get("MODEL_RUNTIME_SERVICE_PORT")
        host = os.environ.get("MODEL_RUNTIME_SERVICE_HOST")
        if host is None:
            host = configuration["MODEL_RUNTIME_SERVICE_HOST"]
        if port is None:
            port = configuration["MODEL_RUNTIME_SERVICE_PORT"]

        api_url = f"http://{host}:{port}/v1.0/model"
        qstrings = {"q": text}
        return requests.get(api_url, params=qstrings) 
def get_timestamp(url):
    """
    get the timestamp of an HTTP get request
    :param url: the URL of the request
    :return the timestamp of the request, of None if the request is not in the cache
    """
    def _to_bytes(s, encoding='utf-8'):
        return bytes(s, encoding)

    def create_key(request):
        url, body = request.url, request.body
        key = hashlib.sha256()
        key.update(_to_bytes(request.method.upper()))
        key.update(_to_bytes(url))
        if request.body:
            key.update(_to_bytes(body))
        return key.hexdigest()

    def url_to_key(url):
        session = requests.Session()
        return create_key(session.prepare_request(requests.Request('GET', url)))

    #   get the cache from request_cache
    results = requests_cache.get_cache()
    #   create the key according to the url
    key_url = url_to_key(url)
    #   results.responses is a dictionary and follows the following format:
    #   { 'key': (requests_cache.backends objects, timestamp), ..., }
    #   for example: '4c28e3e4a61e325e520d9c02e0caee99e30c00951a223e67':
    #                       (<requests_cache.backends.base._Store object at 0x12697e630>,
    #                           datetime.datetime(2018, 10, 16, 0, 19, 8, 130204)),
    if key_url in results.responses:
        back_obj, timestamp = results.responses[key_url]
        return timestamp
    return None 
def hitFor(self,subreddit,where,forwardFlag):
        logger = logging.getLogger('Reddit_API_Hitter')        
        logger.debug("New hit")
        urlToHit=self.urllist.baseURL+self.urllist.URLtypes["subreddit"]+subreddit+"/new.json"
        payload={'limit':self.limit}
        if forwardFlag == 0:
            payload['before']=where
        else:
            payload['after']=where
        self.conditionObj.acquire()
        if self.requestLeft == 0:
            logger.debug("Hit cap. Waiting for reset")
            self.conditionObj.wait()
        returnObj=None
        try:
            req = Request('GET',  urlToHit,
                          params=payload
                      )
            prepped = self.connectSession.prepare_request(req)
            logger.debug("Hitting the url" + req.url)
            r=self.connectSession.send(prepped)
            response=r.json()
            dataObj=[]
            for data in response["data"]["children"]:
                dataObj.append(SubRedditResponseData(data["data"]["id"],data["data"]["url"],data["data"]["domain"],data["data"]["subreddit"],data["data"]["title"]))
            returnObj=SubRedditResponseChildren(response["data"]["after"],response["data"]["before"],dataObj)
            self.requestLeft=self.requestLeft - 1
        except Exception as e:
            logger.debug(type(e))
        finally:
            self.conditionObj.release()
        return returnObj 
def get_graphite_render_url(self, targets, start="", stop="",
                                resp_format="json"):
        params = [('target', target) for target in targets]
        params += [('from', start or None),
                   ('until', stop or None),
                   ('format', resp_format or None)]
        return requests.Request('GET', "%s/render" % config.GRAPHITE_URI,
                                params=params).prepare().url 
def put_cdmi(self, path, data):
        """Return JSON response for a PUT to a CDMI URL.

        :arg path: path to put
        :arg data: JSON data to put
        :returns: CDMI JSON response or text response
        :rtype: dict

        """
        logging.debug("DrasticClient.put_cdmi called: \n{0}"
                      .format(path))
        req_url = self.normalize_cdmi_url(path)
        headers = {'user-agent': self.u_agent,
                   'X-CDMI-Specification-Version': "1.1"}
        if path.endswith('/'):
            headers['Content-type'] = CDMI_CONTAINER
            headers['Accept'] = CDMI_CONTAINER
        else:
            headers['Content-type'] = CDMI_OBJECT
            headers['Accept'] = CDMI_OBJECT
        req = requests.Request('PUT', req_url, headers=headers, auth=self.auth,
                               data=data)
        prepared = req.prepare()
        s = requests.Session()
        res = s.send(prepared)
        if res.status_code in [400, 401, 403, 404, 406]:
            return Response(res.status_code, res)
        elif res.status_code == 409:
            return Response(res.status_code,
                            "A resource with this name already exists")
        return Response(0, res) 
def _fetch(self, url, settings):
        """
        form action = "cgi-bin/sitefind3.pl
        method = "post"
        onsubmit="return validate_sequence(document.rm_form.sequence.value);
        """
        if url is None:
            url = self.Url
        if settings is None:
            settings = self.Settings

        form = settings.copy()
        user_agent = "PyRemoteRestMap/0.1"
        form['sequence'] = self.Sequence

        # data : is sent in the post request body; params are sent in the query.
        # To debug, use: requests.Request('post', url=url, data=form).prepare().body
        res = requests.post(url, data=form)
        res.raise_for_errors()
        soup = BeautifulSoup(res.text)
        title = soup.find('title').text
        if title == "Error":
            raise ValueError("Error response from %s: %s" % (url, title))

        # time.sleep(3)     # I assume this is in order not to overload the server. Should be done better.

        return res 
def __request(self, endpoint, payload=None):
        url = self.api_base + "/" + endpoint
        request = requests.Request("GET", url, params=payload)
        prepared = request.prepare()

        response = self.session.send(prepared)
        if response.status_code != requests.codes.ok:
            raise OXRStatusError(request, response)
        json = response.json()
        if json is None:
            raise OXRDecodeError(request, response)
        return json 
def get_request_vars(self):
        """ Returns the variables required by `request()` and other functions.

          :return: (headers, logger, request_object, response, service)
          :rtype: (dict, logging.Logger, requests.Request|None, list|dict|None, string)
        """
        return (
            self.get_headers(),
            logging.getLogger('sfdc_py'),
            None,
            None,
            self.get_request_url()
        ) 
def request(self):
        """ Makes request to Salesforce and returns serialised response. Catches any exceptions and appends them to
        `self.exceptions`.

          :return: response: Salesforce response, if available
          :rtype: list|dict|None
        """
        (headers, logger, request_object, response, service) = self.get_request_vars()
        logging.getLogger('sfdc_py').info('%s %s' %
                                          (self.http_method, service))

        if self.http_method == 'POST':
            request_fn = post_request
        elif self.http_method == 'PUT':
            request_fn = put_request
        elif self.http_method == 'PATCH':
            request_fn = patch_request
        elif self.http_method == 'DELETE':
            request_fn = delete_request
        else:
            request_fn = get_request

        try:
            request_object = request_fn(self)
            self.status = request_object.status_code

            if request_object.content.decode('utf-8') == 'null':
                raise SFDCRequestException('Request body is null')
            else:
                response = request_object.json()
        except Exception as e:
            self.exceptions.append(e)
            logger.error('%s %s %s' % (self.http_method, service, self.status))
            logger.error(e.message)
            return
        finally:
            return response 
def __init__(self):
        super(self.__class__, self).__init__(input=ConnectionSchema())
        self.session = Session()
        self.request = Request() 
def job_bulid_log(self,url,jobname):
        id=self.servir.get_job_info(jobname)['lastCompletedBuild']['number']
        url1=url+str(id)+"/console"
        log=self.servir.jenkins_request(requests.Request('GET',url1)).text
        return log 
def _normal_get(self, method, url, params=None, output=None):
        s = self._session
        if self.api_key is not None:
            params['key'] = self.api_key
        if method == 'POST':
            req = requests.Request(method=method, url=url, data=params)
        else:
            req = requests.Request(method=method, url=url, params=params)
        if output:
            req.headers['Accept'] = output
        prep = req.prepare()
        if self._verbose: print(self._safe_url(prep.url))
        try:
            resp = s.send(prep)
            self.__last_url = resp.url
        except requests.exceptions.ConnectionError as e:
            host_port = prep.url.split(prep.path_url)[0]
            raise ConnectionError(f'Could not connect to {host_port}. '
                                  'Are SciGraph services running?') from e
        if resp.status_code == 401:
            raise ConnectionError(f'{resp.reason}. '
                                  f'Did you set {self.__class__.__name__}.api_key'
                                  ' = my_api_key?')
        elif not resp.ok:
            return None
        elif resp.headers['content-type'] == 'application/json':
            return resp.json()
        elif resp.headers['content-type'].startswith('text/plain'):
            return resp.text
        else:
            return resp 
def _normal_get(self, method, url, params=None, output=None):
        s = self._session
        if self.api_key is not None:
            params['key'] = self.api_key
        if method == 'POST':
            req = requests.Request(method=method, url=url, data=params)
        else:
            req = requests.Request(method=method, url=url, params=params)
        if output:
            req.headers['Accept'] = output
        prep = req.prepare()
        if self._verbose: print(self._safe_url(prep.url))
        try:
            resp = s.send(prep)
            self.__last_url = resp.url
        except requests.exceptions.ConnectionError as e:
            host_port = prep.url.split(prep.path_url)[0]
            raise ConnectionError(f'Could not connect to {host_port}. '
                                  'Are SciGraph services running?') from e
        if resp.status_code == 401:
            raise ConnectionError(f'{resp.reason}. '
                                  f'Did you set {self.__class__.__name__}.api_key'
                                  ' = my_api_key?')
        elif not resp.ok:
            return None
        elif resp.headers['content-type'] == 'application/json':
            return resp.json()
        elif resp.headers['content-type'].startswith('text/plain'):
            return resp.text
        else:
            return resp 
def __call__(self, req: Request) -> Request:
        # Do nothing by default
        return req 
def __call__(self, req: Request) -> Request:
        # Add bearer authorization header.
        req.headers['Authorization'] = "Bearer {b}".format(b=self.bearer)
        return req 
def _make_request(server, endpoint, data):
    """
    Fires a POST with json-packed data to the given endpoint and returns
    response.

    Parameters:
        endpoint - An `str` object with the endpoint, e.g. "authenticate"
        data - A `dict` containing the payload data.

    Returns:
        A `requests.Request` object.
    """
    res = requests.post(server + "/" + endpoint, data=json.dumps(data),
                        headers=HEADERS)
    return res 
def _raise_from_response(res):
    """
    Raises an appropriate `YggdrasilError` based on the `status_code` and
    `json` of a `requests.Request` object.
    """
    if res.status_code == requests.codes['ok']:
        return None

    exception = YggdrasilError()
    exception.status_code = res.status_code

    try:
        json_resp = res.json()
        if not ("error" in json_resp and "errorMessage" in json_resp):
            raise ValueError
    except ValueError:
        message = "[{status_code}] Malformed error message: '{response_text}'"
        message = message.format(status_code=str(res.status_code),
                                 response_text=res.text)
        exception.args = (message,)
    else:
        message = "[{status_code}] {error}: '{error_message}'"
        message = message.format(status_code=str(res.status_code),
                                 error=json_resp["error"],
                                 error_message=json_resp["errorMessage"])
        exception.args = (message,)
        exception.yggdrasil_error = json_resp["error"]
        exception.yggdrasil_message = json_resp["errorMessage"]
        exception.yggdrasil_cause = json_resp.get("cause")

    raise exception 
def get_authorize_url(self, redirect_url, scopes):

        params = self.get_authorize_params(
            redirect_url=redirect_url,
            scopes=scopes,
        )

        req = requests.Request(url=self.authorize_url, params=params)
        return req.prepare().url 
def test_auth_with_request_on_the_same_host():
    auth = Auth("https://python-poetry.org", "foo", "bar")

    request = Request("GET", "https://python-poetry.org/docs/")
    assert "Authorization" not in request.headers

    request = auth(request)

    assert "Authorization" in request.headers
    assert request.headers["Authorization"] == "Basic {}".format(
        decode(base64.b64encode(encode(":".join(("foo", "bar")))))
    ) 
def test_auth_with_request_with_same_authentication():
    auth = Auth("https://python-poetry.org", "foo", "bar")

    request = Request("GET", "https://foo:[email protected]/docs/")
    assert "Authorization" not in request.headers

    request = auth(request)

    assert "Authorization" in request.headers
    assert request.headers["Authorization"] == "Basic {}".format(
        decode(base64.b64encode(encode(":".join(("foo", "bar")))))
    ) 
def test_auth_with_request_on_different_hosts():
    auth = Auth("https://python-poetry.org", "foo", "bar")

    request = Request("GET", "https://pendulum.eustace.io/docs/")
    assert "Authorization" not in request.headers

    request = auth(request)

    assert "Authorization" not in request.headers 
def __call__(self, r):  # type: (Request) -> Request
        if urlparse.urlparse(r.url).hostname != self._hostname:
            return r

        self._auth(r)

        return r 
def test_auth_token_arg(self):
        """Test: 'dcos-auth-token' arg."""
        token = "eyJhbGciOiJIUzI1NiIsImtpZCI6InNlY3JldCIsInR5cCI6IkpXVCJ9.eyJ \
        hdWQiOiIzeUY1VE9TemRsSTQ1UTF4c3B4emVvR0JlOWZOeG05bSIsImVtYWlsIjoiZHNz \
        dHN0YXBsZXRvbnJvYm90aWNzQGdtYWlsLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlL \
        CJleHAiOjEuNDgwODgyMzM5ZSswOSwiaWF0IjoxLjQ4MDQ1MDMzOWUrMDksImlzcyI6Im \
        h0dHBzOi8vZGNvcy5hdXRoMC5jb20vIiwic3ViIjoiZ29vZ2xlLW9hdXRoMnwxMDYyMDA \
        4NzM2MDg4NzgwNDU5MzEiLCJ1aWQiOiJkc3N0c3RhcGxldG9ucm9ib3RpY3NAZ21haWwu \
        Y29tIn0.iq2rKcCH5_rPEd5td-fM2rxlHjIyGAJOmxTd5lceHAU"

        sys.argv[0:] = self._args_app_name + self._args_mandatory + \
            ['--dcos-auth-token', token]
        args = ctlr.parse_args(version_data)
        self.assertEqual(args.dcos_auth_token, token)

        url = 'http://dcos.com/acs/api/v1/auth/login'
        req = requests.Request('POST', url)
        auth_request = req.prepare()
        auth_request.prepare_headers({'Authorization': ''})

        auth = DCOSAuth(args.dcos_auth_credentials, args.marathon_ca_cert,
                        args.dcos_auth_token)

        auth(auth_request)
        self.assertEqual(auth_request.headers['Authorization'],
                         'token=' + token)

        # test via env var
        env_token = 'It will now be a different value'
        sys.argv[0:] = self._args_app_name + self._args_mandatory
        os.environ['F5_CC_DCOS_AUTH_TOKEN'] = env_token
        args = ctlr.parse_args(version_data)
        self.assertEqual(args.dcos_auth_token, env_token) 
def upload(self, filename, configuration=None, metadata=None, transcript=None):
        """
        Upload new new media to the service as an attachment or from a url.
        HTTP POST on /media
        :param filename: Media file attached to the request.
        :param configuration: VoicebaseMediaConfiguration
        :param metadata: VoicebaseMediaMeta
        :param transcript: attached transcript
        :return: VoicebaseMedia
        """
        data = {}
        if metadata:
            data['metadata'] = str(metadata)
        if configuration:
            data['configuration'] = str(configuration)

        # Determine mime type
        m = magic.Magic(mime=True)
        mime_type = m.from_file(filename)

        # Open file and pipe to request
        with open(filename) as handle:
            file_info = [('media', (filename, handle, mime_type))]
            rq = requests.Request(b'POST', self.full_url('base'), data=data, headers=self.session.headers,
                                  files=file_info)
            prepared_rq = rq.prepare()
            response = self.session.send(prepared_rq)
            response.raise_for_status()
        jsn = response.json()
        log.debug('Upload response: {}'.format(jsn))
        return VoicebaseMedia(jsn, api=self.api) 
def _build_request(self, now):
        params = {'output_format': 'csv/splunk'}
        headers = {'X-RFToken': self.token}
        r = requests.Request(
            'GET',
            'https://api.recordedfuture.com/v2/ip/risklist',
            headers=headers, params=params,

        )

        return r.prepare() 
def _build_request(self, now):
        params = {'output_format': 'csv/splunk'}
        headers = {'X-RFToken': self.token}
        r = requests.Request(
            'GET',
            'https://api.recordedfuture.com/v2/domain/risklist',
            headers=headers, params=params,

        )

        return r.prepare() 
**************************************************


Python requests.RequestException() Examples

def post(self, data):
        logger.info('%s: pushing "%s"',  self.__class__.__name__, data)
        url = '{}create_many/'.format(self.url) if self.use_batch else self.url
        try:
            response = self.session.post(url, json=data)
        except requests.RequestException:
            logger.exception(
                '%s: error during POST', self.__class__.__name__)
            return

        if 200 <= response.status_code < 300:
            pass  # Success.
        elif response.status_code == 400:
            # One or more data points were invalid.
            self.handle_error_response(data, response.json())
        else:
            try:
                response.raise_for_status()
            except requests.RequestException:
                logger.exception(
                    '%s: error during POST', self.__class__.__name__) 
def test_GET_root():
    '''The server should accept a GET and return the form.'''
    print("Testing GET request.")
    uri = "http://localhost:8000/"
    try:
        r = requests.get(uri)
    except requests.RequestException as e:
        return ("Couldn't communicate with the server. ({})\n"
                "If it's running, take a look at its output.").format(e)
    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a GET request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 200:
        return ("The server returned status code {} instead of a 200 OK."
                ).format(r.status_code)
    elif not r.headers['content-type'].startswith('text/html'):
        return ("The server didn't return Content-type: text/html.")
    elif '<title>Bookmark Server</title>' not in r.text:
        return ("The server didn't return the form text I expected.")
    else:
        print("GET request succeeded!")
        return None 
def _push_to_registry(self, namespace, repository, release, bundle, auth_token):
        push_uri = 'https://quay.io/cnr/api/v1/packages/%s/%s' % (namespace, repository)
        logger.info('Pushing bundle to %s' % push_uri)
        headers = {'Content-Type': 'application/json', 'Authorization': auth_token}
        json = {'blob': bundle, 'release': release, "media_type": "helm"}

        try:
            r = requests.post(push_uri, json=json, headers=headers)
        except requests.RequestException as e:
            msg = str(e)
            logger.error(msg)
            raise OpCourierQuayCommunicationError(msg)

        if r.status_code != 200:
            logger.error(r.text)

            try:
                r_json = r.json()
            except ValueError:
                r_json = {}

            msg = r_json.get('error', {}).get(
                'message', 'Failed to get error details.'
            )
            raise OpCourierQuayErrorResponse(msg, r.status_code, r_json) 
def check_container_ready(self):
        """ Function that continuously checks if a container is ready.

        Note:
            This function should be wrapped in a `tenacity.retry` for
            continuously checking the status without failing.

        Raises:
            requests.RequestException: for any `requests` related exception.

        Returns:
            bool:
                ``True`` when the status is good. ``False`` if it cannot
                be verified or is in an unusable state.
        """
        self.logger.debug('checking selenium status')
        resp = requests.get(self._base_url, timeout=(1.0, 1.0))
        # retry on every exception
        resp.raise_for_status()
        return resp.status_code == requests.codes.ok 
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
def main():
    log.info('Cap breaker agent initializing...')
    working_folder = os.getenv('APPDATA') + '\\.capbreaker' if os.name == 'nt' else os.path.expanduser(
        '~') + '/.capbreaker'
    log.info('Server: ' + Config.server)
    log.info('Local working folder is set to: ' + working_folder)
    log.info('Scanning mode: ' + str(Config.hashcat_mode))
    hashcat = Hashcat(working_folder, Config.hashcat_url, Config.hashcat_mode)
    log.info('Done.\n')

    while True:
        log.info('Looking for a new task.')
        try:
            response = requests.post(Config.server + '/agent/getTask', auth=(Config.username, Config.password))
        except requests.RequestException:
            log.fatal('Unable connect to server. Please try again later. Exiting...')
            sleep(2)
            break
        if response.status_code == 200:
            log.info('Task found, starting scan...')
            hashcat.scan(response.json())
            sleep(3)
        elif response.status_code == 204:
            log.warning('Task not found, will try again in 60 seconds.')
            sleep(60)
        else:
            log.fatal('Unexpected error occurred. Exiting...')
            sleep(2)
            break 
def validate_href(image_href):
        """Validate HTTP image reference.

        :param image_href: Image reference.
        :raises: exception.ImageRefValidationFailed if HEAD request failed or
            returned response code not equal to 200.
        :returns: Response to HEAD request.
        """
        try:
            response = requests.head(image_href)
            if response.status_code != http_client.OK:
                raise exception.ImageRefValidationFailed(
                    image_href=image_href,
                    reason=("Got HTTP code %s instead of 200 in response to "
                            "HEAD request." % response.status_code))
        except requests.RequestException as e:
            raise exception.ImageRefValidationFailed(image_href=image_href,
                                                     reason=e)
        return response 
def request(self, endpoint, method="GET", file=None, params=None):
        url = self.api_url + endpoint
        params.update({"apikey": self.apikey})

        try:
            with requests.Session() as s:
                if method == "GET":
                    response = s.get(url, params=params)
                else:
                    response = s.post(url, files=file, data=params)
        except requests.RequestException as e:
            raise e

        content = ""
        if len(response.content) > 0:
            content = json.loads(response.content.decode("utf-8"))

        return content 
def request(self, endpoint, method="GET", file=None, params=None):
        url = self.api_url + endpoint
        params.update({"apikey": self.apikey})

        try:
            with requests.Session() as s:
                if method == "GET":
                    response = s.get(url, params=params)
                else:
                    response = s.post(url, files=file, data=params)
        except requests.RequestException as e:
            raise e

        content = ""
        if len(response.content) > 0:
            content = json.loads(response.content.decode("utf-8"))

        return content 
def send_msg(self, _type, url, message, **kwargs):
        response = None
        try:
            if _type == 'post':
                response = requests.post(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'put':
                response = requests.put(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'get':
                response = requests.get(url, headers=WebClient.headers, data=message, **kwargs)
            else:
                response = requests.delete(url, headers=WebClient.headers, data=message, **kwargs)
        except requests.RequestException as exception:
            logger.info('Requests fail - exception %s', exception)
            response = None
        finally:
            reply = self.__process_msg_response(response)
            logger.info('Requests - response %s', response)
            if reply:
                return reply.text
            return reply 
def obtain_access_token(self):
        """Returns an OAuth 2 access token to make OAuth 2 authenticated
        read-only calls.

        :rtype: string
        """
        if self.oauth_version != 2:
            raise TwythonError('This method can only be called when your \
                               OAuth version is 2.0.')

        data = {'grant_type': 'client_credentials'}
        basic_auth = HTTPBasicAuth(self.app_key, self.app_secret)
        try:
            response = self.client.post(self.request_token_url,
                                        data=data, auth=basic_auth)
            content = response.content.decode('utf-8')
            try:
                content = content.json()
            except AttributeError:
                content = json.loads(content)
                access_token = content['access_token']
        except (KeyError, ValueError, requests.exceptions.RequestException):
            raise TwythonAuthError('Unable to obtain OAuth 2 access token.')
        else:
            return access_token 
def bot(message: str, user_config: dict):
    if config['enable_bot'] and user_config['bot_notice']:
        try:
            group_id = user_config['group_id']
        except KeyError:
            group_id = config['group_id']
        # 传入JSON时，应使用这个UA
        headers = {'Content-Type': 'application/json',
                   'Authorization': f'Bearer {config["bot_token"]}'}
        for _group_id in group_id:
            _msg = {
                'group_id': int(_group_id),
                'message': message,
                'auto_escape': False
            }
            msg = json.dumps(_msg)
            logger = logging.getLogger('run.bot')
            try:
                requests.post(f'http://{config["bot_host"]}/send_group_msg', data=msg, headers=headers)
                logger.warning(f'{msg}')
            except requests.exceptions.RequestException as e:
                logger.exception(e) 
def request_html(url, method='GET', headers=None, proxies=None):
    """
    :param url:
    :param method:
    :param headers:
    :param proxies:
    :return:
    """
    resp = None
    try:
        r = requests.request(method, url, headers=headers, proxies=proxies)
        if r.status_code == 200:
            resp = r.text
    except requests.RequestException as e:
        print(e)

    return resp 
def __login(self):
        """Login using account-based or key-based methods."""
        if self.__session is None:
            self.__session = requests.session()

        login_url = "/".join([self.__url, "login"])
        try:
            response = self.__session.request(
                method="POST",
                url=login_url,
                data=self.__login_params,
                verify=self.__verify_ssl,
                timeout=self.__timeout,
                proxies=None,
            )
        except requests.RequestException as e:
            raise CommunicationError(e)

        self.__handle_response(response) 
def exec(self, mask, target, args):
        """Run a system command and upload the output to ix.io.

            %%exec <command>...
        """

        try:
            output = _exec_wrapper(args['<command>'])
            if not output:
                return f'{mask.nick}: Command returned no output.'

            # Don't paste single line outputs.
            if not is_multiline_string(output):
                return f'{mask.nick}: {output}'

            # Upload result of command to ix.io to avoid flooding channels with long output.
            result = requests.post('http://ix.io', data={'f:1': output})

        except (FileNotFoundError, requests.RequestException, subprocess.TimeoutExpired) as ex:
            return f'{mask.nick}: {ex}'

        return f'{mask.nick}: {result.text}' 
def request(self, host, handler, request_body, verbose):
        """
        Make an xmlrpc request.
        """
        headers = {'User-Agent': self.user_agent,
                   #Proxy-Connection': 'Keep-Alive',
                   #'Content-Range': 'bytes oxy1.0/-1',
                   'Accept': 'text/xml',
                   'Content-Type': 'text/xml' }
        url = self._build_url(host, handler)
        try:
            resp = requests.post(url, data=request_body, headers=headers)
        except ValueError:
            raise
        except Exception:
            raise # something went wrong
        else:
            try:
                resp.raise_for_status()
            except requests.RequestException as e:
                raise xmlrpc.ProtocolError(url, resp.status_code,
                                                        str(e), resp.headers)
            else:
                return self.parse_response(resp) 
def get_password(self, hash_start: str) -> list:
        """
        :param hash_start: The first 5 characters of a SHA1 hash
        :return: A list of hashes that match the hash_start param
        """
        BASE_URl = 'https://api.pwnedpasswords.com/range/'

        url = BASE_URl + hash_start
        try:
            response = requests.get(url)
        except requests.RequestException as e:
            self.logger.error(e)
            raise
        hash_list = response.text.splitlines()
        hash_list = [hash_start + hash_ for hash_ in hash_list]
        hash_list = [hash_[:40] for hash_ in hash_list]
        return hash_list 
def _get_data(self):
        try:
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        res.raise_for_status()
        root = ET.fromstring(res.text)
        citybikewien_data = []

        # extract only wanted stations and parse to citybikewien dict
        conf = get_config()
        stations = conf['api']['citybikewien']['stations']
        for station_xml in root.findall('station'):
            if station_xml.find('id').text in list(map(lambda s: str(s['id']), stations)):
                citybikewien_data.append({
                    'id': station_xml.find('id').text,
                    'name': station_xml.find('name').text,
                    'bikes': station_xml.find('free_bikes').text,
                    'status': station_xml.find('status').text
                })

        # rename stations to names from config, so they can be mapped with other api data by name
        for conf_station in stations:
            if 'rename' in conf_station:
                for station in citybikewien_data:
                    if station['id'] == str(conf_station['id']):
                        station['name'] = conf_station['rename']
                        break

        logger.info("updated data: %s" % citybikewien_data)
        self.data = citybikewien_data 
def _new_session(self):
        self.header = {'Channel': 'inet'}
        try:
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        except RequestException or HTTPError:  # retry on error
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        res.raise_for_status()
        auth = res.json()
        logger.debug('autenticated: %s' % auth)
        self.header.update(
            {'AccessToken': auth['accessToken'], 'SessionId': auth['sessionId'], 'x-ts-supportid': auth['supportId']})
        self.session_end = time.time() + auth['sessionTimeout'] 
def _hook_release_created(**kwargs):
    if kwargs.get('created'):
        release = kwargs['instance']
        # append release lifecycle logs to the app
        release.app.log(release.summary)

        for deploy_hook in settings.DEIS_DEPLOY_HOOK_URLS:
            url = deploy_hook
            params = {
                'app': release.app,
                'release': 'v{}'.format(release.version),
                'release_summary': release.summary,
                'sha': '',
                'user': release.owner,
            }
            if release.build is not None:
                params['sha'] = release.build.sha

            # order of the query arguments is important when computing the HMAC auth secret
            params = sorted(params.items())
            url += '?{}'.format(urllib.parse.urlencode(params))

            headers = {}
            if settings.DEIS_DEPLOY_HOOK_SECRET_KEY is not None:
                headers['Authorization'] = hmac.new(
                    settings.DEIS_DEPLOY_HOOK_SECRET_KEY.encode('utf-8'),
                    url.encode('utf-8'),
                    hashlib.sha1
                ).hexdigest()

            try:
                get_session().post(url, headers=headers)
                # just notify with the base URL, disregard the added URL query
                release.app.log('Deploy hook sent to {}'.format(deploy_hook))
            except requests.RequestException as e:
                release.app.log('An error occurred while sending the deploy hook to {}: {}'.format(
                    deploy_hook, e), logging.ERROR)


# Log significant app-related events 
def CheckURI(uri, timeout=5):
    '''Check whether this URI is reachable, i.e. does it return a 200 OK?

    This function returns True if a GET request to uri returns a 200 OK, and
    False if that GET request returns any other response, or doesn't return
    (i.e. times out).
    '''
    try:
        r = requests.get(uri, timeout=timeout)
        # If the GET request returns, was it a 200 OK?
        return r.status_code == 200
    except requests.RequestException:
        # If the GET request raised an exception, it's not OK.
        return False 
def test_request_exception_compatibility(op_courier_exception):
    """Test that exceptions replacing RequestException are backwards compatible"""
    assert (
        issubclass(op_courier_exception, RequestException)
        and not issubclass(op_courier_exception, ValueError)
    ) 
def request_transaction(self, transaction: Transaction) -> Transaction:
        data = {
            'payer_number': transaction.meta.get('payer_number'),
            'payer_name': transaction.meta.get('payer_name'),
            'amount': transaction.amount,
            'note': transaction.meta.get('note'),
            'silent': transaction.meta.get('silent')
        }
        for key in ('payer_name', 'payer_number', 'note'):
            if data[key] is None:
                raise ValueError('Transaction meta required (%s)' % key)
        url = '%s/bills' % self._server_url
        headers = {
            'access-token': self.config['access_token'],
            'content-type': 'application/json'
        }
        try:
            response = request(
                'post', url, json=[data], headers=headers
            )
        except RequestException:
            raise GatewayNetworkError('Cannot connect to bahamta server.')

        if response.status_code != 200:
            raise TransactionError(
                'Invalid transaction information (%s)' % response.status_code
            )
        response_data = response.json()[0]
        transaction.id = response_data['bill_id']
        transaction.meta = response_data
        return transaction 
def verify_transaction(self, transaction: Transaction, data):
        url = '%s/bills/%s' % (self._server_url, transaction.id)
        headers = {
            'access-token': self.config['access_token'],
            'content-type': 'application/json'
        }
        try:
            response = request('get', url, headers=headers)
        except RequestException:
            raise GatewayNetworkError('Cannot connect to bahamta server.')

        if response.status_code != 200:
            raise TransactionError(
                'Invalid transaction information (%s)' % response.status_code
            )
        response_data = response.json()

        if response_data['state'] != 'pay':
            raise TransactionError('Transaction not paid')

        if int(transaction.amount) != int(response_data['amount']):
            raise TransactionError('Amount mismatch')

        transaction.pan = response_data['pay_pan']
        transaction.meta = response_data
        return transaction 
def is_working_url(self, url):
        try:
            response = requests.head(url,
                                     timeout=self.url_check_timeout,
                                     verify=self.verify_ssl)
            matches = []
            if response.status_code not in EXCEPTION_STATUS_CODES:
                matches = \
                    [re.match(pattern, str(response.status_code)) is not None
                     for pattern in INVALID_STATUS_CODES_REGEX]
            return True not in matches, response.status_code
        except Timeout:
            return False, 408
        except (RequestException, Exception):
            return False, None 
def _get_repo(self, org, repo):
        """Either return the repo dictionary, or None if it doesn't exists.

        Args:
            org (str): Organization the repo lives in.
            repo (str): The name of the repo.
        Raises:
            requests.exceptions.RequestException
            GitHubUnknownError
        Returns:
            dict or None: Repo dictionary from github
                (https://developer.github.com/v3/repos/#get) or None if it
                doesn't exist.
        """
        repo_url = '{url}repos/{org}/{repo}'.format(
            url=self.api_url,
            org=org,
            repo=repo
        )

        # Try and get the URL, if it 404's we are good, otherwise raise
        repo_response = self.session.get(repo_url)
        if repo_response.status_code == 200:
            return repo_response.json()
        if repo_response.status_code != 404:
            raise GitHubUnknownError(repo_response.text) 
def create_repo(self, org, repo, description):
        """Creates a new github repository or raises exceptions

        Args:
            org (str): Organization to create the repo in.
            repo (str): Name of the repo to create.
            description (str): Description of repo to use.
        Raises:
            GitHubRepoExists
            GitHubUnknownError
            requests.exceptions.RequestException
        Returns:
            dict: Github dictionary of a repo
                (https://developer.github.com/v3/repos/#create)

        """
        repo_dict = self._get_repo(org, repo)
        if repo_dict is not None:
            raise GitHubRepoExists('This repository already exists')

        # Everything looks clean, create the repo.
        create_url = '{url}orgs/{org}/repos'.format(
            url=self.api_url,
            org=org
        )
        payload = {
            'name': repo,
            'description': description,
            'private': True,
        }
        repo_create_response = self.session.post(create_url, json=payload)
        if repo_create_response.status_code != 201:
            raise GitHubUnknownError(repo_create_response.text)
        return repo_create_response.json() 
def _create_team(self, org, team_name, read_only):
        """Internal function to create a team.

        Args:
            org (str): Organization to create the repo in.
            team_name (str): Name of team to create.
            read_only (bool): If false, read/write, if true read_only.

        Raises:
            GitHubUnknownError
            requests.RequestException
        Returns:
            dict: Team dictionary
                  (https://developer.github.com/v3/orgs/teams/#response)
        """
        if read_only:
            permission = 'pull'
        else:
            permission = 'push'

        create_url = '{url}orgs/{org}/teams'.format(
            url=self.api_url,
            org=org
        )
        response = self.session.post(create_url, json={
            'name': team_name,
            'permission': permission
        })
        if response.status_code != 201:
            raise GitHubUnknownError(response.text)
        return response.json() 
def add_team_repo(self, org, repo, team):
        """Add a repo to an existing team (by name) in the specified org.

        We first look up the team to get its ID
        (https://developer.github.com/v3/orgs/teams/#list-teams), and
        then add the repo to that team
        (https://developer.github.com/v3/orgs/teams/#add-team-repo).

        Args:
            org (str): Organization to create the repo in.
            repo (str): Name of the repo to create.
            team (str): Name of team to add.
        Raises:
            GitHubNoTeamFound
            GitHubUnknownError
            requests.exceptions.RequestException

        """
        found_team = self._find_team(org, team)
        team_repo_url = '{url}teams/{id}/repos/{org}/{repo}'.format(
            url=self.api_url,
            id=found_team['id'],
            org=org,
            repo=repo
        )
        response = self.session.put(team_repo_url)
        if response.status_code != 204:
            raise GitHubUnknownError(response.text) 
def add_web_hook(self, org, repo, url):
        """Adds an active hook to a github repository.

        This utilizes
        https://developer.github.com/v3/repos/hooks/#create-a-hook to
        create a form type Web hook that responds to push events
        (basically all the defaults).

        Args:
            org (str): Organization to create the repo in.
            repo (str): Name of the repo the hook will live in.
            url (str): URL of the hook to add.
        Raises:
            GitHubUnknownError
            requests.exceptions.RequestException
        Returns:
            dict: Github dictionary of a hook
                (https://developer.github.com/v3/repos/hooks/#response-2)

        """
        hook_url = '{url}repos/{org}/{repo}/hooks'.format(
            url=self.api_url,
            org=org,
            repo=repo
        )
        payload = {
            'name': 'web',
            'active': True,
            'config': {
                'url': url,
            }
        }
        response = self.session.post(hook_url, json=payload)
        if response.status_code != 201:
            raise GitHubUnknownError(response.text)
        return response.json() 
def _send_stuf_message(stuf_msg: str, soap_action: str):
    """
    Send a STUF message to the server that is configured.
    """
    if not settings.SIGMAX_AUTH_TOKEN or not settings.SIGMAX_SERVER:
        raise SigmaxException('SIGMAX_AUTH_TOKEN or SIGMAX_SERVER not configured.')

    # Prepare our request to Sigmax
    encoded = stuf_msg.encode('utf-8')

    headers = {
        'SOAPAction': soap_action,
        'Content-Type': 'text/xml; charset=UTF-8',
        'Authorization': 'Basic ' + settings.SIGMAX_AUTH_TOKEN,
        'Content-Length': b'%d' % len(encoded)
    }

    # Send our message to Sigmax. Network problems, and HTTP status codes
    # are all raised as errors.
    try:
        response = requests.post(
            url=settings.SIGMAX_SERVER,
            headers=headers,
            data=encoded,
            verify=False
        )
        response.raise_for_status()
    except requests.RequestException as e:
        raise SigmaxException from e

    # Inspect response content with lxml, check for Fo03/Bv03. Raise if we
    # receive anything other than XML or a message `berichtcode` other than
    # StUF Bv03.
    if not _stuf_response_ok(response):
        raise SigmaxException('Geen Bv03 ontvangen van Sigmax/CityControl')

    return response 
def __next__(self):
        while not self._event_complete() and not self.requestClose:
            try:
                nextchar = next(self.resp.iter_content(decode_unicode=True))
                self.buf += nextchar
            except (StopIteration, requests.RequestException):
                time.sleep(self.retry / 1000.0)
                self._connect()

                # The SSE spec only supports resuming from a whole message, so
                # if we have half a message we should throw it out.
                head, sep, tail = self.buf.rpartition('\n')
                self.buf = head + sep
                continue

        split = re.split(end_of_field, self.buf)
        head = split[0]
        tail = "".join(split[1:])

        self.buf = tail
        msg = Event.parse(head)

        # If the server requests a specific retry delay, we need to honor it.
        if msg.retry:
            self.retry = msg.retry

        # last_id should only be set if included in the message.  It's not
        # forgotten if a message omits it.
        if msg.id:
            self.last_id = msg.id

        return msg 
def download_illust(artwork: Artwork, folder: str = '') -> Iterator[Tuple[Artwork.DownloadStatus, str]]:
        artwork_detail = texts.DOWNLOAD_INITIALIZE_FAILED
        folder = str(folder)
        if folder and not os.path.isdir(folder):
            os.mkdir(folder)
        try:
            for status, url_and_headers, filename in artwork:
                url, headers = url_and_headers
                page_num_search = re.search(r'\d{8}_p(\d*)', url)
                page_num = page_num_search.group(1) if page_num_search else -1
                filename = os.path.join(util.clean_filename(str(folder)), util.clean_filename(str(filename)))
                artwork_detail = f'[{str(artwork.title)}] p{page_num} {texts.get("BY")} [{str(artwork.author)}]'
                if status is Artwork.DownloadStatus.OK:

                    if os.path.isfile(filename):
                        yield Artwork.DownloadStatus.SKIPPED, artwork_detail
                        continue

                    with requests.get(url=url, headers=headers) as r:
                        r.raise_for_status()
                        with open(filename, 'wb') as file:
                            for chunk in r.iter_content(chunk_size=1024):
                                file.write(chunk)
                    yield Artwork.DownloadStatus.OK, artwork_detail

                else:
                    yield Artwork.DownloadStatus.FAILED, artwork_detail

        except requests.RequestException as e:
            yield Artwork.DownloadStatus.FAILED, artwork_detail + f': {e}' 
def download_illust(artwork: Artwork, folder: str = '') -> Iterator[Tuple[Artwork.DownloadStatus, str]]:
        artwork_detail = 'None'
        folder = str(folder)
        if folder and not os.path.isdir(folder):
            os.mkdir(folder)
        try:
            for status, url_and_headers, filename in artwork:
                url, headers = url_and_headers
                page_num_search = re.search(r'\d{8}_p(\d*)', url)
                page_num = page_num_search.group(1) if page_num_search else -1
                filename = os.path.join(util.clean_filename(str(folder)), util.clean_filename(str(filename)))
                artwork_detail = f'[{str(artwork.title)}] p{page_num} by [{str(artwork.author)}]'
                if status is Artwork.DownloadStatus.OK:

                    if os.path.isfile(filename):
                        yield Artwork.DownloadStatus.SKIPPED, artwork_detail
                        continue

                    with requests.get(url=url, headers=headers) as r:
                        r.raise_for_status()
                        with open(filename, 'wb') as file:
                            for chunk in r.iter_content(chunk_size=1024):
                                file.write(chunk)
                    yield Artwork.DownloadStatus.OK, artwork_detail

        except requests.RequestException as e:
            yield Artwork.DownloadStatus.FAILED, artwork_detail + f': {e}' 
def _hack_ip():
    system = _system()
    if system not in SUPPORTED_SYSTEMS:
        return False, 'Unknown operation system {0}'.format(system)

    local_ip = public_ip = DEFAULT_IP_ADDRESS
    if system == 'Darwin':
        command = ['ifconfig']
        pattern = re.compile(r'inet (?P<ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    elif system == 'Linux':
        command = ['ip', 'addr']
        pattern = re.compile(r'inet (?P<ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    else:
        command = ['ipconfig']
        pattern = re.compile(r'IPv4.+: (?P<ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    rs = _exec(command)
    for match in re.finditer(pattern, rs):
        sip = match.group('ip')
        if sip != DEFAULT_IP_ADDRESS:
            local_ip = sip
            break
    try:
        r = requests.get(VERIFY_HOST)
        public_ip = r.json()['origin']
    except requests.RequestException:
        pass
    return True, '{0}\n{1}'.format(local_ip, public_ip) 
def test_exceptions(self):
        import requests

        exceptions = requests_.RequestsClient.exceptions

        with pytest.raises(exceptions.BaseClientException):
            raise requests.RequestException()

        with pytest.raises(exceptions.BaseClientException):
            # Test polymorphism
            raise requests.exceptions.InvalidURL()

        with pytest.raises(exceptions.ConnectionError):
            raise requests.exceptions.ConnectionError()

        with pytest.raises(exceptions.ConnectionTimeout):
            raise requests.exceptions.ConnectTimeout()

        with pytest.raises(exceptions.ServerTimeout):
            raise requests.exceptions.ReadTimeout()

        with pytest.raises(exceptions.SSLError):
            raise requests.exceptions.SSLError()

        with pytest.raises(exceptions.InvalidURL):
            raise requests.exceptions.InvalidURL() 
def request(self, endpoint, method='GET', params=None):
        """Returns dict of response from OANDA's open API
        :param endpoint: (required) OANDA API endpoint (e.g. v1/instruments)
        :type endpoint: string
        :param method: (optional) Method of accessing data, either GET or POST. (default GET)
        :type method: string
        :param params: (optional) Dict of parameters (if any) accepted the by OANDA API endpoint you are trying to access (default None)
        :type params: dict or None
        """

        url = '%s/%s' % ( self.api_url, endpoint)

        method = method.lower()
        params = params or {}

        func = getattr(self.client, method)

        request_args = {}
        if method == 'get':
            request_args['params'] = params
        else:
            request_args['data'] = params

        try:
            response = func(url, **request_args)
        except requests.RequestException as e:
            print (str(e))
        content = response.content.decode('utf-8')

        content = json.loads(content)

        # error message
        if response.status_code >= 400:
            raise OandaError(content)

        return content 
def _fetch_access_token(self, url, params):
        """ The real fetch access token """
        res = requests.get(
            url=url,
            params=params
        )
        try:
            res.raise_for_status()
        except requests.RequestException as reqe:
            raise WeChatClientException(
                errcode=None,
                errmsg=None,
                client=self,
                request=reqe.request,
                response=reqe.response
            )
        result = res.json()
        if 'errcode' in result and result['errcode'] != 0:
            raise WeChatClientException(
                result['errcode'],
                result['errmsg'],
                client=self,
                request=res.request,
                response=res
            )

        expires_in = 7200
        if 'expires_in' in result:
            expires_in = result['expires_in']
        self.session.set(
            self.access_token_key,
            result['access_token'],
            expires_in
        )
        self.expires_at = int(time.time()) + expires_in
        return result 
def _request(self, method, url_or_endpoint, **kwargs):
        if not url_or_endpoint.startswith(('http://', 'https://')):
            api_base_url = kwargs.pop('api_base_url', self.API_BASE_URL)
            url = '{base}{endpoint}'.format(
                base=api_base_url,
                endpoint=url_or_endpoint
            )
        else:
            url = url_or_endpoint

        if 'params' not in kwargs:
            kwargs['params'] = {}
        if isinstance(kwargs['params'], dict) and \
                'component_access_token' not in kwargs['params']:
            kwargs['params'][
                'component_access_token'] = self.access_token
        if isinstance(kwargs['data'], dict):
            kwargs['data'] = json.dumps(kwargs['data'])

        res = requests.request(
            method=method,
            url=url,
            **kwargs
        )
        try:
            res.raise_for_status()
        except requests.RequestException as reqe:
            raise WeChatClientException(
                errcode=None,
                errmsg=None,
                client=self,
                request=reqe.request,
                response=reqe.response
            )

        return self._handle_result(res, method, url, **kwargs) 
def do_request(self, req, timeout):
        try:
            return Response(self.session.request(req.method, req.url,
                                                 data=req.data,
                                                 params=req.params,
                                                 headers=req.headers,
                                                 stream=True,
                                                 timeout=timeout))
        except requests.RequestException as e:
            raise RequestError(e) 
def _check(self, ip, port, save_to_queue=False):
        """
        检测给定的代理IP和端口是否存活
        :param ip: 代理IP
        :param port: 代理端口
        :param save_to_queue: 如果设置为True，则存储到结果队列中，否则不存储，默认为False
        :return: success, delay 如果目标代理存活，则success为True且delay为延迟，否则为False，delay为0
        """
        # 检查参数合法性
        if ip == "" or port == "":
            logger.error("Invalid ip or port found. Skipping...")
            return False, -1.0

        # 3次重试机会
        retry = 3
        time_summary = 0.0
        success = False
        while retry:
            logger.debug("Times: {0}. Trying {1}:{2} connection...".format(3-retry+1, ip, port))
            proxies = {
                'http': ip + ":" + port
            }

            try:
                time_start = time.time()
                requests.get("http://ip.cn/", headers=self.headers, proxies=proxies, timeout=10)
                time_summary = time.time() - time_start
                success = True
                break
            except requests.RequestException:
                logger.warning("{0}:{1} proxy time out.".format(ip, port))
                continue
            finally:
                retry -= 1
        if save_to_queue:
            self.result_queue.put((ip, port, success, time_summary))
        return success, time_summary 
def download_as_file(self, file_path, overwrite=False, compress=True):
        if os.path.isfile(file_path) and not overwrite:
            return

        cols = self.get_colnames_from_query(self.query)

        # taken from https://github.com/noaodatalab/datalab/blob/master/dl/queryClient.py#L1791
        r = requests.get(
            "https://datalab.noao.edu/query/query",
            {"sql": self.query, "ofmt": "ascii", "async": False},
            headers={
                "Content-Type": "application/octet-stream",
                "X-DL-AuthToken": "anonymous.0.0.anon_access",
            },
            timeout=(120, 3600),
        )
        if not r.ok:
            raise requests.RequestException('DES query failed: "{}"'.format(r.text))

        t = Table.read(r.text, format="ascii.fast_tab", names=cols)
        r.close()

        file_open = gzip.open if compress else open
        makedirs_if_needed(file_path)
        with file_open(file_path, "wb") as f:
            t.write(f, format="fits") 
def download_as_file(self, file_path, overwrite=False, compress=True):
        if not compress:
            raise ValueError("Only support compress=True!")
        if os.path.isfile(file_path) and not overwrite:
            return
        r = requests.get(
            "http://www.slac.stanford.edu/~yymao/saga/base-catalogs-non-sdss/{}_decals_{}.fits.gz".format(
                self.host_id, self.data_release
            ),
            headers={"Content-Type": "application/gzip"},
            stream=True,
            timeout=(120, 3600),
        )

        if not r.ok:
            raise requests.RequestException(
                "Decals-prebuilt download failed: '{}'".format(r.text)
            )

        makedirs_if_needed(file_path)
        chunk_size = 16 * 1024 * 1024
        with open(file_path, "wb") as f:
            # here we don't use iter_content because we want to keep gzipped
            while True:
                chunk = r.raw.read(chunk_size)
                if not chunk:
                    break
                f.write(chunk)
        r.close() 
def healthy(self):
        tc = TransplantClient(
            self.flask_app.config.get("TRANSPLANT_URL"),
            self.flask_app.config.get("TRANSPLANT_USERNAME"),
            self.flask_app.config.get("TRANSPLANT_PASSWORD"),
        )
        try:
            resp = tc.ping()
        except requests.RequestException as exc:
            return "RequestException: {!s}".format(exc)

        if resp.status_code != 200:
            return "Unexpected Status Code: {}".format(resp.status_code)

        return True 
def request(self, method, url_path, **kwargs):
        """Return the response of a request to Tree Status API.

        Args:
            method: HTTP method to use for request.
            url_path: Path to be appended to api url for request.

        Returns:
            JSON decoded response from TreeStatus

        Raises:
            TreeStatusException:
                Base exception class for other exceptions.
            TreeStatusError:
                If the API returns an error response.
            TreeStatusCommunicationException:
                If there is an error communicating with the API.
        """

        try:
            response = self.session.request(method, self.url + url_path, **kwargs)
            data = response.json()
        except requests.RequestException as exc:
            raise TreeStatusCommunicationException(
                "An error occurred when communicating with Tree Status"
            ) from exc
        except JSONDecodeError as exc:
            raise TreeStatusCommunicationException(
                "Tree Status response could not be decoded as JSON"
            ) from exc

        TreeStatusError.raise_if_error(response, data)
        return data 
def ping(self):
        """Ping the Tree Status API

        Returns:
            True if ping was successful, False otherwise.
        """
        try:
            self.session.request("HEAD", self.url + "swagger.json")
            return True
        except requests.RequestException:
            return False 
**************************************************


Python requests.patch() Examples

def _send_raw_http_request(self, method, url, data=None):
        self.__logger.debug('%s %s' % (method, url))
        if method in ['POST', 'PUT', 'PATCH']:
            self.__logger.log(TINTRI_LOG_LEVEL_DATA, 'Data: %s' % data)

        headers = {'content-type': 'application/json'}
        if self.__session_id:
            headers['cookie'] = 'JSESSIONID=%s' % self.__session_id

        if method in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE']:
            if method == 'GET': httpresp = requests.get(url, headers=headers, verify=False)
            elif method == 'POST': httpresp = requests.post(url, data, headers=headers, verify=False)
            elif method == 'PUT': httpresp = requests.put(url, data, headers=headers, verify=False)
            elif method == 'PATCH': httpresp = requests.patch(url, data, headers=headers, verify=False)
            elif method == 'DELETE': httpresp = requests.delete(url, headers=headers, verify=False)
            self._httpresp = httpresp # self._httpresp is for debugging only, not thread-safe
            return httpresp
        else:
            raise TintriError(None, message='Invalid HTTP method: ' + method) # This should never happen 
def run(self):
        try:
            self.sse = ClosableSSEClient(self.url)
            for msg in self.sse:
                event = msg.event
                if event is not None and event in ('put', 'patch'):
                    response = json.loads(msg.data)
                    if response is not None:
                        # Default to CHILD_CHANGED event
                        occurred_event = FirebaseEvents.CHILD_CHANGED
                        if response['data'] is None:
                            occurred_event = FirebaseEvents.CHILD_DELETED

                        # Get the event I'm trying to listen to
                        ev = FirebaseEvents.id(self.event_name)
                        if occurred_event == ev or ev == FirebaseEvents.CHILD_CHANGED:
                            self.callback(event, response)
        except socket.error:
            pass 
def import_project(project, opts):
    u = opts.scheme + '://' + opts.host + _api + opts.project_id
    r = requests.patch(
            url=u,
            auth=HTTPBasicAuth(opts.username, opts.password),
            data=json.dumps(project),
            headers={'Content-Type': 'application/json'},
            verify=not (opts.insecure_skip_verify and opts.insecure_skip_verify))

    rjson = r.json()
    ret = dict(lair_response)
    ret['status'] = rjson['Status']
    ret['message'] = rjson['Message']

    return ret

# Function that performs project export. Returns a json string 
def _update_category(self, signal_id, new_category_slug):
        endpoint = '{url}/v1/private/signals/{signal_id}'.format(url=self.url, signal_id=signal_id)
        data = json.dumps({
            'category': {
                'sub_category': new_category_slug,
                'text': MESSAGE,
            }
        })

        r = requests.patch(endpoint, data=data, headers=self.headers)
        if r.status_code == 200:
            print('Updated category for Signal #{}'.format(signal_id))
            self.success += 1
        else:
            print('Failed to update the category for Signal #{}'.format(signal_id))
            self.errors.append(signal_id) 
def update_status(self, signal_id, new_state, message, acceptable_states=None):
        if acceptable_states is None:
            acceptable_states = []
        acceptable_states.append(new_state)  # if we are in desired state, skip

        # check status
        current_status = self._check_status(signal_id)
        if current_status['state'] in acceptable_states:
            print('Already in desired state.')
            return  # already in desired state

        # mutate signal status
        print('mutate')
        payload = copy.deepcopy(UPDATE_STATUS)
        payload['status']['state'] = new_state
        payload['status']['text'] = message

        response = requests.patch(
            DETAIL_ENDPOINT.format(base_url=self.base_url, signal_id=signal_id),
            json=payload,
            headers=self.headers,
        )
        response.raise_for_status()
        self._check_status(signal_id)
        print('') 
def update_status(self, signal_id, new_state, message, acceptable_states=None):
        if acceptable_states is None:
            acceptable_states = []
        acceptable_states.append(new_state)  # if we are in desired state, skip

        # check status
        current_status = self._check_status(signal_id)
        if current_status['state'] in acceptable_states:
            print('Already in desired state.')
            return  # already in desired state

        # mutate signal status
        print('mutate')
        payload = copy.deepcopy(UPDATE_STATUS)
        payload['status']['state'] = new_state
        payload['status']['text'] = message

        response = requests.patch(
            DETAIL_ENDPOINT.format(base_url=self.base_url, signal_id=signal_id),
            json=payload,
            headers=self.headers,
        )
        response.raise_for_status()
        self._check_status(signal_id) 
def update_category(self, signal_id, category_url, message):
        """
        Move given signal to category with descriptive message in logs.
        """
        category_data = self._check_category(signal_id)
        current_cat_url = urlparse(category_data['category_url']).path
        if current_cat_url == category_url:
            return

        payload = copy.deepcopy(UPDATE_CATEGORY)
        payload['category']['sub_category'] = category_url
        payload['category']['text'] = message
        print('mutate')
        response = requests.patch(
            DETAIL_ENDPOINT.format(base_url=self.base_url, signal_id=signal_id),
            json=payload,
            headers=self.headers,
        )
        response.raise_for_status()
        self._check_category(signal_id) 
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def patch(self, url, data):
        """PATCH method for amp."""
        try:
            response = requests.patch(
                "https://{}{}".format(self.endpoint, url),
                data=json.dumps(data),
                auth=(self.client_id, self.key),
                headers=self.headers
            )
            # Consider any status other than 2xx an error
            if not response.status_code // 100 == 2:
                return "Error: Unexpected response {}".format(response)
            try:
                return response.json()
            except:
                return "Error: Non JSON response {}".format(response.text)
        except requests.exceptions.RequestException as e:
            # A serious problem happened, like an SSLError or InvalidURL
            return "Error: {}".format(e) 
def patch(self, url, data):
        """PATCH method for amp."""
        try:
            response = requests.patch(
                "https://{}{}".format(self.endpoint, url),
                data=json.dumps(data),
                auth=(self.client_id, self.key),
                headers=self.headers
            )
            # Consider any status other than 2xx an error
            if not response.status_code // 100 == 2:
                return "Error: Unexpected response {}".format(response)
            try:
                return response.json()
            except:
                return "Error: Non JSON response {}".format(response.text)
        except requests.exceptions.RequestException as e:
            # A serious problem happened, like an SSLError or InvalidURL
            return "Error: {}".format(e) 
def patch(self, rest_query, data=None):
        """
        Sends a PATCH request to the Alyx server.
        For the dictionary contents, refer to:
        https://alyx.internationalbrainlab.org/docs

        :param rest_query: (required)the endpoint as full or relative URL
        :type rest_query: str
        :param data: json encoded string or dictionary
        :type data: None, dict or str

        :return: response object
        """
        if isinstance(data, dict):
            data = json.dumps(data)
        return self._generic_request(requests.patch, rest_query, data=data) 
def __init__(self, username, password, org, repo, base_url=None):
        self.username = username
        self.password = password
        self.org = org
        self.repo = repo

        base_url = base_url or "https://api.github.com"
        self.base_url = "{}/repos/{}/{}".format(base_url, org, repo)

        # Endpoints
        self.diff_media_type = "application/vnd.github.3.diff"
        self.patch_media_type = "application/vnd.github.3.patch"
        self.contents_url = "{}/contents".format(self.base_url)
        self.merge_url = "{}/merges".format(self.base_url)
        self.compare_url = "{}/compare".format(self.base_url)
        self.trees_url = "{}/git/trees".format(self.base_url)
        self.refs_url = "{}/git/refs".format(self.base_url)
        self.blobs_url = "{}/git/blobs".format(self.base_url)
        self.commits_url = "{}/git/commits".format(self.base_url)
        self.repo_commits_url = "{}/commits".format(self.base_url) 
def __update_property(self, base_url, sas_token, api_version, prop_name, prop_id, properties):
        prop_res = requests.patch(base_url + 'properties/' + prop_id + api_version,
                                  headers = {'Authorization': sas_token, 'If-Match': '*'},
                                  json = {
                                      'name': prop_name,
                                      'value': properties['value'],
                                      'tags': properties['tags'],
                                      'secret': properties['secret']    
                                  })
        if (200 != prop_res.status_code
            and 204 != prop_res.status_code):
            print "Update of property '" + prop_name + "' failed."
            print prop_res.text
            return False
        print "Successfully updated property '" + prop_name + "' (id " + prop_id + ")."
        return True 
def get_scm_sas_token(self, instance):
        rest_token = self.get_sas_token(instance)
        
        git_access = requests.get(self.get_base_url(instance) + 'tenant/access/git' + self.get_api_version(), 
            headers = {'Authorization': rest_token})
        
        if (requests.codes.ok != git_access.status_code):
            return git_access.text
        
        git_data = byteify(json.loads(git_access.text))
        
        if not git_data['enabled']:
            print "Enabling git repository..."
            enable_res = requests.patch(self.get_base_url(instance) + 'tenant/access/git' + self.get_api_version(),
                                        headers = {'Authorization': rest_token},
                                        json = {'enabled': True})
            if (204 != enable_res.status_code):
                print "Failed to enable git access!"
                return False
            return self.get_scm_sas_token(instance)

        return urllib.quote_plus(self.get_sas_token_internal(git_data['id'], git_data['primaryKey'])) 
def run(self, params={}):
        user_principal_name = params.get(Input.USER_PRINCIPAL_NAME)
        location = params.get(Input.LOCATION)
        token = self.connection.access_token

        base_url = "https://graph.microsoft.com/v1.0/users/%s" % user_principal_name
        headers = {"Authorization": "Bearer %s" % token, "Content-Type": "application/json",}
        
        body = {
            "usageLocation": location
        }
        
        try:
            response = requests.patch(base_url, json=body, headers=headers)
        except requests.HTTPError:
            raise PluginException(cause=f"There was an issue updating the user's location. Double-check the user name: {user_principal_name}",
                        data=response.text)
        if response.status_code == 204:
            return {Output.SUCCESS: True}
        else:
            raise PluginException(f"The response from Office365 indicated something went wrong: {response.status_code}",
                              data=response.text) 
def _upload_chunk(self, data, offset, file_endpoint, headers=None, auth=None):
        floyd_logger.debug("Uploading %s bytes chunk from offset: %s", len(data), offset)

        h = {
            'Content-Type': 'application/offset+octet-stream',
            'Upload-Offset': str(offset),
            'Tus-Resumable': self.TUS_VERSION,
        }

        if headers:
            h.update(headers)

        response = requests.patch(file_endpoint, headers=h, data=data, auth=auth)
        self.check_response_status(response)

        return int(response.headers["Upload-Offset"]) 
def _patch(self, url, data_dict, params):
        rdata = json.dumps(data_dict)

        response = requests.patch(url, data=rdata, params=params,
                                  headers=self._headers)
        data = json.loads(response.content.decode())

        if response.status_code == 200:
            return data

        self.last_error = {
            "status_code": response.status_code,
            "detail": response.content
        }
        print(self.last_error)
        return None 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def configLicenseServerDetails(self, licenseServer=None, licenseMode=None, licenseTier=None):
        """
        Description
           Configure license server details: license server IP, license mode and license tier.

        Parameter
            licenseServer: License server IP address(s) in a list.
            licenseMode: subscription|perpetual}mixed
            licenseTier: tier1, tier2, tier3 ...

        Syntax
           PATCH: https://{apiServerIp}/api/v1/sessions/{id}/ixnetwork/globals/licensing
        """
        # Each new session requires configuring the new session's license details.
        data = {}
        if licenseServer:
            data.update({'licensingServers': licenseServer})
        if licenseMode:
            data.update({'mode': licenseMode})
        if licenseTier:
            data.update({'tier': licenseTier})

        response = self.patch(self.sessionUrl+'/globals/licensing', data=data)
        self.showLicenseDetails() 
def configMultivalue(self, multivalueUrl, multivalueType, data):
        """
        Description
            Configure multivalues.

        Parameters
            multivalueUrl: The multivalue href. Ex: /api/v1/sessions/1/ixnetwork/multivalue/1
            multivalueType: counter|singleValue|valueList
            data = In Python Dict format. Ex:
                   If singleValue, data={'value': '1.1.1.1'})
                   If valueList,   data needs to be in a [list]:  data={'values': [list]}
                   If counter,     data={'start': value, 'direction': increment|decrement, 'step': value}
        """
        if multivalueType == 'counter':
            # Example: macAddress = {'start': '00:01:01:00:00:01', 'direction': 'increment', 'step': '00:00:00:00:00:01'}
            #          data=macAddress)
            self.patch(self.httpHeader+multivalueUrl+'/counter', data=data)

        if multivalueType == 'singleValue':
            # data={'value': value}
            self.patch(self.httpHeader+multivalueUrl+'/singleValue', data=data)

        if multivalueType == 'valueList':
            # data={'values': ['item1', 'item2']}
            self.patch(self.httpHeader+multivalueUrl+'/valueList', data=data) 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
def main(args):
    if not os.path.isfile(args.yaml_path):
        raise FileNotFoundError(f'{args.yaml_path} does not exist')

    command = 'delete' if args.delete else 'apply'
    print(f'{command} {args.yaml_path} to {args.endpoint}')
    with open(args.yaml_path) as f:
        data = json.dumps(yaml.load(f))

    path = '/orion/v2/entities/' + args.entity_id + '/attrs?type=' + args.entity_type
    url = urllib.parse.urljoin(args.endpoint, path)
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'bearer {args.token}',
        'Fiware-Service': args.fiware_service,
        'Fiware-Servicepath': args.fiware_servicepath,
    }

    payload = {
        command: {
            'value': urllib.parse.quote(data)
        }
    }
    response = requests.patch(url, json=payload, headers=headers)
    print(f'status_code={response.status_code}, body={response.text}\n') 
def update(self, request, *args, **kwargs):
        """Update a Source."""
        if request.method == 'PUT':
            raise SourcesMethodException('PUT not supported')

        source_id = kwargs.get('source_id')
        url = f'{self.url}{source_id}/'
        try:
            r = requests.patch(url, json=request.data, headers=self.request.headers)
        except requests.exceptions.ConnectionError as error:
            raise SourcesProxyException(str(error))
        response = HttpResponse(
            content=r.content,
            status=r.status_code,
            content_type=r.headers['Content-Type']
        )

        return response 
def set_source_status(self, error_msg, cost_management_type_id=None):
        """Set the source status with error message."""
        if not cost_management_type_id:
            cost_management_type_id = self.get_cost_management_application_type_id()

        application_query_url = '{}/applications?filter[application_type_id]={}&filter[source_id]={}'.\
            format(self._base_url, cost_management_type_id, str(self._source_id))
        application_query_response = requests.get(application_query_url, headers=self._identity_header)
        response_data = application_query_response.json().get('data')
        if response_data:
            application_id = response_data[0].get('id')

            application_url = f'{self._base_url}/applications/{str(application_id)}'
            if error_msg:
                status = 'unavailable'
            else:
                status = 'available'
                error_msg = ''
            json_data = {'availability_status': status, 'availability_status_error': str(error_msg)}
            application_response = requests.patch(application_url, json=json_data, headers=self._identity_header)
            if application_response.status_code != 204:
                raise SourcesHTTPClientError(f'Unable to set status for Source: {self._source_id}')
            return True
        return False 
def patch(self, method, uri, query_param, request_param, headers, **kwargs):
        """
        TODO: Implementation.

        :param method:
        :param uri:
        :param query_param:
        :param request_param:
        :param headers:
        :param kwargs:
        :return:
        """
        _url = self.base_url + uri + "?" + urlencode(query_param)
        if headers is not None:
            resp = requests.ptach(_url, data=request_param, headers=headers, **kwargs)
        else:
            resp = requests.patch(_url, data=request_param, **kwargs)

        if resp.status_code == 200:
            return resp

        raise BacklogError("Http response {status}: {message}".format(status=resp.status_code, message=resp.text)) 
def define_policy_as_default(policy_uuid,service_uuid):
    """Define a Runtime Policy as default.

    :param policy_uuid: uuid of a policy descriptor.

    :returns: A tuple. [0] is a bool with the result. [1] is a string containing
        the uuid of the terminated policy descriptor.
    """

    url = env.policy_api + '/default/' + policy_uuid

    data = {'nsid': service_uuid, 'defaultPolicy': True}
    resp = requests.patch(url,
                          json=data,
                          timeout=env.timeout)
  
    if resp.status_code != 200:
        LOG.debug("Request returned with " + (str(resp.status_code)))
        error = resp.text
        return False, error

    message = json.loads(resp.text)['message']

    return True, message 
def attach_policy(policy_uuid, service_uuid, sla_uuid):
    """Attaches a policy to a service and SLA.

    :param policy_uuid: uuid of a policy descriptor.
    :param service_uuid: uuid of a network service.
    :param sla_uuid: uuid of an SLA.

    :returns: A tuple. [0] is a bool with the result. [1] is a string indicating
        the result.
    """

    data = {'nsid': service_uuid, 'slaid': sla_uuid}
    resp = requests.patch(env.policy_bind_api + '/' + policy_uuid,
                          json=data,
                          timeout=env.timeout)
  
    if resp.status_code != 200:
        LOG.debug("Request returned with " + (str(resp.status_code)))
        error = resp.text
        return False, error

    message = json.loads(resp.text)['message']

    return True, message 
def genericPATCH(self, body):
        """
           PATCH to edit an existing configuration object with a JSON body.
           Need to formulate the URL with the name as part of the URL and NAME must not be in the body
        """
        URI = "%s%s%s" % (BIG_IP.TRANSPORT, self.BIG_IP_host, self.uri)
        try:
            if self.token is None:
                r = requests.patch(URI, auth=(self.username, self.password), data=body, headers=BIG_IP.HEADER, verify=False)
            else:
                r = requests.patch(URI, data=body, headers=BIG_IP.HEADER, verify=False)
        except requests.ConnectionError as e:
            self.status_code = 599
            self.response = str(e)
            return None
        self.status_code = r.status_code
        try:
            self.response = r.json()
        except ValueError:
            self.response = None

        if r.status_code == 200:
            self.changed = True
            return True
        return False 
def patch(self, *args, **kwargs):
        kwargs['method'] = 'patch'
        return self.do(*args, **kwargs) 
def update(self, payload):
        return requests.patch(self.current_url, json=payload) 
def rest_api_patch(self, rest_url, body, api_version):
        """
        PATCH request to the REST API - Not tested
        :return: JSON string of the PATCH response
        """
        response = requests.patch(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            data=body,
            headers=self.sf_headers
        )

        return response 
def _tag_release(new_version, current_version, milestone, release_name, token):
    global GIT_COMMANDS
    global RELEASE_NOTE_UPDATE_URL
    for command_name in ["create_new_tag", "push_tag"]:
        command = GIT_COMMANDS.get(command_name)
        command[0] = command[0].format(
            new_version=new_version, current_version=current_version
        )
        out, error, ret = _run_shell_command(command=command)
        if int(ret) != 0:
            print("Failed to execute the command: {}".format(command[0]))
            exit(1)

    change_log = _generate_markdown_document(
        milestone, release_name, current_version, new_version
    )

    body = {"name": release_name or new_version, "body": change_log}

    headers = {"content-type": "application/json"}

    response = patch(
        RELEASE_NOTE_UPDATE_URL.format(new_version=new_version, token=token),
        data=dumps(body),
        headers=headers,
    )
    response.raise_for_status() 
def _patch(self, request, data, headers=None):
        url = '{0}{1}'.format(self._url(), request)
        headers = self.headers if headers is None else headers
        response = requests.patch(url, data=json.dumps(data), headers=headers, verify=self.verify_cert,
                                  timeout=self.timeout)
        return self._validate(response) 
def precord(payload):
    # r = requests.patch(uri, data=json.dumps(payload), headers=headers)
    # For bypassing self-signed verification
    r = requests.patch(zone_uri, data=json.dumps(payload), headers=headers, verify=False)
    print(r.text) 
def exec_pdns_api(self, action, url, json_data=None, text=False):

        # remove double: //
        url = url.replace(r'//', '/')
        # remove extra ^/
        if url[0] == '/':
            url = url[1:]

        call_url = self.url_base + '/' + url

        headers = {'X-API-Key': self.key} 

        if action == 'GET':
            r = requests.get(call_url, headers=headers)
        elif action == 'POST':
            r = requests.post(call_url, data=json_data, headers=headers)
        elif action == 'PATCH':
            r = requests.patch(call_url, data=json_data, headers=headers)
        elif action == 'DELETE':
            r = requests.delete(call_url, headers=headers)
        else:
            raise ValueError('action unknown: %s' % action)

        if r.ok:
            if action == 'GET':
                if text:
                    return r.text
                else:
                    return r.json()
            else:
                return r
        else:
            raise ValueError('url returned an error: %s:\n%s\n---\n%s' % (call_url, r.headers, r.text)) 
def _send_request(method, url, params, data, **settings):
        if method == TestMethod.GET:
            return requests.get(url=url, params=params, **settings)
        elif method == TestMethod.PUT:
            return requests.put(url=url, data=data, **settings)
        elif method == TestMethod.POST:
            return requests.post(url=url, data=data, **settings)
        elif method == TestMethod.PATCH:
            return requests.patch(url=url, data=data, **settings)
        elif method == TestMethod.DELETE:
            return requests.delete(url=url, **settings)
        else:
            raise UnsupportedMethodError('Unsupported method: %s' % method) 
def update_deck(self, deck, user_id):
        """Update an existing deck.

        Args:
            deck (Deck): The Deck object to update.

        Returns:
            Deck: The updated Deck object if update was successful.

        """
        # Clone headers to not modify the global variable.
        headers = dict(DEFAULT_HEADERS)
        if deck.cover:
            # A new cover has been set on the deck, send the PATCH request as a
            # multipart-form:
            request_payload = json_converter.deck_to_json(deck)
            request_payload = to_multipart_form(request_payload)
            headers['Content-Type'] = request_payload.content_type
        else:
            # Otherwise, send the PATCH request as JSON:
            request_payload = json_converter.deck_to_json(deck,
                                                          as_json_str=True)
            request_payload = json.dumps(request_payload)
            headers['Content-Type'] = 'application/json'

        r = requests.patch(url=API_URL + 'decks/' + deck.id,
                           data=request_payload, headers=headers,
                           cookies={'jwt_token': self.jwt})

        if not r.ok:
            raise Exception('Failure while sending updates to server: %s'
                            % r.text)

        # The response from the PATCH request does not contain cards.
        # Therefore, we have to query the updated deck with an extra request.
        updated_deck = self.get_deck(deck.id, user_id)

        return updated_deck 
def _execute_call(self, url, method='get', data=None):
        try:
            self.logger.info('Calling {}'.format(url))
            requests.packages.urllib3.disable_warnings()
            url_base = 'https://{0}:{1}/restconf/data/'.format(self.host, self.port)
            headers = {
            'Accept': 'application/yang-data+json',
            'content-type': 'application/yang-data+json'
            }
            if method == 'get':
                response = requests.get(url_base+url, auth=(self.username, self.password), headers=headers, verify=False)
            elif method == 'patch':
                response = requests.patch(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))
            elif method == 'delete':
                response = requests.delete(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))

            result = Result(response=response)
            result.status_code = response.status_code

            if response.status_code in HTTP_ERROR_CODES:
                result.ok = False
                result.error = HTTP_ERROR_CODES[response.status_code]

            elif response.status_code in HTTP_SERVER_ERRORS:
                result.ok = False
                result.error = HTTP_SERVER_ERRORS[response.status_code]

            elif response.status_code in HTTP_SUCCESS_CODES:
                result.ok = True
                result.message = HTTP_SUCCESS_CODES[response.status_code]

            if not response.status_code == 204:
                result.json = response.json()

            return result

                #response = requests.get(url, auth=(USER, PASS), headers=headers, verify=False)
        except Exception as e:
            self.logger.error(e) 
def add_access_group(self, interface):
        """Function to create a IP accessgroup on IOS XE"""
        parsed_interface =re.search(r"(?P<intrfname>[A-Za-z]+)(?P<intf_num>\d((/\d+)+(\.\d+)?)|\d)",interface).groupdict()
        interface_name = parsed_interface.get('intrfname')
        interface_number = parsed_interface.get('intf_num')
        api_interface = '{0}={1}'.format(interface_name, interface_number)
        url = 'https://{0}:{1}/data/Cisco-IOS-XE-native:native/interface/{2}'.format(self.host, self.port, api_interface)
        headers = {
        'Accept': 'application/yang-data+json',
        'content-type': 'application/yang-data+json'
        }

        data = {
        "Cisco-IOS-XE-native:GigabitEthernet":[
              {
                 "name":interface_number,
                 "ip":{
                    "access-group":{
                       "in":{
                          "acl":{
                             "acl-name":"DROP",
                             "in":[None]
                          }
                       }
                    }
                 }
              }
           ]
        }

        response = self._execute_call('Cisco-IOS-XE-native:native/interface/{0}'.format(api_interface), method='patch', data=data)
        return response 
def _patch(self, url, json=None, **kwargs):
        return self._request_submit(requests.patch, url=url, json=json, **kwargs) 
def patch(self, path):
        """
        Makes a RESTful PATCH request to the back end.
        :param path: URL of the request (without root URL e.g. "/data")
        :return: response: Response
        """
        auth_header = self.get_header()
        auth = self.get_auth()
        return requests.patch(self._url+path, headers=auth_header, auth=auth, timeout=5) 
def patch(url,data):
	try:
	    response = requests.patch(url, data)
	    # Consider any status other than 2xx an error
	    if not response.status_code // 100 == 2:
	        return "Error: Unexpected response {}".format(response)
	    try:
	        return response.json()
	    except:
	        return "Error: Non JSON response {}".format(response.text)
	except requests.exceptions.RequestException as e:
	    # A serious problem happened, like an SSLError or InvalidURL
	    return "Error: {}".format(e) 
def patch(url, headers, data):
    try:
        response = requests.patch(url, json.dumps(data), headers=headers, verify=True)
        # Consider any status other than 2xx an error
        if not response.status_code // 100 == 2:
            return "Error: Unexpected response {}".format(response)
        try:
            return response.json()
        except:
            return "Error: Non JSON response {}".format(response.text)
    except requests.exceptions.RequestException as e:
        # A serious problem happened, like an SSLError or InvalidURL
        return "Error: {}".format(e) 
def amppatch(url, headers, data):
	try:
		response = requests.patch(url, json.dumps(data), headers=headers, verify=True)
		# Consider any status other than 2xx an error
		if not response.status_code // 100 == 2:
			return "Error: Unexpected response {}".format(response)
		try:
			return response.json()
		except:
			return "Error: Non JSON response {}".format(response.text)
	except requests.exceptions.RequestException as e:
		# A serious problem happened, like an SSLError or InvalidURL
		return "Error: {}".format(e) 
def address_update(self, ip, hostname=None, description=None, is_gateway=None, mac=None):
        """Update address informations"""
        orgdata = self.address_search(ip)[0]
        data = {}
        if hostname != None: data["hostname"] = hostname
        if description != None: data["description"] = description
        if is_gateway != None: data["is_gateway"] = is_gateway
        if mac != None: data["mac"] = mac
        return self.__query("/addresses/%s/"%orgdata['id'], method=requests.patch, data=data) 
def close(self, issue_number):
        """
        Close an issue
        """
        edit_issue_url = "%s/%s" % (self.issues_url, issue_number)
        r = requests.patch(
            edit_issue_url,
            json={
                "state": "closed",
            },
            headers=self.headers,
        )
        r.raise_for_status() 
def patch_request(base_request):
    """
    Performs PATCH request for the class provided.

    :param: base_request: Class with which to make request.
    :type: BaseRequest
    :return: response
    :rtype: requests.Response
    """
    (headers, _, _, _, service) = base_request.get_request_vars()

    return requests.patch(
        service, headers=headers, proxies=base_request.proxies, timeout=base_request.timeout,
        json=base_request.request_body) 
def _patch(self, url, data=None):
        """ Abstract the requests.patch call """
        payload = self._make_payload(data)

        response = requests.patch(url,
            data=payload,
            auth=(self.username, self.password),
            verify=False)
        self._validate_response(response)
        item = response.json()

        return item 
**************************************************


Python requests.adapters() Examples

def __init__(self, endpoint, session_id=None, req_session=None, args=None):
        self._endpoint = endpoint.rstrip('/')
        self._session_id = session_id
        self._args = args or dict()
        # dict structure: {ttileable_key -> graph_key, tileable_ids}
        # dict value is a tuple object which records graph key and tileable id
        self._executed_tileables = dict()

        if req_session:
            self._req_session = req_session
        else:
            import requests
            from requests.adapters import HTTPAdapter

            self._req_session = requests.Session()
            self._req_session.mount('http://stackoverflow.com', HTTPAdapter(max_retries=5))

        self._main() 
def _set_response_ins_(self, pageurl):
        """
        Sets the response for the GET request of pageurl and stores it in self.resp

        :param pageurl: url for which we store the response.
        """
        try:
            s = requests.Session()
            a = requests.adapters.HTTPAdapter(max_retries=5)
            s.mount('http://', a)
            resp = s.get(pageurl, timeout=30)
            self.__resp_obj__ = resp
            resp.close()
        except requests.exceptions.Timeout:
            logging.error("\tVery Slow Internet Connection.")
        except requests.exceptions.ConnectionError:
            logging.error("\tNetwork Unavailable. Check your connection.")
        except requests.exceptions.MissingSchema:
            logging.error("\t503 Service Unavailable. Retrying download ... ") 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 **kwargs):
        super(AuthorizedSession, self).__init__(**kwargs)
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        auth_request_session = requests.Session()

        # Using an adapter to make HTTP requests robust to network errors.
        # This adapter retrys HTTP requests when network errors occur
        # and the requests seems safely retryable.
        retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
        auth_request_session.mount("https://", retry_adapter)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        # Do not pass `self` as the session here, as it can lead to infinite
        # recursion.
        self._auth_request = Request(auth_request_session) 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 **kwargs):
        super(AuthorizedSession, self).__init__(**kwargs)
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        auth_request_session = requests.Session()

        # Using an adapter to make HTTP requests robust to network errors.
        # This adapter retrys HTTP requests when network errors occur
        # and the requests seems safely retryable.
        retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
        auth_request_session.mount("https://", retry_adapter)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        # Do not pass `self` as the session here, as it can lead to infinite
        # recursion.
        self._auth_request = Request(auth_request_session) 
def refresh(self):
        """
        Refresh session on 401. This is called automatically if your existing
        session times out and resends the operation/s which returned the
        error.

        :raises SMCConnectionError: Problem re-authenticating using existing
            api credentials
        """
        if self.session and self.session_id: # Did session timeout?
            logger.info('Session timed out, will try obtaining a new session using '
                'previously saved credential information.')
            # Preserve any custom session adapters attached to original session
            transport_adapters = self.session.adapters
            self.logout() # Force log out session just in case
            self.login(**self.copy())
            if self.session:
                for req, transport in transport_adapters.items():
                    self.session.mount(req, transport)
                return
            #return self.login(**self.copy())
        raise SMCConnectionError('Session expired and attempted refresh failed.') 
def __init__(self, account, endpoint, user_agent=None, proxies=None, stream=False, retry_times=3, conn_timeout=5,
                 read_timeout=120, pool_connections=10, pool_maxsize=10, exception_handler_=exception_handler):
        if endpoint.endswith('/'):
            endpoint = endpoint[:-1]
        self._account = account
        self._endpoint = endpoint
        self._user_agent = user_agent or default_user_agent()
        self._proxies = proxies
        self._stream = stream
        self._retry_times = retry_times
        self._conn_timeout = conn_timeout
        self._read_timeout = read_timeout

        self._session = requests.Session()
        self._session.headers.update({Headers.ACCEPT_ENCODING: ''})

        # mount adapters with retry times
        adapter = HTTPAdapter(pool_connections=pool_connections, pool_maxsize=pool_maxsize,
                              max_retries=self._retry_times)
        self._session.mount('http://', adapter)
        self._session.mount('https://', adapter)

        # exception handler
        self._exception_handler = exception_handler_ 
def __init__(self):
    self.headers = default_headers()
    self.auth = None
    self.proxies = {}
    self.hooks = default_hooks()
    self.params = {}
    self.stream = False
    self.verify = True
    self.cert = None
    self.max_redirects = DEFAULT_REDIRECT_LIMIT
    self.trust_env = True
    self.cookies = cookiejar_from_dict({})
    self.adapters = OrderedDict()
    self.mount('https://', HTTPAdapter())
    self.mount('http://', HTTPAdapter())
    self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)

    self._get_proxies() 
def __init__(self):
        self._config_timestamp = None
        self._mode = None

        self.authorization_endpoint = None
        self.signing_keys = None
        self.token_endpoint = None
        self.end_session_endpoint = None
        self.issuer = None

        method_whitelist = frozenset([
            'HEAD', 'GET', 'PUT', 'DELETE', 'OPTIONS', 'TRACE', 'POST'
        ])

        retry = Retry(
            total=settings.RETRIES,
            read=settings.RETRIES,
            connect=settings.RETRIES,
            backoff_factor=0.3,
            method_whitelist=method_whitelist
        )
        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(max_retries=retry)
        self.session.mount('https://', adapter)
        self.session.verify = settings.CA_BUNDLE 
def connect(self):
        if self.session:
            return True
        self._logger.debug("Attempting a connection to device")
        requests.packages.urllib3.disable_warnings(InsecurePlatformWarning)
        requests.packages.urllib3.disable_warnings(SNIMissingWarning)
        if not self.pOptions.verify_ssl:
            requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

        self.adapter = requests.adapters.HTTPAdapter(
                pool_connections = 1,
                max_retries = self.pOptions.max_retries)
        self.session = requests.Session()
        self.session.auth = None
        if self.pOptions.authentication == AuthenticationType.Basic:
            self.session.auth = requests.auth.HTTPBasicAuth(self.creds.username,
                                                    self.creds.password)
        self.session.headers.update(self.headers)
        self.session.mount("https", self.adapter)
        self._logger.debug("Connection to device: complete")
        return True 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def init_poolmanager(self, connections, maxsize, block=False, **pool_kwargs):
        # Rewrite of the
        # requests.adapters.HTTPAdapter.init_poolmanager method
        # to use WeakCiphersPoolManager instead of
        # urllib3's PoolManager
        self._pool_connections = connections
        self._pool_maxsize = maxsize
        self._pool_block = block

        self.poolmanager = WeakCiphersPoolManager(num_pools=connections,
                                                  maxsize=maxsize, block=block, strict=True, **pool_kwargs) 
def init_poolmanager(
            self, connections, maxsize,
            block=requests.adapters.DEFAULT_POOLBLOCK, **pool_kwargs):
        """see requests.adapters.HTTPAdapter.init_poolmanager"""
        # Disable hostname verification
        pool_kwargs['assert_hostname'] = False

        # Call
        HTTPAdapter.init_poolmanager(
            self, connections=connections, maxsize=maxsize, block=block,
            **pool_kwargs) 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def __init__(self, api_key=None, proxy_dict=None, env=None, json_encoder=None, adapter=None):
        if api_key:
            self._FCM_API_KEY = api_key
        elif os.getenv('FCM_API_KEY', None):
            self._FCM_API_KEY = os.getenv('FCM_API_KEY', None)
        else:
            raise AuthenticationError("Please provide the api_key in the google-services.json file")

        self.FCM_REQ_PROXIES = None
        self.requests_session = requests.Session()
        retries = Retry(backoff_factor=1, status_forcelist=[502, 503],
                        method_whitelist=(Retry.DEFAULT_METHOD_WHITELIST | frozenset(['POST'])))
        self.requests_session.mount('http://', adapter or HTTPAdapter(max_retries=retries))
        self.requests_session.mount('https://', adapter or HTTPAdapter(max_retries=retries))
        self.requests_session.headers.update(self.request_headers())
        self.requests_session.mount(self.INFO_END_POINT, HTTPAdapter(max_retries=self.INFO_RETRIES))

        if proxy_dict and isinstance(proxy_dict, dict) and (('http' in proxy_dict) or ('https' in proxy_dict)):
            self.FCM_REQ_PROXIES = proxy_dict
            self.requests_session.proxies.update(proxy_dict)
        self.send_request_responses = []

        if env == 'app_engine':
            try:
                from requests_toolbelt.adapters import appengine
                appengine.monkeypatch()
            except ModuleNotFoundError:
                pass

        self.json_encoder = json_encoder 
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
def test_session_close_proxy_clear(self, mocker):
        proxies = {
          'one': mocker.Mock(),
          'two': mocker.Mock(),
        }
        session = requests.Session()
        mocker.patch.dict(session.adapters['http://'].proxy_manager, proxies)
        session.close()
        proxies['one'].clear.assert_called_once_with()
        proxies['two'].clear.assert_called_once_with() 
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
def test_session_close_proxy_clear(self, mocker):
        proxies = {
          'one': mocker.Mock(),
          'two': mocker.Mock(),
        }
        session = requests.Session()
        mocker.patch.dict(session.adapters['http://'].proxy_manager, proxies)
        session.close()
        proxies['one'].clear.assert_called_once_with()
        proxies['two'].clear.assert_called_once_with() 
def get_room_info(url):
    s = requests.Session()
    s.mount("http://", requests.adapters.HTTPAdapter(max_retries=MAX_RETRIES))
    r = s.get(url, headers=headers, timeout=TIMEOUT)
    if r is None:
        return None
    soup = bs4.BeautifulSoup(r.content, "lxml")
    # logger.debug(soup.prettify())
    room = []

    hide_info = soup.find("div", class_="hide")
    room_id = hide_info.find("input", id="room_id")["value"]
    house_id = hide_info.find("input", id="house_id")["value"]
    room.append(("url", url))
    room.append(("room_id", room_id))
    room.append(("house_id", house_id))

    outer = soup.select("body > div.area.clearfix")
    if len(outer) != 1:
        return None
    outer = outer[0]

    right = outer.find("div", class_="room_detail_right")
    details = [detail.get_text(strip=True) for detail in right.find("ul", class_="detail_room").find_all("li")]
    details = [" ".join(detail.replace("\n", " ").split()) for detail in details]
    room.append(("名称", right.find("div", class_="room_name").h2.get_text(strip=True)))
    for detail in details:
        room.append(tuple(map(lambda x: x.strip(), detail.split("："))))

    detail_json_r = s.get("http://sz.ziroom.com/detail/info?id={}&house_id={}".format(room_id, house_id),
                          headers=headers, timeout=10)
    if detail_json_r is not None:
        detail_json = detail_json_r.json()
        room.append((detail_json["data"]["air_part"]["vanancy"]["promise"].strip(),
                     "{}，{}".format(detail_json["data"]["air_part"]["vanancy"]["vanancy_day"],
                                    detail_json["data"]["air_part"]["vanancy"]["status"])))
        room.append(tuple(
            map(lambda x: x.strip(), detail_json["data"]["air_part"]["air_quality"]["show_info"]["status"].split(":"))))

    logger.debug(room)
    return room 
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
def __init__(
        self,
        credentials,
        refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
        max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
        refresh_timeout=None,
        auth_request=None,
    ):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def set_retry_on_busy(self, total=5, backoff_factor=0.1, status_forcelist=None, **kwargs):
        """
        Mount a custom retry object on the current session that allows service level
        retries when the SMC might reply with a Service Unavailable (503) message.
        This can be possible in larger environments with higher database activity.
        You can all this on the existing session, or provide as a dict to the login
        constructor.
        
        :param int total: total retries
        :param float backoff_factor: when to retry
        :param list status_forcelist: list of HTTP error codes to retry on
        :param list method_whitelist: list of methods to apply retries for, GET, POST and
            PUT by default
        :return: None
        """
        if self.session:
            from requests.adapters import HTTPAdapter
            from requests.packages.urllib3.util.retry import Retry
    
            method_whitelist = kwargs.pop('method_whitelist', []) or ['GET', 'POST', 'PUT']
            status_forcelist = frozenset(status_forcelist) if status_forcelist else frozenset([503])
            retry = Retry(
                total=total,
                backoff_factor=backoff_factor,
                status_forcelist=status_forcelist,
                method_whitelist=method_whitelist)
            
            for proto_str in ('http://', 'https://'):
                self.session.mount(proto_str, HTTPAdapter(max_retries=retry))
            logger.debug('Mounting retry object to HTTP session: %s' % retry) 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def requests_retry_session(
    retries=3, backoff_factor=0.3, status_forcelist=(500, 502, 504)
):
    """Opinionated wrapper that creates a requests session with a
    HTTPAdapter that sets up a Retry policy that includes connection
    retries.

    If you do the more naive retry by simply setting a number. E.g.::

        adapter = HTTPAdapter(max_retries=3)

    then it will raise immediately on any connection errors.
    Retrying on connection errors guards better on unpredictable networks.
    From http://docs.python-requests.org/en/master/api/?highlight=retries#requests.adapters.HTTPAdapter
    it says: "By default, Requests does not retry failed connections."

    The backoff_factor is documented here:
    https://urllib3.readthedocs.io/en/latest/reference/urllib3.util.html#urllib3.util.retry.Retry
    A default of retries=3 and backoff_factor=0.3 means it will sleep like::

        [0.3, 0.6, 1.2]
    """  # noqa
    session = requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
def __init__(self):
        super().__init__()
        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(max_retries=10)
        self.session.mount('http://', a) 
def __init__(self):
        super().__init__()

        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(max_retries=10)
        self.session.mount('http://', a) 
def __init__(self):
        super().__init__()

        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(max_retries=10)
        self.session.mount('http://', a) 
def __init__(self):
        super().__init__()
        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(
            max_retries=Retry(method_whitelist=frozenset(['GET', 'POST']))
        )
        self.session.mount('http://', a) 
def set_retry_on_busy(self, total=5, backoff_factor=0.1, status_forcelist=None, **kwargs):
        """
        Mount a custom retry object on the current session that allows service level
        retries when the SMC might reply with a Service Unavailable (503) message.
        This can be possible in larger environments with higher database activity.
        You can all this on the existing session, or provide as a dict to the login
        constructor.
        
        :param int total: total retries
        :param float backoff_factor: when to retry
        :param list status_forcelist: list of HTTP error codes to retry on
        :param list method_whitelist: list of methods to apply retries for, GET, POST and
            PUT by default
        :return: None
        """
        if self.session:
            from requests.adapters import HTTPAdapter
            from requests.packages.urllib3.util.retry import Retry
    
            method_whitelist = kwargs.pop('method_whitelist', []) or ['GET', 'POST', 'PUT']
            status_forcelist = frozenset(status_forcelist) if status_forcelist else frozenset([503])
            retry = Retry(
                total=total,
                backoff_factor=backoff_factor,
                status_forcelist=status_forcelist,
                method_whitelist=method_whitelist)
            
            for proto_str in ('http://', 'https://'):
                self.session.mount(proto_str, HTTPAdapter(max_retries=retry))
            logger.debug('Mounting retry object to HTTP session: %s' % retry) 
def requests_with_retry(retries: int = 3) -> requests.Session:
    session = requests.Session()
    adapter = requests.adapters.HTTPAdapter(
        max_retries=retry.Retry(
            total=retries, backoff_factor=0.1, status_forcelist=(500, 502, 504)
        )
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session 
def __init__(self, domain: str, api_version: str = API_VERSION, application: str = DEFAULT_APPLICATION, verify=True,
                 http_adapter: requests.adapters.HTTPAdapter = None):
        super().__init__()
        self._session = None
        self.domain = domain
        self.api_version = api_version
        self.application = application
        self.verify = verify
        self.http_adapter = http_adapter 
def use(
            cls,
            environment_or_domain: Union[Environment, str] = Environment.PROD,
            client_id: Optional[str] = None,
            client_secret: Optional[str] = None,
            scopes: Optional[Union[Tuple, List, str]] = (),
            api_version: str = API_VERSION,
            application: str = DEFAULT_APPLICATION,
            http_adapter: requests.adapters.HTTPAdapter = None
    ) -> None:
        environment_or_domain = environment_or_domain.name if isinstance(environment_or_domain,
                                                                         Environment) else environment_or_domain
        session = cls.get(
            environment_or_domain,
            client_id=client_id,
            client_secret=client_secret,
            scopes=scopes,
            api_version=api_version,
            application=application,
            http_adapter=http_adapter
        )

        session.init()

        if cls.current_is_set:
            cls.current = session
        else:
            cls.default = session 
def get(
            cls,
            environment_or_domain: Union[Environment, str] = Environment.PROD,
            client_id: Optional[str] = None,
            client_secret: Optional[str] = None,
            scopes: Optional[Union[Tuple, List, str]] = (),
            token: str = '',
            is_gssso: bool = False,
            api_version: str = API_VERSION,
            application: str = DEFAULT_APPLICATION,
            http_adapter: requests.adapters.HTTPAdapter = None
    ) -> 'GsSession':
        """ Return an instance of the appropriate session type for the given credentials"""

        environment_or_domain = environment_or_domain.name if isinstance(environment_or_domain,
                                                                         Environment) else environment_or_domain

        if client_id is not None:
            if environment_or_domain not in (Environment.PROD.name, Environment.QA.name, Environment.DEV.name):
                raise MqUninitialisedError('Only PROD, QA and DEV are valid environments')
            if isinstance(scopes, str):
                scopes = (scopes,)
            else:
                scopes = cls.Scopes.get_default() if len(scopes) == 0 else scopes
            return OAuth2Session(environment_or_domain, client_id, client_secret, scopes, api_version=api_version,
                                 application=application, http_adapter=http_adapter)
        elif token:
            if is_gssso:
                try:
                    return PassThroughGSSSOSession(environment_or_domain, token, api_version=api_version,
                                                   application=application, http_adapter=http_adapter)
                except NameError:
                    raise MqUninitialisedError('This option requires gs_quant_internal to be installed')
            else:
                return PassThroughSession(environment_or_domain, token, api_version=api_version,
                                          application=application, http_adapter=http_adapter)
        else:
            try:
                return KerberosSession(environment_or_domain, api_version=api_version, http_adapter=http_adapter)
            except NameError:
                raise MqUninitialisedError('Must specify client_id and client_secret') 
def __init__(self, environment_or_domain: str, api_version: str = API_VERSION,
                     application: str = DEFAULT_APPLICATION, http_adapter: requests.adapters.HTTPAdapter = None):
            domain, verify = self.domain_and_verify(environment_or_domain)
            GsSession.__init__(self, domain, api_version=api_version, application=application, verify=verify,
                               http_adapter=http_adapter) 
def __init__(self, url=None,
                 base_url=None,
                 proxy=None,
                 username=None,
                 password=None,
                 verify=False,
                 minutes=3,
                 timeout=30):
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        OpTestLogger.optest_logger_glob.setUpChildLogger("urllib3")
        self.username = username
        self.password = password
        self.session = requests.Session()
        if self.username is not None and self.password is not None:
            self.session.auth = (self.username, self.password)
        self.session.verify = verify
        self.jsonHeader = {'Content-Type': 'application/json'}
        self.xAuthHeader = {}
        self.timeout = timeout
        self.minutes = minutes
        self.session.mount('https://', HTTPAdapter(max_retries=5))
        # value.max_retries for future debug if needed
#        for key, value in self.session.adapters.items():
#            log.debug("max_retries={}".format(value.max_retries))

        if proxy:
            self.session.proxies = {"http": proxy}
        else:
            self.session.proxies = {}

        self.base_url = url + (base_url if base_url else "") 
def get_default_session():
    s = requests.Session()
    # remount http and https adapters to config max_retries
    adapter = HTTPAdapter(
        max_retries=0,
        pool_connections=5,
        pool_maxsize=50,
        pool_block=True,
    )
    s.mount('http://', adapter)
    s.mount('https://', adapter)
    return s 
def session(self):
        if not self._session:
            session = requests.session()
            session.mount(self.config.api_url, requests.adapters.HTTPAdapter(max_retries=3))
            self._session = session
        return self._session 
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
def _download(url, outfile, headers, transient_retry, strip_prefix):
  s = requests.Session()
  retry = None
  if transient_retry > 0:
    # See http://urllib3.readthedocs.io/en/latest/reference/urllib3.util.html
    retry = Retry(
      total=transient_retry,
      connect=5,
      read=5,
      redirect=5,
      status_forcelist=range(500, 600),
      backoff_factor=0.2,
      raise_on_status=False,
    )
    print retry
    s.mount(url, requests.adapters.HTTPAdapter(max_retries=retry))


  logging.info('Connecting to %s ...', url)
  r = s.get(url, headers=headers, stream=True)
  if r.status_code != requests.codes.ok:
    r.raise_for_status()

  if outfile:
    fd = open(outfile, 'wb')
  else:
    fd = sys.stdout

  total = 0
  with fd:
    logging.info('Downloading %s ...', url)
    loaded_prefix = ''
    for chunk in r.iter_content(CHUNK_SIZE):
      total += len(chunk)

      if strip_prefix:
        remaining_prefix = strip_prefix[len(loaded_prefix):]
        round_prefix = chunk[:len(remaining_prefix)]
        loaded_prefix += round_prefix
        if round_prefix != remaining_prefix[:len(round_prefix)]:
          raise ValueError(
              'Expected prefix was not observed: %r != %r...' % (
              loaded_prefix, strip_prefix))
        chunk = chunk[len(round_prefix):]
        if not chunk:
          continue

      fd.write(chunk)
      logging.info('Downloaded %.1f MB so far', total / 1024 / 1024)
  return r.status_code, total 
def __init__(self, access_key=None, secret_key=None, https_proxy=None,
                 insecure=False, endpoint=None, search_endpoint=None):
        """Initializes a new API connection.

        Args:
            access_key (str, optitonal): The user's Matchlight Public
                API access key. If not passed as an argument this value
                must be set using the ``MATCHLIGHT_ACCESS_KEY``
                environment variable.
            secret_key (str, optional): The user's Matchlight Public
                API access key. If not passed as an argument this value
                must be set using the ``MATCHLIGHT_SECRET_KEY``
                environment variable.
            https_proxy (str): A string defining the HTTPS proxy to
                use. Defaults to None.
            insecure (bool, optional): Whether or not to verify
                certificates for the HTTPS proxy. Defaults to ``False``
                (certificates will be verified).
            endpoint (str, optional): Base URL for requests. Defaults
                to ``'https://api.matchlig.ht/api/v2'``.
            search_endpoint (str, optional): Base URL for all search
                API requests.

        """
        if access_key is None:
            access_key = os.environ.get('MATCHLIGHT_ACCESS_KEY', None)
        if secret_key is None:
            secret_key = os.environ.get('MATCHLIGHT_SECRET_KEY', None)
        if access_key is None or secret_key is None:
            raise matchlight.error.SDKError(
                'The APIConnection object requires your Matchlight '
                'API access_key and secret_key either be passed as input '
                'parameters or set in the MATCHLIGHT_ACCESS_KEY and '
                'MATCHLIGHT_SECRET_KEY environment variables.')
        if endpoint is None:
            endpoint = MATCHLIGHT_API_URL_V2
        if search_endpoint is None:
            search_endpoint = MATCHLIGHT_API_URL_V2

        self.access_key = access_key
        self.secret_key = secret_key
        self.proxy = {'https': https_proxy}
        self.insecure = insecure
        self.endpoint = endpoint
        self.search_endpoint = search_endpoint
        self.session = requests.Session()
        self.session.mount(
            self.endpoint,
            requests.adapters.HTTPAdapter(
                max_retries=requests_urllib3.util.Retry(
                    total=5, status_forcelist=[500, 502, 503, 504])),
        ) 
**************************************************


Python requests.org() Examples

def _query(
            self,
            page: 'WikipediaPage',
            params: Dict[str, Any]
    ):
        base_url = 'https://' + page.language + '.wikipedia.org/w/api.php'
        log.info(
            "Request URL: %s",
            base_url + "?" + "&".join(
                [k + "=" + str(v) for k, v in params.items()]
            )
        )
        params['format'] = 'json'
        params['redirects'] = 1
        r = self._session.get(
            base_url,
            params=params,
            **self._request_kwargs
        )
        return r.json() 
def rest_tb_file_dnload_to_fd(self, fd, remote_filename):
        """
        Download a remote file from the broker to a local file

        :param str remote_filename: filename in the broker's user
          storage area
        :params int fd: file descriptor where to write the data to
        """
        url = "files/%s" % remote_filename
        with contextlib.closing(self.send_request("GET", url, data = {},
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                total += len(chunk)
            return total 
def rest_tb_target_console_read_to_fd(self, fd, rt, console, offset,
                                          max_size = 0, ticket = ''):
        url = "targets/%s/console/" % rt['id']
        data = {
            'offset': offset,
        }
        if console:
            data['console'] = console
        if ticket != '':
            data['ticket'] = ticket
        with contextlib.closing(self.send_request("GET", url, data = data,
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                # don't use chunk_size, as it might be less
                total += len(chunk)
                if max_size > 0 and total >= max_size:
                    break
            return total 
def rest_tb_file_dnload_to_fd(self, fd, remote_filename):
        """
        Download a remote file from the broker to a local file

        :param str remote_filename: filename in the broker's user
          storage area
        :params int fd: file descriptor where to write the data to
        """
        url = "files/%s" % remote_filename
        with contextlib.closing(self.send_request("GET", url, data = {},
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                total += len(chunk)
            return total 
def rest_tb_target_console_read_to_fd(self, fd, rt, console, offset,
                                          max_size = 0, ticket = ''):
        url = "targets/%s/console/" % rt['id']
        data = {
            'offset': offset,
        }
        if console:
            data['console'] = console
        if ticket != '':
            data['ticket'] = ticket
        with contextlib.closing(self.send_request("GET", url, data = data,
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                # don't use chunk_size, as it might be less
                total += len(chunk)
                if max_size > 0 and total >= max_size:
                    break
            return total 
def infer_msg(self, tts, rsp):
        """Attempt to guess what went wrong by using known
        information (e.g. http response) and observed behaviour

        """
        # rsp should be <requests.Response>
        # http://docs.python-requests.org/en/master/api/
        status = rsp.status_code
        reason = rsp.reason

        cause = "Unknown"
        if status == 403:
            cause = "Bad token or upstream API changes"
        elif status == 404 and not tts.lang_check:
            cause = "Unsupported language '%s'" % self.tts.lang
        elif status >= 500:
            cause = "Uptream API error. Try again later."

        return "%i (%s) from TTS API. Probable cause: %s" % (
            status, reason, cause) 
def __init__(self, api_key, return_python_objects=True):
        """
        A Bot instance. From here you can call all the functions.
        The api key can be optained from @BotFather, see https://core.telegram.org/bots#6-botfather

        :param api_key: The API key. Something like "ABC-DEF1234ghIkl-zyx57W2v1u123ew11"
        :type  api_key: str

        :param return_python_objects: If it should convert the json to `pytgbot.api_types.**` objects. Default: `True`
        :type  return_python_objects: bool
        """
        from datetime import datetime

        if api_key is None or not api_key:
            raise ValueError("No api_key given.")
        self.api_key = api_key
        self.return_python_objects = return_python_objects
        self._last_update = datetime.now()
        self._id = None        # will be filled when using the property .id or .username, or when calling ._load_info()
        self._username = None  # will be filled when using the property .id or .username, or when calling ._load_info()
    # end def __init__ 
def delete_webhook(self):
        """
        Use this method to remove webhook integration if you decide to switch back to getUpdates. Returns True on success. Requires no parameters.

        https://core.telegram.org/bots/api#deletewebhook

        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        result = self.do("deleteWebhook")
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_webhook 
def __init__(self, api_key, return_python_objects=True):
        """
        A Bot instance. From here you can call all the functions.
        The api key can be optained from @BotFather, see https://core.telegram.org/bots#6-botfather

        :param api_key: The API key. Something like "ABC-DEF1234ghIkl-zyx57W2v1u123ew11"
        :type  api_key: str

        :param return_python_objects: If it should convert the json to `pytgbot.api_types.**` objects. Default: `True`
        :type  return_python_objects: bool
        """
        from datetime import datetime

        if api_key is None or not api_key:
            raise ValueError("No api_key given.")
        self.api_key = api_key
        self.return_python_objects = return_python_objects
        self._last_update = datetime.now()
        self._id = None        # will be filled when using the property .id or .username, or when calling ._load_info()
        self._username = None  # will be filled when using the property .id or .username, or when calling ._load_info()
    # end def __init__ 
def get_session():
    global session
    if session is None:
        session = requests.Session()
        session.headers = {
            # https://toolbelt.readthedocs.org/en/latest/user-agent.html#user-agent-constructor
            'User-Agent': user_agent('Deis Controller', deis_version),
        }
        # `mount` a custom adapter that retries failed connections for HTTP and HTTPS requests.
        # http://docs.python-requests.org/en/latest/api/#requests.adapters.HTTPAdapter
        session.mount('http://', requests.adapters.HTTPAdapter(max_retries=10))
        session.mount('https://', requests.adapters.HTTPAdapter(max_retries=10))
    return session 
def __encode_msg(self, msg):
        if isinstance(msg, str):
            msg = msg.encode('utf-8')
        return msg

    # http://docs.python.org/2/library/httplib.html 
def __call__(self, r):
        """
        Add Tendl Bearer Token into header of the request.

        For full description, see requests documentation:
        http://docs.python-requests.org/en/master/user/authentication/
        """
        headers = {
            "Authorization": "Bearer {}".format(self.__bearer_token),
            }
        r.prepare_headers(headers)
        return r 
def _get_data(self, url, instance):
        ssl_params = {
            'ssl': instance.get('ssl'),
            'ssl_keyfile': instance.get('ssl_keyfile'),
            'ssl_certfile': instance.get('ssl_certfile'),
            'ssl_verify': instance.get('ssl_verify'),
        }
        for key, param in ssl_params.items():
            if param is None:
                del ssl_params[key]

        # Load SSL configuration, if available.
        # ssl_verify can be a bool or a string (http://docs.python-requests.org/en/latest/user/advanced/#ssl-cert-verification)
        if isinstance(ssl_params.get('ssl_verify'), bool) or isinstance(ssl_params.get('ssl_verify'), basestring):
            verify = ssl_params.get('ssl_verify')
        else:
            verify = None
        if ssl_params.get('ssl_certfile') and ssl_params.get('ssl_keyfile'):
            cert = (ssl_params.get('ssl_certfile'), ssl_params.get('ssl_keyfile'))
        elif ssl_params.get('ssl_certfile'):
            cert = ssl_params.get('ssl_certfile')
        else:
            cert = None

        resp = requests.get(
            url,
            timeout=10,
            verify=verify,
            cert=cert
        )
        resp.raise_for_status()
        return resp.json() 
def communicate_with(self, endpoint, payload=None, cache=False):
        """Sends an HTTP request to the specified endpoint.

        @param endpoint An Endpoint subclass instance.
        @param payload A pycamunda.entity.RequestsInput implementation containing to be sent along with the request.
        @param cache Whether the response should be cached.
        If not set to True, the internal cache will never be used.
        If set to True, the first request for an endpoint will contact the remote while subsequent requests return the cached response.
        @returns An instance of @p endpoint.return_type.
        @see http://docs.python-requests.org/en/master/api/#requests.request
        """
        if cache and endpoint in self.cache:
            return self.cache[endpoint]
        request_kwargs = {'auth': self.auth, 'headers': endpoint.headers, 'timeout': endpoint.timeout,
                          'params': endpoint.params}
        if payload is not None:
            request_kwargs.update(payload.to_requests())
        url = self.base_url + endpoint.uri
        log.debug('Sending request to Camunda endpoint %s', url)
        response = requests.request(endpoint.method, url, **request_kwargs)
        # TODO: Deal with standard api exceptions
        if response.status_code == 400:
            raise BadRequest(response)
        if response.status_code == 404:
            raise ResourceNotFound(response)

        if endpoint.return_type is None:
            return None

        cleaned_response = response.text.replace(')]}\'\n', '', 1)
        response = endpoint.return_type(cleaned_response)
        if cache:
            self.cache[endpoint] = response
        return response 
def __init__(self, session_id, instance_url, **kwargs):
        """ Constructor.

            :param: session_id: Session ID used to make request
            :type: session_id: string
            :param: instance_url: Instance URL used to make the request (eg. `'eu11.salesforce.com'`)
            :type: instance_url: string
            :param: **kwargs: kwargs
            :type: **kwargs: dict
            :Keyword Arguments:
                * *api_version* (`string`) --
                    API version for the request
                    Default: `'37.0'`
                * *http_method* (`string`) --
                    HTTP method for the request
                    Default: `'GET'`
                * *proxies* (`dict`) --
                    A dict containing proxies to be used by `requests` module. Ex:
                        `{"https": "example.org:443"}`
                    Default: `None`
                * *timeout* (`string`) --
                    A dict indicating the timeout value for connect and read to be used by `requests` module. Ex:
                        `{"timeout": "30"}`
                    Default: `None`
                * *request_body* (`dict`) --
                    A dict containing the request body
                    Default: `None`
        """
        self.proxies = kwargs.get('proxies', None)
        self.session_id = session_id
        self.http_method = kwargs.get('http_method', 'GET')
        self.instance_url = instance_url
        self.request_body = kwargs.get('request_body', None)
        self.api_version = kwargs.get('version', DEFAULT_API_VERSION)
        self.timeout = float(kwargs['timeout']) if 'timeout' in kwargs else None
        self.service = None
        self.status = None
        self.response = None
        self.headers = None
        self.request_url = None
        self.exceptions = [] 
def set_proxies(self, proxies):
        """ Sets `proxies` for this class.

        :param proxies: A dict containing proxies to use (see: # noqa
        `Proxies <http://docs.python-requests.org/en/master/user/advanced/#proxies)>`_ # noqa
        in the python-requests.org guide.

        :type: dict
        """
        self.proxies = proxies 
def _set_attributes(self, r):
        x = IseErsRequest(inspect.stack()[1][3])
        # http://docs.python-requests.org/en/master/api/#requests.Response
        x.response = r
        x.status_code = r.status_code
        x.reason = r.reason
        x.headers = r.headers
        x.encoding = r.encoding
        self._log(DEBUG2, r.encoding)
        self._log(DEBUG2, r.request.headers)  # XXX authorization header
        self._log(DEBUG2, r.headers)
        x.content = r.content  # bytes
        x.text = r.text  # Unicode
        self._log(DEBUG3, r.text)
        try:
            x.xml_root = etree.fromstring(r.content)
        except etree.ParseError as e:
            self._log(DEBUG1, 'ElementTree.fromstring ParseError: %s', e)

        if x.xml_root is not None:
            self._log(DEBUG1, 'root tag: %s', x.xml_root.tag)
            if x.xml_root.tag == '{ers.ise.cisco.com}ersResponse':
                message = x.xml_root.find('messages/message')
                if message is not None:
                    x.obj = {}
                    x.obj['error'] = {}
                    for k in ['type', 'code']:
                        if k in message.attrib:
                            x.obj['error'][k] = message.attrib[k]
                    title = message.findall('title')
                    if title is not None:
                        x.obj['error']['title'] = []
                        for elem in title:
                            x.obj['error']['title'].append(elem.text)

                    self._log(DEBUG2, x.obj)

        return x 
def __init__(
            self,
            language: str = 'en',
            extract_format: ExtractFormat = ExtractFormat.WIKI,
            headers: Optional[Dict[str, Any]] = None,
            **kwargs
    ) -> None:
        """
        Constructs Wikipedia object for extracting information Wikipedia.

        :param language: Language mutation of Wikipedia -
                http://meta.wikimedia.org/wiki/List_of_Wikipedias
        :param extract_format: Format used for extractions
                :class:`ExtractFormat` object.
        :param headers:  Headers sent as part of HTTP request
        :param kwargs: Optional parameters used in -
                http://docs.python-requests.org/en/master/api/#requests.request

        Examples:

        * Use proxy: ``Wikipedia('en', proxies={'http': 'http://localhost:1234'})``
        """
        kwargs.setdefault('timeout', 10.0)

        self.language = language.strip().lower()
        self.extract_format = extract_format
        default_headers = dict() if headers is None else headers
        default_headers.setdefault(
            'User-Agent',
            'Wikipedia-API (https://github.com/martin-majlis/Wikipedia-API)'
        )
        self._session = requests.Session()
        self._session.headers.update(default_headers)
        self._request_kwargs = kwargs 
def info(
            self,
            page: 'WikipediaPage'
    ) -> 'WikipediaPage':
        """
        https://www.mediawiki.org/w/api.php?action=help&modules=query%2Binfo
        https://www.mediawiki.org/wiki/API:Info
        """
        params = {
            'action': 'query',
            'prop': 'info',
            'titles': page.title,
            'inprop': '|'.join([
                'protection',
                'talkid',
                'watched',
                'watchers',
                'visitingwatchers',
                'notificationtimestamp',
                'subjectid',
                'url',
                'readable',
                'preload',
                'displaytitle'
            ])
        }
        raw = self._query(
            page,
            params
        )
        self._common_attributes(raw['query'], page)
        pages = raw['query']['pages']
        for k, v in pages.items():
            if k == '-1':
                page._attributes['pageid'] = -1
                return page
            else:
                return self._build_info(v, page)
        return page 
def categories(
            self,
            page: 'WikipediaPage',
            **kwargs
    ) -> PagesDict:
        """
        Returns categories for page with respect to parameters

        API Calls for parameters:

        - https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bcategories
        - https://www.mediawiki.org/wiki/API:Categories

        :param page: :class:`WikipediaPage`
        :param kwargs: parameters used in API call
        :return: categories for page
        """

        params = {
            'action': 'query',
            'prop': 'categories',
            'titles': page.title,
            'cllimit': 500,
        }

        used_params = kwargs
        used_params.update(params)

        raw = self._query(
            page,
            used_params
        )
        self._common_attributes(raw['query'], page)
        pages = raw['query']['pages']
        for k, v in pages.items():
            if k == '-1':
                page._attributes['pageid'] = -1
                return {}
            else:
                return self._build_categories(v, page)
        return {} 
def langlinks(self) -> PagesDict:
        """
        Returns all language links to pages in other languages.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Blanglinks
        * https://www.mediawiki.org/wiki/API:Langlinks

        :return: :class:`PagesDict`
        """
        if not self._called['langlinks']:
            self._fetch('langlinks')
        return self._langlinks 
def links(self) -> PagesDict:
        """
        Returns all pages linked from the current page.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Blinks
        * https://www.mediawiki.org/wiki/API:Links

        :return: :class:`PagesDict`
        """
        if not self._called['links']:
            self._fetch('links')
        return self._links 
def categories(self) -> PagesDict:
        """
        Returns categories associated with the current page.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bcategories
        * https://www.mediawiki.org/wiki/API:Categories

        :return: :class:`PagesDict`
        """
        if not self._called['categories']:
            self._fetch('categories')
        return self._categories 
def categorymembers(self) -> PagesDict:
        """
        Returns all pages belonging to the current category.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bcategorymembers
        * https://www.mediawiki.org/wiki/API:Categorymembers

        :return: :class:`PagesDict`
        """
        if not self._called['categorymembers']:
            self._fetch('categorymembers')
        return self._categorymembers 
def __init__(self, cuc, username, password, verify=False, disable_warnings=False, timeout=2):
        """
        Sets up the connection to Cisco Unity Connection

        :param cuc: Unity connection IP Address
        :param username: User with privilege to access rest api
        :param password: Users password
        :param verify: Verify SSL certificate
        :param disable_warnings: Disable console warnings if ssl cert invalid
        :param timeout: Timeout for request response
        """

        self.url_base = 'https://{0}/vmrest'.format(cuc)
        self.cuc = requests.session()
        self.cuc.auth = (username, password)
        self.cuc.verify = verify  # http://docs.python-requests.org/en/latest/user/advanced/#ssl-cert-verification
        self.disable_warnings = disable_warnings
        self.timeout = timeout
        self.cuc.headers.update({
            'Accept': 'application/json',
            'Connection': 'keep_alive',
            'Content_type': 'application/json',
        })

        if self.disable_warnings:
            requests.packages.urllib3.disable_warnings() 
def _do_request(self, url, params=None, files=None, use_long_polling=None, request_timeout=None):
        """

        :param url: The complete url to send to
        :type  url: str

        :keyword params: Parameter for that connection

        :keyword files: Optional files parameters

        :keyword use_long_polling: if it should use long polling.
                                (see http://docs.python-requests.org/en/latest/api/#requests.Response.iter_content)
        :type    use_long_polling: bool

        :keyword request_timeout: When the request should time out.
        :type    request_timeout: int

        :return: json data received
        :rtype: DictObject.DictObject
        """
        import requests
        r = requests.post(url, params=params, files=files, stream=use_long_polling,
                          verify=True, timeout=request_timeout)
        # No self signed certificates. Telegram should be trustworthy anyway...
        from DictObject import DictObject
        try:
            logger.debug("Response: {}".format(r.json()))
            json_data = DictObject.objectify(r.json())
        except Exception:
            logger.exception("Parsing answer failed.\nRequest: {r!s}\nContent: {r.content}".format(r=r))
            raise
        # end if
        json_data["response"] = r  # TODO: does this failes on json lists? Does TG does that?
        return json_data
    # end def 
def get_webhook_info(self):
        """
        Use this method to get current webhook status.
        Requires no parameters.
        If the bot is using get_updates, will return an object with the url field empty.

        https://core.telegram.org/bots/api#getwebhookinfo


        Returns:

        :return: On success, returns a :class:`pytgbot.api_types.receivable.updates.WebhookInfo` object
        :rtype:  pytgbot.api_types.receivable.updates.WebhookInfo
        """
        result = self.do("getWebhookInfo")
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import WebhookInfo
            try:
                return WebhookInfo.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type WebhookInfo", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_webhook_info 
def export_chat_invite_link(self, chat_id):
        """
        Use this method to generate a new invite link for a chat; any previously generated link is revoked. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns the new invite link as String on success.

        Note: Each administrator in a chat generates their own invite links. Bots can't use invite links generated by other administrators. If you want your bot to work with invite links, it will need to generate its own link using exportChatInviteLink – after this the link will become available to the bot via the getChat method. If your bot needs to generate a new invite link replacing its previous one, use exportChatInviteLink again.


        https://core.telegram.org/bots/api#exportchatinvitelink


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns the new invite link as String on success
        :rtype:  str|unicode
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("exportChatInviteLink", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(str, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive str", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def export_chat_invite_link 
def delete_chat_photo(self, chat_id):
        """
        Use this method to delete a chat photo. Photos can't be changed for private chats. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group.

        https://core.telegram.org/bots/api#deletechatphoto


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("deleteChatPhoto", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_chat_photo 
def set_chat_title(self, chat_id, title):
        """
        Use this method to change the title of a chat. Titles can't be changed for private chats. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group.

        https://core.telegram.org/bots/api#setchattitle


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode

        :param title: New chat title, 1-255 characters
        :type  title: str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(title, unicode_type, parameter_name="title")

        result = self.do("setChatTitle", chat_id=chat_id, title=title)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_chat_title 
def unpin_chat_message(self, chat_id):
        """
        Use this method to unpin a message in a supergroup or a channel.
        The bot must be an administrator in the chat for this to work and must have the ‘can_pin_messages’ admin right
        in the supergroup or ‘can_edit_messages’ admin right in the channel. Returns True on success.

        https://core.telegram.org/bots/api#unpinchatmessage


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup/channel (in the format @username)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("unpinChatMessage", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def unpin_chat_message 
def leave_chat(self, chat_id):
        """
        Use this method for your bot to leave a group, supergroup or channel. Returns True on success.

        https://core.telegram.org/bots/api#leavechat


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                        format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("leaveChat", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def leave_chat 
def get_chat(self, chat_id):
        """
        Use this method to get up to date information about the chat (current name of the user for one-on-one
        conversations, current username of a user, group or channel, etc.)

        Returns a Chat object on success.

        https://core.telegram.org/bots/api#getchat


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                        format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns a Chat object on success
        :rtype:  pytgbot.api_types.receivable.peer.Chat
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("getChat", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.peer import Chat
            try:
                return Chat.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Chat", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_chat 
def get_chat_administrators(self, chat_id):
        """
        Use this method to get a list of administrators in a chat.

        On success, returns an Array of ChatMember objects that contains information about all chat administrators
        except other bots. If the chat is a group or a supergroup and no administrators were appointed,
        only the creator will be returned.

        https://core.telegram.org/bots/api#getchatadministrators


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                        format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: On success, returns an Array of ChatMember objects that contains information about all
                 chat administrators except other bots
        :rtype:  list of pytgbot.api_types.receivable.peer.ChatMember
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("getChatAdministrators", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.peer import ChatMember
            try:
                return ChatMember.from_array_list(result, list_level=1)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type ChatMember", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_chat_administrators 
def get_chat_member(self, chat_id, user_id):
        """
        Use this method to get information about a member of a chat. Returns a ChatMember object on success.

        https://core.telegram.org/bots/api#getchatmember


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                         format @channelusername)
        :type  chat_id: int | str|unicode

        :param user_id: Unique identifier of the target user
        :type  user_id: int


        Returns:

        :return: Returns a ChatMember object on success
        :rtype:  pytgbot.api_types.receivable.peer.ChatMember
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        result = self.do("getChatMember", chat_id=chat_id, user_id=user_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.peer import ChatMember
            try:
                return ChatMember.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type ChatMember", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_chat_member 
def set_chat_sticker_set(self, chat_id, sticker_set_name):
        """
        Use this method to set a new group sticker set for a supergroup. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Use the field can_set_sticker_set optionally returned in getChat requests to check if the bot can use this method. Returns True on success.

        https://core.telegram.org/bots/api#setchatstickerset


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup (in the format @supergroupusername)
        :type  chat_id: int | str|unicode

        :param sticker_set_name: Name of the sticker set to be set as the group sticker set
        :type  sticker_set_name: str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(sticker_set_name, unicode_type, parameter_name="sticker_set_name")

        result = self.do("setChatStickerSet", chat_id=chat_id, sticker_set_name=sticker_set_name)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_chat_sticker_set 
def delete_chat_sticker_set(self, chat_id):
        """
        Use this method to delete a group sticker set from a supergroup. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Use the field can_set_sticker_set optionally returned in getChat requests to check if the bot can use this method. Returns True on success.

        https://core.telegram.org/bots/api#deletechatstickerset


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup (in the format @supergroupusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("deleteChatStickerSet", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_chat_sticker_set 
def get_sticker_set(self, name):
        """
        Use this method to get a sticker set. On success, a StickerSet object is returned.

        https://core.telegram.org/bots/api#getstickerset


        Parameters:

        :param name: Name of the sticker set
        :type  name: str|unicode


        Returns:

        :return: On success, a StickerSet object is returned
        :rtype: pytgbot.api_types.receivable.stickers.StickerSet
        """
        assert_type_or_raise(name, unicode_type, parameter_name="name")

        result = self.do("getStickerSet", name=name)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.stickers import StickerSet
            try:
                return StickerSet.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type StickerSet", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_sticker_set 
def upload_sticker_file(self, user_id, png_sticker):
        """
        Use this method to upload a .png file with a sticker for later use in createNewStickerSet and addStickerToSet methods (can be used multiple times). Returns the uploaded File on success.

        https://core.telegram.org/bots/api#uploadstickerfile


        Parameters:

        :param user_id: User identifier of sticker file owner
        :type  user_id: int

        :param png_sticker: Png image with the sticker, must be up to 512 kilobytes in size, dimensions must not exceed 512px, and either width or height must be exactly 512px.
        :type  png_sticker: pytgbot.api_types.sendable.files.InputFile


        Returns:

        :return: Returns the uploaded File on success
        :rtype: pytgbot.api_types.receivable.media.File
        """
        from pytgbot.api_types.sendable.files import InputFile

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        assert_type_or_raise(png_sticker, InputFile, parameter_name="png_sticker")

        result = self.do("uploadStickerFile", user_id=user_id, png_sticker=png_sticker)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.media import File
            try:
                return File.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type File", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def upload_sticker_file 
def set_sticker_position_in_set(self, sticker, position):
        """
        Use this method to move a sticker in a set created by the bot to a specific position . Returns True on success.

        https://core.telegram.org/bots/api#setstickerpositioninset


        Parameters:

        :param sticker: File identifier of the sticker
        :type  sticker: str|unicode

        :param position: New sticker position in the set, zero-based
        :type  position: int


        Returns:

        :return: Returns True on success
        :rtype: bool
        """
        assert_type_or_raise(sticker, unicode_type, parameter_name="sticker")

        assert_type_or_raise(position, int, parameter_name="position")

        result = self.do("setStickerPositionInSet", sticker=sticker, position=position)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_sticker_position_in_set 
def delete_sticker_from_set(self, sticker):
        """
        Use this method to delete a sticker from a set created by the bot. Returns True on success.

        https://core.telegram.org/bots/api#deletestickerfromset


        Parameters:

        :param sticker: File identifier of the sticker
        :type  sticker: str|unicode


        Returns:

        :return: Returns True on success
        :rtype: bool
        """
        assert_type_or_raise(sticker, unicode_type, parameter_name="sticker")

        result = self.do("deleteStickerFromSet", sticker=sticker)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_sticker_from_set 
def set_passport_data_errors(self, user_id, errors):
        """
        Informs a user that some of the Telegram Passport elements they provided contains errors. The user will not be able to re-submit their Passport to you until the errors are fixed (the contents of the field for which you returned the error must change). Returns True on success.
        Use this if the data submitted by the user doesn't satisfy the standards your service requires for any reason. For example, if a birthday date seems invalid, a submitted document is blurry, a scan shows evidence of tampering, etc. Supply some details in the error message to make sure the user knows how to correct the issues.

        https://core.telegram.org/bots/api#setpassportdataerrors


        Parameters:

        :param user_id: User identifier
        :type  user_id: int

        :param errors: A JSON-serialized array describing the errors
        :type  errors: list of pytgbot.api_types.sendable.passport.PassportElementError


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        from pytgbot.api_types.sendable.passport import PassportElementError

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        assert_type_or_raise(errors, list, parameter_name="errors")

        result = self.do("setPassportDataErrors", user_id=user_id, errors=errors)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_passport_data_errors 
def do(self, command, files=None, use_long_polling=False, request_timeout=None, **query):
        """
        Send a request to the api.

        If the bot is set to return the json objects, it will look like this:

        ```json
        {
            "ok": bool,
            "result": {...},
            # optionally present:
            "description": "human-readable description of the result",
            "error_code": int
        }
        ```

        :param command: The Url command parameter
        :type  command: str

        :param request_timeout: When the request should time out. Default: `None`
        :type  request_timeout: int

        :param files: if it needs to send files.

        :param use_long_polling: if it should use long polling. Default: `False`
                                (see http://docs.python-requests.org/en/latest/api/#requests.Response.iter_content)
        :type  use_long_polling: bool

        :param query: all the other `**kwargs` will get json encoded.

        :return: The json response from the server, or, if `self.return_python_objects` is `True`, a parsed return type.
        :rtype:  DictObject.DictObject | pytgbot.api_types.receivable.Receivable
        """
        import requests

        url, params = self._prepare_request(command, query)
        r = requests.post(url, params=params, files=files, stream=use_long_polling,
                          verify=True,  # No self signed certificates. Telegram should be trustworthy anyway...
                          timeout=request_timeout)
        return self._postprocess_request(r)
    # end def do 
def delete_webhook(self, ):
        """
        Use this method to remove webhook integration if you decide to switch back to getUpdates. Returns True on success. Requires no parameters.

        https://core.telegram.org/bots/api#deletewebhook

        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        
        result = self.do("deleteWebhook", )
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_webhook 
def get_webhook_info(self, ):
        """
        Use this method to get current webhook status. Requires no parameters. On success, returns a WebhookInfo object. If the bot is using getUpdates, will return an object with the url field empty.

        https://core.telegram.org/bots/api#getwebhookinfo

        
        Returns:

        :return: On success, returns a WebhookInfo object
        :rtype:  pytgbot.api_types.receivable.updates.WebhookInfo
        """
        
        result = self.do("getWebhookInfo", )
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import WebhookInfo
            try:
                return WebhookInfo.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type WebhookInfo", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_webhook_info 
def unban_chat_member(self, chat_id, user_id):
        """
        Use this method to unban a previously kicked user in a supergroup or channel. The user will not return to the group or channel automatically, but will be able to join via link, etc. The bot must be an administrator for this to work. Returns True on success.

        https://core.telegram.org/bots/api#unbanchatmember

        
        Parameters:
        
        :param chat_id: Unique identifier for the target group or username of the target supergroup or channel (in the format @username)
        :type  chat_id: int | str|unicode
        
        :param user_id: Unique identifier of the target user
        :type  user_id: int
        
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(user_id, int, parameter_name="user_id")
        
        result = self.do("unbanChatMember", chat_id=chat_id, user_id=user_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def unban_chat_member 
def set_chat_permissions(self, chat_id, permissions):
        """
        Use this method to set default chat permissions for all members. The bot must be an administrator in the group or a supergroup for this to work and must have the can_restrict_members admin rights. Returns True on success.

        https://core.telegram.org/bots/api#setchatpermissions

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target supergroup (in the format @supergroupusername)
        :type  chat_id: int | str|unicode
        
        :param permissions: New default chat permissions
        :type  permissions: pytgbot.api_types.receivable.peer.ChatPermissions
        
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        from pytgbot.api_types.receivable.peer import ChatPermissions
        
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(permissions, ChatPermissions, parameter_name="permissions")
        
        result = self.do("setChatPermissions", chat_id=chat_id, permissions=permissions)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_chat_permissions 
def export_chat_invite_link(self, chat_id):
        """
        Use this method to generate a new invite link for a chat; any previously generated link is revoked. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns the new invite link as String on success.

        Note: Each administrator in a chat generates their own invite links. Bots can't use invite links generated by other administrators. If you want your bot to work with invite links, it will need to generate its own link using exportChatInviteLink – after this the link will become available to the bot via the getChat method. If your bot needs to generate a new invite link replacing its previous one, use exportChatInviteLink again.


        https://core.telegram.org/bots/api#exportchatinvitelink

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        
        Returns:

        :return: Returns the new invite link as String on success
        :rtype:  str|unicode
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        result = self.do("exportChatInviteLink", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(str, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive str", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def export_chat_invite_link 
def delete_chat_photo(self, chat_id):
        """
        Use this method to delete a chat photo. Photos can't be changed for private chats. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group.


        https://core.telegram.org/bots/api#deletechatphoto

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        result = self.do("deleteChatPhoto", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_chat_photo 
def __do_http_basic(self, method, uri,
                        value=None, headers=None, of=None,
                        handler=None, params=None):

        request_id, content, msg, err, status = None, None, None, None, None
        try:
            conn = httplib.HTTPConnection(self.endpoint, timeout=self.timeout)
            # conn.set_debuglevel(1)
            conn.request(method, uri, value, headers)
            resp = conn.getresponse()
            request_id = resp.getheader("X-Request-Id", "Unknown")

            status = resp.status
            if status / 100 == 2:
                if method == 'GET' and of:
                    readsofar = 0
                    totalsize = resp.getheader('content-length')
                    totalsize = totalsize and int(totalsize) or 0

                    hdr = None
                    if handler and totalsize > 0:
                        hdr = handler(totalsize, params)

                    while True:
                        chunk = resp.read(self.chunksize)
                        if chunk and hdr:
                            readsofar += len(chunk)
                            if readsofar != totalsize:
                                hdr.update(readsofar)
                            else:
                                hdr.finish()
                        if not chunk:
                            break
                        of.write(chunk)
                if method == 'GET' and of is None:
                    content = self.__decode_msg(resp.read())
                if method == 'PUT' or method == 'HEAD':
                    content = resp.getheaders()
            else:
                msg = resp.reason
                err = self.__decode_msg(resp.read())

        except (httplib.HTTPException, socket.error, socket.timeout) as e:
            raise UpYunClientException(str(e))
        except Exception as e:
            raise UpYunClientException(str(e))
        finally:
            if conn:
                conn.close()

        if msg:
            raise UpYunServiceException(request_id, status, msg, err)

        return content

    # http://docs.python-requests.org/ 
**************************************************


Python requests.Timeout() Examples

def test_authentication(self):
        try:
            resp = self.get('account/', op='list_authorisation_tokens')
        except requests.Timeout:
            raise errors.TransientDriverError("Timeout connection to MaaS")
        except Exception as ex:
            raise errors.PersistentDriverError(
                "Error accessing MaaS: %s" % str(ex))

        if resp.status_code in [401, 403]:
            raise errors.PersistentDriverError(
                "MaaS API Authentication Failed")

        if resp.status_code in [500, 503]:
            raise errors.TransientDriverError("Received 50x error from MaaS")

        if resp.status_code != 200:
            raise errors.PersistentDriverError(
                "Received unexpected error from MaaS")

        return True 
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        method = params.get('method', 'GET')
        json_data = params.get('json', {})
        timeout = params.pop('timeout', None) or self.timeout
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        try:
            with self.session.request(
                method, url, timeout=timeout, headers=self.headers, params=params, json=json_data
            ) as resp:
                return self._raise_for_status(resp, resp.text, method=method)
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        if self.ratelimit[1] == 0 and time() < self.ratelimit[2] / 1000:
            if not url.endswith('/auth/stats'):
                raise RatelimitErrorDetected(self.ratelimit[2] / 1000 - time())
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        timeout = params.pop('timeout', None) or self.timeout
        try:
            with self.session.get(url, timeout=timeout, headers=self.headers, params=params) as resp:
                return self._raise_for_status(resp, resp.text, method='GET')
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
def process_response(wrapped, instance, args, kwargs):
    """
    Decorator to process requests.Response

    Raises:
        Exception: Service Unavailable

    Returns:
        dict: json data
    """

    try:
        resp = wrapped(*args, **kwargs)

    except (requests.ConnectionError, requests.Timeout) as e:
        raise Exception("Service Unavailable") from e

    else:
        resp.raise_for_status()
        return resp.json() 
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
def test_location_google_breaks(self):
        """User passed location arg but google api gave error"""
        caught_exceptions = [
            requests.ConnectionError, requests.HTTPError, requests.Timeout]
        with mock.patch('requests.get') as mock_get:
            for exception in caught_exceptions:
                mock_get.side_effect = exception
                with capture_sys_output():
                    with self.assertRaises(RipeAtlasToolsException):
                        cmd = Command()
                        cmd.init_args(["--location", "blaaaa"])
                        cmd.run()
            mock_get.side_effect = Exception()
            with self.assertRaises(Exception):
                cmd = Command()
                cmd.init_args(["--location", "blaaaa"])
                cmd.run() 
def test_raise_exception_if_api_returns_error_json_response(get_phab_client):
    phab = get_phab_client(api_key="api-key")
    error_json = {
        "result": None,
        "error_code": "ERR-CONDUIT-CORE",
        "error_info": "BOOM",
    }

    with requests_mock.mock() as m:
        # Test with the generic Timeout exception, which all other timeout
        # exceptions derive from.
        m.get(phab_url("conduit.ping"), status_code=500, json=error_json)

        with pytest.raises(PhabricatorAPIException):
            phab.call_conduit("conduit.ping")
        assert m.called 
def api_delete(server_name, api, session_id):
    #Header and URL for delete call
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.delete(url, headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintrRequestsiApiException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# PUT 
def api_put(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.put(url, data=json.dumps(payload),
                         headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# POST 
def api_post(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.post(url, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# Login. 
def download_file(server_name, report_url, session_id, file_name):
    headers = {'content-type': 'application/json'}

    try:
        r = requests.get(report_url, headers=headers, verify=False, stream=True)
        # if HTTP Response is not 200 then raise an exception
        if r.status_code != 200:
            message = "The HTTP response for get call to the server is not 200."
            raise TintriApiException(message, r.status_code, report_url, "No Payload", r.text)

        with open(file_name, 'w') as file_h:
            for block in r.iter_content(4096):
                file_h.write(block)

    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except Exception as e:
        raise TintriRequestsException("An unexpected error: " + e.__str__()) 
def execute(self):
        try:
            response = Requester.request(self.method, self.url(), self.headers, self.params)
        except (requests.ConnectionError, requests.Timeout) as err:
            raise self.compose_error(err)

        if response.status_code == 401:
            text = response.text or "Authentication failed."
            raise AuthenticationError(text)
        elif response.status_code == 400:
            text = response.text or "Invalid request. Please check the URL and parameters."
            raise APIError(text)
        elif response.status_code == 404:
            text = response.text or "Invalid request. Please check the URL and parameters."
            raise APIError(text)
        elif response.status_code != 200:
            text = response.text or "An error occured while making the API call."
            raise APIError(text)

        try:
            return response.json()
        except ValueError:
            return APIError("Unable to parse the server response as JSON.") 
def scrape_page_for_open_location(self, my_webpage):
        # logger.info(u"scraping", url)
        try:
            find_pdf_link = self.should_look_for_publisher_pdf()
            if not find_pdf_link:
                logger.info('skipping pdf search')

            my_webpage.scrape_for_fulltext_link(find_pdf_link=find_pdf_link)

            if my_webpage.error:
                self.error += my_webpage.error

            if my_webpage.is_open:
                my_open_location = my_webpage.mint_open_location()
                self.open_locations.append(my_open_location)
                # logger.info(u"found open version at", webpage.url)
            else:
                # logger.info(u"didn't find open version at", webpage.url)
                pass

        except requests.Timeout, e:
            self.error += "Timeout in scrape_page_for_open_location on {}: {}".format(
                my_webpage, unicode(e.message).encode("utf-8"))
            logger.info(self.error) 
def sysprep(self):
        resource_location = "windows/sysprep.ps1"

        cmd = r"C:\{}".format(resource_location.split('/')[-1])
        self.download_resource(resource_location, cmd)
        LOG.debug("Running %s ", cmd)
        try:
            self._client.run_remote_cmd(
                cmd, command_type=util.POWERSHELL_SCRIPT_BYPASS,
                upper_timeout=CONFIG.argus.io_upper_timeout)
        except (socket.error, winrm_exceptions.WinRMTransportError,
                winrm_exceptions.InvalidCredentialsError,
                requests.ConnectionError, requests.Timeout):
            # After executing sysprep.ps1 the instance will reboot and
            # it is normal to have connectivity issues during that time.
            # Knowing these we have to except this kind of errors.
            # This fixes errors that stops scenarios from getting
            # created on different windows images.
            LOG.debug("Currently rebooting...")
        LOG.info("Wait for the machine to finish rebooting ...")
        self.wait_boot_completion() 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Notifications.json'
            r1=requests.get(Url,auth=(self.Sid,self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def FilterErrorCode(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Notifications.json?'
            params = {'ErrorCode': self.ErrorCode}
            r2 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def FilterPage(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Notifications.json?'
            params = {'PageSize': self.ErrorCode}
            r3 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Transcriptions.json'
            r1 = requests.get(Url , auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def FilterText(self):

        try:

            params = {'TranscriptionText':self.text}
            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Transcriptions.json?'
            r2 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/IncomingPhoneNumbers.json'
            r1 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content
        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def Attach(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/IncomingPhoneNumbers.json'
            data = {'PhoneNumber': self.phNumber, 'VoiceUrl': self.VoiceUrl, 'isSIP': 'true'}
            r2 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def Delete(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/IncomingPhoneNumbers.json/'+self.CallSid
            r3 = requests.delete(Url, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Call Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Clients.json'
            r4 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r4.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Recordings.json'
            r1 = requests.get(Url, auth=(self.Sid,self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def FilterCallSid(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Recordings.json?'
            params = {'CallSid':self.CallSid}

            r2 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url or Call Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def FilterPage(self):

        try:

            PageInfo = self.CallSid
            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Recordings.json?'
            params = {'PageSize': PageInfo}
            r3 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def Details(self):

        try:

            Url=self.BaseUrl+'/Accounts.json/'+self.Sid
            r1=requests.get(Url, auth=(self.Sid,self.AuthToken))

            if r1.status_code == 401:
                return "Authentication Error! Please Enter Valid Account Sid and Authentication Token"
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                print(content)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def Close(self):

        try:

            Url = self.BaseUrl+'/Accounts.json/'+self.SubSid
            data = {'Status': 'closed'}
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url is Incorrect or Invalid SubSid! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Management/Gateways.json'
            r2 = requests.get(Url,auth=(self.Sid,self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def Update(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Management/Gateways.json/'+self.GatewaySid
            data = {'FriendlyName':self.FriendlyName,'UserName':self.UserName}
            r3 = requests.post(Url,data=data,auth=(self.Sid,self.AuthToken))

            if r3.status_code == 401:
                print("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Gateway Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            print("HTTP ERROR")
        except requests.ConnectionError:
            print("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            print("TIMEOUT ERROR")
        except requests.RequestException:
            print("Invalid Url! Please check and try again") 
def Delete(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Management/Gateways.json/'+self.GatewaySid
            r4 = requests.delete(Url, auth=(self.Sid,self.AuthToken))

            if r4.status_code == 401:
                print("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url or Gateway Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            print("HTTP ERROR")
        except requests.ConnectionError:
            print("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            print("TIMEOUT ERROR")
        except requests.RequestException:
            print("Invalid Url! Please check and try again") 
def Update(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Applications.json/' + self.AppSid
            data = {'FriendlyName': self.FriendlyName}
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Application Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Applications.json/'
            r4 = requests.get(Url, auth = (self.Sid, self.AuthToken))

            if r4.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetDetails(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Calls.json'
            r2 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def Redirect(self):

        try:

            data = {'Url': self.Url}
            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Calls.json/'+self.SubSid
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Sub Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def Mute(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Conferences.json/' + self.ConferenceSid + '/Participants.json/' + self.ParticipantSid
            data = {'Mute': 'true'}

            r5 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))
            if r5.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r5.status_code == 404:
                return "Base Url/Participant Sid/Conference Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r5.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def UnMute(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Conferences.json/' + self.ConferenceSid + '/Participants.json/' + self.ParticipantSid
            data = {'Mute': 'false'}

            r6 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))
            if r6.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r6.status_code == 404:
                return "Base Url/Participant Sid/Conference Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r6.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Usage/Records/Daily.json'
            r1 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/SMS/Messages.json'
            r2 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def PageInfo(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/SMS/Messages.json'
            params = {'PageSize': self.PageSize}
            r4 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r4.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
def test_connectivity(self):
        try:
            resp = self.get('version/')
        except requests.Timeout:
            raise errors.TransientDriverError("Timeout connection to MaaS")

        if resp.status_code in [500, 503]:
            raise errors.TransientDriverError("Received 50x error from MaaS")

        if resp.status_code != 200:
            raise errors.PersistentDriverError(
                "Received unexpected error from MaaS")

        return True 
def download_file(self, report_url, file_name):
        """
        Downloads the file pointed by URL.

        Args:
        
            report_url (str): URL returned from API from which file can be downloaded
            file_name (str): Name to be used for downloaded file 
        """
        headers = {'content-type': 'application/json'}
    
        try:
            r = requests.get(report_url, headers=headers, verify=False, stream=True)
            if r.status_code != 200:
                message = "The HTTP response for get call on: %s is %s" % (report_url, r.status_code)
                raise TintriServerError(r.status_code, message=message)
    
            with open(file_name, 'w') as file_h:
                for block in r.iter_content(4096):
                    file_h.write(block)

        except TintriServerError:
            raise    
        except requests.ConnectionError:
            raise TintriError("API Connection error occurred.")
        except requests.HTTPError:
            raise TintriError("HTTP error occurred.")
        except requests.Timeout:
            raise TintriError("Request timed out.")
        except Exception as e:
            raise TintriError("An unexpected error occurred: " + e.__str__()) 
def is_working_url(self, url):
        try:
            response = requests.head(url,
                                     timeout=self.url_check_timeout,
                                     verify=self.verify_ssl)
            matches = []
            if response.status_code not in EXCEPTION_STATUS_CODES:
                matches = \
                    [re.match(pattern, str(response.status_code)) is not None
                     for pattern in INVALID_STATUS_CODES_REGEX]
            return True not in matches, response.status_code
        except Timeout:
            return False, 408
        except (RequestException, Exception):
            return False, None 
def test_is_working_url_url_with_timeout(self, req_mock):
        url_validator = UrlValidator(self.catalog, True, 1, 10)
        req_mock.head(self.test_url, exc=Timeout)
        self.assertEqual(
            (False, 408), url_validator.is_working_url(self.test_url)) 
def test_throws_exception(self):
        self.requests_mock.head(requests_mock.ANY, exc=Timeout)
        assert_false(self.dj.is_valid_catalog(broken_links=True)) 
def location2degrees(self):
        """Fetches degrees based on the given location."""
        error_log = (
            "Following error occured while trying to fetch lat/lon"
            "for location <{}>:\n{}"
        )
        goole_api_url = "http://maps.googleapis.com/maps/api/geocode/json"
        try:
            result = requests.get(goole_api_url, params={
                "sensor": "false",
                "address": self.arguments.location
            })
        except (
            requests.ConnectionError,
            requests.HTTPError,
            requests.Timeout,
        ) as e:
            error_log = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error_log)

        result = result.json()

        try:
            lat = result["results"][0]["geometry"]["location"]["lat"]
            lng = result["results"][0]["geometry"]["location"]["lng"]
        except (KeyError, IndexError) as e:
            error = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error)

        return str(lat), str(lng) 
**************************************************


Python requests.utils() Examples

def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingWebException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [WebResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        filters = requests.utils.quote("'{}'".format(self.image_filters))
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format, filters)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingImageException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [ImageResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingVideoException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [VideoResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingNewsException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [NewsResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
def login(url, data):
        headers = {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, sdch",
            "Accept-Language": "zh-CN,zh;q=0.8,en;q=0.6",
            "Connection": "keep-alive",
            "Content-Type": "application/x-www-form-urlencoded",
            "Host": "ac.ppdai.com",
            "Origin": "https://ac.ppdai.com",
            "Referer": "https://ac.ppdai.com/User/Login?message=&Redirect=",
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/51.0.2704.103 Safari/537.36",
            "X-Requested-With": "XMLHttpRequest"
        }

        cookies, exists = Server.__get_cookie()
        if not exists:
            session = requests.Session()
            session.headers = headers
            response = session.post(url, data=data)

            # 写入cookie
            with open('cookie', 'w') as f:
                pickle.dump(requests.utils.dict_from_cookiejar(response.cookies), f) 
def loadCartAndCheckout(self):
        #Import Cookies
        driver = webdriver.Chrome(executable_path="./chromedriver")
        driver.delete_all_cookies()
        driver.get(self.URL_cart)

        cookies = requests.utils.dict_from_cookiejar(self.user_session.cookies)
        
        for cookie in cookies.items():
            cookie_dict = {'name': '',
                           'value': '',
                           'path': '/'}
            cookie_dict['name'] = cookie[0]
            cookie_dict['value'] = cookie[1]
            driver.add_cookie(cookie_dict)
                          
        driver.get(self.URL_cart)
        #time.sleep(5)
        #driver.quit() 
def load_cookie(self, fname):
        # Python2 compatibility
        if PY2:
            FileNotFoundError = IOError

        try:
            with open(fname, 'r') as f:
                self.session = requests.Session()
                self.session.cookies = requests.utils.cookiejar_from_dict(json.load(f))
            cookie_username = self.cookie_dict['ds_user']
            assert cookie_username == self.username
        except FileNotFoundError:
            raise Exception('Cookie file `{}` not found'.format(fname))
        except (TypeError, EOFError):
            os.remove(fname)
            msg = ('An error occured opening the cookie `{}`, '
                   'it will be removed an recreated.')
            raise Exception(msg.format(fname))
        except AssertionError:
            msg = 'The loaded cookie was for {} instead of {}.'
            raise Exception(msg.format(cookie_username, self.username)) 
def douban_tranlation(matched_name): 
    import urllib2
    priority = {'movie':10, 'tv':9}
    qs = utils.url_encode({'q': matched_name})
    search_api = 'http://api.douban.com/v2/movie/search?%s' % (qs)
    rs = json.loads(urllib2.urlopen(search_api).read())

    items = rs['subjects']
    ret = None

    for item in items:
        if ret == None or (priority[ret['subtype']] < priority[item['subtype']]):
            ret = {
                'origin'  : item['original_title'], 
                'subtype' : item['subtype']
            }

    return ret 
def _session_check(self):
        """Attempt to authenticate the user through a session file.

        This process is done to avoid having to authenticate the user every
        single time. It uses a session file that is saved when a valid session
        is captured and then reused. Because sessions can expire, we need to
        test the session prior to calling the user authenticated. Right now
        that is done with a test string found in an unauthenticated session.
        This approach is not an ideal method, but it works.
        """
        if not os.path.exists(SESSION_FILE):
            self._log.debug("Session file does not exist")
            return False
        with open(SESSION_FILE, 'rb') as f:
            cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
            self._session.cookies = cookies
            self._log.debug("Loaded cookies from session file")
        response = self._session.get(url=self.TEST_URL, headers=self.HEADERS)
        if self.TEST_KEY in str(response.content):
            self._log.debug("Session file appears invalid")
            return False
        self._is_authenticated = True
        self._process_state()
        return True 
def authenticated(func):
    def wrapper(self, *args, **kwargs):
        success = False
        # 先判断有没有cookie文件, 再判断cookie是否有效
        if 'z_c0' in requests.utils.dict_from_cookiejar(self.cookies):
            from ..url import URL
            r = self._execute(method="get", url=URL.profile(user_slug="zhijun-liu"))
            success = r.ok
        while not success:
            account = input("请输入Email或者手机号码:")
            password = input("请输入密码:")
            obj = Account()
            data = obj.login(account, password)
            if "error" not in data:
                success = True
                self.cookies = obj.cookies
            else:
                print(data["error"]["message"])
        else:
            return func(self, *args, **kwargs)

    return wrapper 
def acquire_authentication_cookie(self, options):
        """Retrieve SPO auth cookie"""
        logger = self.logger(self.acquire_authentication_cookie.__name__)

        url = options['endpoint']

        session = requests.session()
        logger.debug_secrets("session: %s\nsession.post(%s, data=%s)", session, url, self.token)
        session.post(url, data=self.token, headers={'Content-Type': 'application/x-www-form-urlencoded'})
        logger.debug_secrets("session.cookies: %s", session.cookies)
        cookies = requests.utils.dict_from_cookiejar(session.cookies)
        logger.debug_secrets("cookies: %s", cookies)
        if 'FedAuth' in cookies and 'rtFa' in cookies:
            self.FedAuth = cookies['FedAuth']
            self.rtFa = cookies['rtFa']
            return True
        self.error = "An error occurred while retrieving auth cookies"
        logger.error(self.error)
        return False 
def copy_session(session: requests.Session) -> requests.Session:
    """Duplicates a requests.Session."""
    new = requests.Session()
    new.cookies = requests.utils.cookiejar_from_dict(requests.utils.dict_from_cookiejar(session.cookies))
    new.headers = session.headers.copy() # type: ignore
    return new 
def save_session_to_file(self, sessionfile):
        """Not meant to be used directly, use :meth:`Instaloader.save_session_to_file`."""
        pickle.dump(requests.utils.dict_from_cookiejar(self._session.cookies), sessionfile) 
def load_session_from_file(self, username, sessionfile):
        """Not meant to be used directly, use :meth:`Instaloader.load_session_from_file`."""
        session = requests.Session()
        session.cookies = requests.utils.cookiejar_from_dict(pickle.load(sessionfile))
        session.headers.update(self._default_http_header())
        session.headers.update({'X-CSRFToken': session.cookies.get_dict()['csrftoken']})
        self._session = session
        self.username = username 
def __get_cookie():
        path = os.getcwd()
        path = os.path.join(path, 'cookie')

        if os.path.isfile(path):
            with open('cookie') as f:
                cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
                return cookies, True
        else:
            return None, False 
def test_get_auth_from_url(self):
        url = 'http://user:[email protected]/path?query=yes'
        assert ('user', 'pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_encoded_spaces(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_not_encoded_spaces(self):
        url = 'http://user:pass [email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_percent_chars(self):
        url = 'http://user%25user:[email protected]/path?query=yes'
        assert ('user%user', 'pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_encoded_hashes(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass#pass') == requests.utils.get_auth_from_url(url) 
def test_html_charset(self):
        """HTML5 meta charset attribute"""
        content = '<meta charset="UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
def test_html4_pragma(self):
        """HTML4 pragma directive"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
def test_xhtml_pragma(self):
        """XHTML 1.x served with text/html MIME type"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8" />'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
def test_xml(self):
        """XHTML 1.x served as XML"""
        content = '<?xml version="1.0" encoding="UTF-8"?>'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
def test_precedence(self):
        content = '''
        <?xml version="1.0" encoding="XML"?>
        <meta charset="HTML5">
        <meta http-equiv="Content-type" content="text/html;charset=HTML4" />
        '''.strip()
        encodings = requests.utils.get_encodings_from_content(content)
        assert encodings == ['HTML5', 'HTML4', 'XML'] 
def test_get_environ_proxies_ip_ranges(self):
        """Ensures that IP addresses are correctly matches with ranges
        in no_proxy variable."""
        from requests.utils import get_environ_proxies
        os.environ['no_proxy'] = "192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1"
        assert get_environ_proxies('http://192.168.0.1:5000/') == {}
        assert get_environ_proxies('http://192.168.0.1/') == {}
        assert get_environ_proxies('http://172.16.1.1/') == {}
        assert get_environ_proxies('http://172.16.1.1:5000/') == {}
        assert get_environ_proxies('http://192.168.1.1:5000/') != {}
        assert get_environ_proxies('http://192.168.1.1/') != {} 
def test_get_environ_proxies(self):
        """Ensures that IP addresses are correctly matches with ranges
        in no_proxy variable."""
        from requests.utils import get_environ_proxies
        os.environ['no_proxy'] = "127.0.0.1,localhost.localdomain,192.168.0.0/24,172.16.1.1"
        assert get_environ_proxies(
            'http://localhost.localdomain:5000/v1.0/') == {}
        assert get_environ_proxies('http://www.requests.com/') != {} 
def test_guess_filename_when_int(self):
        from requests.utils import guess_filename
        assert None is guess_filename(1) 
def test_guess_filename_when_filename_is_an_int(self):
        from requests.utils import guess_filename
        fake = type('Fake', (object,), {'name': 1})()
        assert None is guess_filename(fake) 
def test_guess_filename_with_file_like_obj(self):
        from requests.utils import guess_filename
        from requests import compat
        fake = type('Fake', (object,), {'name': b'value'})()
        guessed_name = guess_filename(fake)
        assert b'value' == guessed_name
        assert isinstance(guessed_name, compat.bytes) 
def test_is_ipv4_address(self):
        from requests.utils import is_ipv4_address
        assert is_ipv4_address('8.8.8.8')
        assert not is_ipv4_address('8.8.8.8.8')
        assert not is_ipv4_address('localhost.localdomain') 
def test_is_valid_cidr(self):
        from requests.utils import is_valid_cidr
        assert not is_valid_cidr('8.8.8.8')
        assert is_valid_cidr('192.168.1.0/24') 
def test_dotted_netmask(self):
        from requests.utils import dotted_netmask
        assert dotted_netmask(8) == '255.0.0.0'
        assert dotted_netmask(24) == '255.255.255.0'
        assert dotted_netmask(25) == '255.255.255.128' 
def test_address_in_network(self):
        from requests.utils import address_in_network
        assert address_in_network('192.168.1.1', '192.168.1.0/24')
        assert not address_in_network('172.16.0.1', '192.168.1.0/24') 
def test_get_auth_from_url(self):
        """Ensures that username and password in well-encoded URI as per
        RFC 3986 are correclty extracted."""
        from requests.utils import get_auth_from_url
        from requests.compat import quote
        percent_encoding_test_chars = "%!*'();:@&=+$,/?#[] "
        url_address = "request.com/url.html#test"
        url = "http://" + quote(
            percent_encoding_test_chars, '') + ':' + quote(
            percent_encoding_test_chars, '') + '@' + url_address
        (username, password) = get_auth_from_url(url)
        assert username == percent_encoding_test_chars
        assert password == percent_encoding_test_chars 
def test_requote_uri_properly_requotes(self):
        """Ensure requoting doesn't break expectations."""
        from requests.utils import requote_uri
        quoted = 'http://example.com/fiz?buz=%25ppicture'
        assert quoted == requote_uri(quoted) 
def save_cookie(self, fname):
        with open(fname, 'w') as f:
            json.dump(requests.utils.dict_from_cookiejar(self.session.cookies), f) 
def save_cookies(session):
    with open(cookie_path, 'w') as f:
        pickle.dump(requests.utils.dict_from_cookiejar(session.cookies), f) 
def start_session(forceNew = False):
    session = requests.session()
    session.headers.update(headers)
    if os.path.exists(cookie_path) and forceNew != True:
        with open(cookie_path) as f:
            cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
            session.cookies.update(cookies)
            session._new_ = False
    else:
        session._new_ = True
    return session 
def reload_session(self):
    with open('cookies/cookie_' + self.user_id + '.ck') as f:
        cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
        self.s.cookies = cookies 
def authenticate(self):
        """Authenticate the user and setup our state."""
        valid = self._session_check()
        if self._is_authenticated and valid:
            self._log.debug("[!] User has already authenticated")
            return
        init = self._session.get(url=self.LOGIN_URL, headers=self.HEADERS)
        soup = BeautifulSoup(init.content, "html.parser")
        soup_login = soup.find('form').find_all('input')
        post_data = dict()
        for u in soup_login:
            if u.has_attr('name') and u.has_attr('value'):
                post_data[u['name']] = u['value']
        post_data['Email'] = self._email
        post_data['Passwd'] = self._password
        response = self._session.post(url=self.AUTH_URL, data=post_data,
                                      headers=self.HEADERS)
        if self.CAPTCHA_KEY in str(response.content):
            raise AccountCaptcha('Google is forcing a CAPTCHA. To get around this issue, run the google-alerts with the seed option to open an interactive authentication session. Once authenticated, this module will cache your session and load that in the future')
        cookies = [x.name for x in response.cookies]
        if 'SIDCC' not in cookies:
            raise InvalidCredentials("Email or password was incorrect.")
        with open(SESSION_FILE, 'wb') as f:
            cookies = requests.utils.dict_from_cookiejar(self._session.cookies)
            pickle.dump(cookies, f, protocol=2)
            self._log.debug("Saved session to disk for future reference")
        self._log.debug("User successfully authenticated")
        self._is_authenticated = True
        self._process_state()
        return 
def test_get_auth_from_url(self):
        url = 'http://user:[email protected]/path?query=yes'
        assert ('user', 'pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_encoded_spaces(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_not_encoded_spaces(self):
        url = 'http://user:pass [email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_percent_chars(self):
        url = 'http://user%25user:[email protected]/path?query=yes'
        assert ('user%user', 'pass') == requests.utils.get_auth_from_url(url) 
def test_get_auth_from_url_encoded_hashes(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass#pass') == requests.utils.get_auth_from_url(url) 
def test_html_charset(self):
        """HTML5 meta charset attribute"""
        content = '<meta charset="UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
def test_html4_pragma(self):
        """HTML4 pragma directive"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
def test_xhtml_pragma(self):
        """XHTML 1.x served with text/html MIME type"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8" />'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
def test_xml(self):
        """XHTML 1.x served as XML"""
        content = '<?xml version="1.0" encoding="UTF-8"?>'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************************

